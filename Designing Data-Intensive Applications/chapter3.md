# 第三章 存储与获取

*Wer Ordnung hält, ist nur zu faul zum Suchen*

（如果你喜欢保持事物整齐有序，你只是太懒不想去寻找罢了）

德国谚语

---

从最基础的层次来讲，数据库需要做两件事：当你给它某些数据，它应该存储这些数据，并且稍后当你问它这些数据时，它应该把数据给回你。

在第二张中我们讨论了数据模型和查询语言——比如，你（应用开发者）给数据库数据的格式，以及稍后问它再要回来的机制。在这一章我们讨论同样的东西，只是从数据库的角度出发：我们如何存储给定的数据，以及当我们被要求提供它时如何找到它。

为什么你，作为一个应用开发者，应当关心数据库内部是如何处理存储与获取的呢？你大概不会从头开始实现自己的存储引擎，但是你*确实*需要从一众可用选择中挑出适合你应用的存储引擎。为了让存储引擎在你的工作负载上运行出色，你需要对当前工作的存储引擎有一个粗略的概念。

特别的是，**为事务性负载优化的存储引擎与为分析优化的存储引擎是有很大差别的**。稍后在“事物处理还是分析？”一节探索这个差别，而在“面向列的存储”一节我们将讨论为分析优化的一个存储引擎家族。

然而，首先我们将通过讨论我们熟悉的数据库种类所使用的存储引擎开启这一章：传统的关系型数据库，以及大部分的NoSQL数据库。我们会查看储存引擎的两个家族：*日志结构*的存储引擎，以及*面向页*的存储引擎，比如B树。

## 为数据库助力的数据结构
想象一下世界上最简单的数据库，由两个Bash函数实现：
```Shell
#!/bin/bash

db_set () {
    echo "$1,$2" >> database
}

db_get () {
    grep "^$1," database | sed -e "s/^$1,//" | tail -n 1
}
```
这两个函数实现了一个键值对存储。你可以调用`db_set key value`，把`key`与`value`储存在数据库中。键与值（几乎）可以是你想要的任何事物——举个例子，值可以是一个JSON文档。之后你可以调用`db_get key`，它会查找这个键绑定的最新的值并返回它。

而它确实可以工作的：
```Shell
$ db_set 123456 '{"name":"London","attractions":["Big Ben","London Eye"]}'
$ db_set 42 '{"name":"San Francisco","attractions":["Golden Gate Bridge"]}'
$ db_get 42
```
底层存储格式非常简单：一个文本文件，每一行包含一个键值对，用逗号隔开（大致与一个CSV文件类似，除了转义字符问题）。每一个`db_set`调用把值附加在文件结尾处，所以加入你更新某个键对应的值好几次，旧版本的值没有被覆盖——你需要查找文件中键出现的最后一次从而定位到最新的值（也就是`db_get`中的`tail -n 1`）：
```Shell
$ db_set 42 '{"name":"San Francisco","attractions":["Exploratorium"]}'

$ db_get 42
'{"name":"San Francisco","attractions":["Exploratorium"]}'

$ cat database
123456 '{"name":"London","attractions":["Big Ben","London Eye"]}'
42 '{"name":"San Francisco","attractions":["Golden Gate Bridge"]}'
42 '{"name":"San Francisco","attractions":["Exploratorium"]}'
```
我们的`db_set`函数实际上对简单的事物有着相当不错的性能，因为附加到一个文件通常是非常有效率的。与`db_set`的行为类似，许多数据库在内部使用*日志*，一个只能附加的数据文件。真实的数据库有更多的问题要解决（比如并发控制、回收磁盘空间从而日志大小不会永远增长下去、以及处理错误与部分写入的条目），但是基本原则是一样的。日志出人意料的有用，在书的余下部分我们还会遇到它们几次。

> 注意
>
> *日志*这个词经常用于指代应用程序日志，那是应用程序输出描述发生了什么的文本。本书使用了*日志*更一般的含义：一个只追加的条目序列。它不必是人类可读；它也许是二进制的，只是为了让其它程序读取。

另一方面，如果在我们的数据库中有大量条目，我们的`db_get`函数性能会非常差。每一次要查找一个键，`db_get`都要从头到尾扫描整个数据库文件，查找键的出现。用算法术语的话，一次查询的代价是`O(n)`:如果数据库中的条目数`n`翻倍，那么查找也要花掉双倍的时间。这可不妙。

为了有效率地在数据库中查找特定地键，我们需要一个不一样地数据结构：*索引*。在这一章我们将看到一系列的索引结构并比较它们；它们背后的大概概念是另外保留某些额外的元数据作为路标，并帮助你定位到你想要的数据。如果你要用集中不同的方式搜索同一个数据，你也许需要几种由不同部分数据构成的索引。

索引是由主数据衍生出来的*额外的*数据结构。许多数据库允许添加和移除索引，而这并不影响数据库的内容；它只影响查询的性能。维护多余的数据结构导致额外的开销，尤其是在写入的时候。对写入来说，要击败只是附加内容到文件的性能是很难的，因为那就是最简单的写入操作。任何类型的索引通常都会使写入变慢，因为每次数据写入时都需要更新索引。

在数据系统中这是很重要的权衡：精心挑选的索引使读取查询更快，但是每一个索引都会使写入变慢。由于这个原因，数据库默认不为所有数据创建索引，而是要求你——应用开发者或是数据库管理员——手动选择索引，这需要借助你对应用的典型查询模式的理解。这样你可以选择带给应用最大便利的索引，而不必引入不必要的开销。

### 哈希索引
让我们从键值对数据索引开始。当然你不只是能为这类数据建立索引，但是它很常见，同时也是更复杂索引的有用组件。键值存储与大多数编程语言中的*字典*类型非常类似，通常实现为一个哈希映射（哈希表）。哈希映射在许多算法教科书里都有描述，所以我们在这里不会具体讨论它是怎么工作的。既然我们已经为内存内数据结构使用了哈希映射，为什么不用它们为磁盘上的数据建立映射呢？

Let’s say our data storage consists only of appending to a file, as in the preceding example. Then the simplest possible indexing strategy is this: keep an in-memory hash map where every key is mapped to a byte offset in the data file — the location at which the value can be found, as illustrated in Figure   3-1. Whenever you append a new key-value pair to the file, you also update the hash map to reflect the offset of the data you just wrote (this works both for inserting new keys and for updating existing keys). When you want to look up a value, use the hash map to find the offset in the data file, seek to that location, and read the value.

假如说我们的数据存储只是附加数据到文件，就像之前的例子一样。那么最简单可行的索引策略是这样的：维护一个在内存中的哈希映射，其中每一个键都映射到数据文件的一个字节偏移地址——在这个地址可以找到对应的值，如图3-1所示。一旦一个新键值对被附加到文件，同时更新这个哈希映射从而反映刚刚写入数据的偏移地址（这个策略对插入新键以及更新已有的键都有效）。当你需要查找一个值时，用这个哈希映射找到数据文件中的偏移地址，寻址并读取值。

*图3-1 用类似CSV格式储存键值对日志，并用在内存中的哈希映射建立索引*

这听起来很简单，但确实是一种可行的方法。实际上，Bitcask（Riak的默认存储引擎）就是这么做的。Bitcask提供了高性能的读写，满足了所有键都可以存储在可用内存的需求，因为哈希映射完全储存在内存中。值会用掉比可用内存更多的空间，因为只需要一次寻址就可以从磁盘加载这些值。如果部分数据文件已经在文件系统的缓存中的话，那么读取完全不需要任何磁盘输入输出。

类似Bitcask这样的存储引擎非常适合值经常更新的情况。举个例子，键也许是一个关于猫的视频的URL，而值也许是视频被播放的次数（每当有任点击了播放键就增加）。在这样的负载下，有许多的写入，但是没有太多不同的键——每个键写入次数很多，但是把所有键保存在内存中是可行的。

到目前位置所描述的，都只是附加数据到文件——那么我们如何避免最终耗光磁盘空间呢？一个好的解决方案是把日志拆分为特定大小的段，当段达到特定大小之后关闭这个段，并把后续数据写入到一个新的段文件中。这样我们就可以对这些段文件进行压缩，如图3-2所示。压缩意味着丢弃日志中重复的键，只保留每个键最新的更新。

*图3-2 压缩一个键值对更新日志（记录每一个猫视频的播放次数），只保留每个键最新的更新*

此外，由于压缩经常使段文件变得非常小（假设一个键在一个段中平均被复写了好几次），我们还可以在压缩的同时合并好几个段文件，如图3-3所示。段文件在被写入后不会再被修改，于是合并了的段被写入到一个新文件。合并与压缩被冻结的段可以在后台线程中完成，而同时，我们可以继续如往常一样用老的段文件服务读取和写入请求。当合并过程结束，读取请求从就的段文件切换到到新的合并过的段——在这之后旧的段文件就可以删除了。

*图3-3. 同时执行压缩与合并*

现在每一个段都有了自己的在内存中的哈希表，把键映射到了文件偏移地址。为了找到键对应的值，我们首先检查最新的段的哈希映射；如果键不存在我们检查第二新的段，以此类推。合并使得段的数量很小，所以查找并不需要检查太多哈希映射。

Lots of detail goes into making this simple idea work in practice. Briefly, some of the issues that are important in a real implementation are:

许多细节都把这个简单的想法付诸实践。简而言之，真正的实现中一些重要的问题是：

*文件格式*

对于日志来说CSV并不是最好的格式。使用二进制格式更快也更简单：编码首先是以字节为单位的字符串长度，而后是原始字符串（不需要转义）。

*删除条目*

如果你要删除一个键以及对应的值，你必须附加一个特殊的删除条目到数据文件（有时被叫做*墓碑*）。当日志段被合并的时候，墓碑会告诉合并过程丢掉被删除的键对应的任何之前的值。

*崩溃恢复*

如果数据库被重启，在内存中的哈希映射会丢失。原则上，你可以通过从头到尾读取整个段文件，并在过程中标记每个键最新的值的偏移地址的方法恢复每一个段的哈希映射。然而，如果段文件很大的话这大概会花很长时间，使得服务器重启变得很痛苦。Bitcask通过把每一个段的哈希映射快照储存在磁盘上提高了恢复速度，快照可以非常快速的被加载到内存中。

*部分写入记录*

数据库随时有可能崩溃，其中当然也包括正在附加条目到日志的时候。Bitcask文件包含校验值，从而可以检测、忽略日志受损的部分。

*并发控制*

只允许附加的日志第一眼看起来是很浪费的：为什么不就地更新文件呢，用新的值覆盖旧的值？然而只允许附加的设计结果因为这几个原因被证明是很好的：
* 附加数据与段合并时顺序写入操作，这通常比随机写入要快得多，尤其是传统机械硬盘上。某种程度上相对于基于闪存芯片的*固态硬盘*顺序写入也是更优先的选择。我们会在“比较B树与LSM树”一节深入讨论这个问题。
* 如果段文件是只允许附加的或者不可变的话，并发与崩溃恢复就会更简单。举个例子，你不需要担心当值被复写时崩溃发生了，留下了一个包含部分旧数据和部分新数据的文件。
* 合并旧的段防止了数据文件碎片化的问题。

然而，哈希表索引也有局限：
* 哈希表必须能放到内存中，如果你有很大量的键的话就很不走运了。原则上你可以在磁盘上维护哈希映射，但是不幸的是让位于磁盘上的哈希映射运行良好很困难。它需要大量随机访问输入输出，变满了之后再要增长就会有很高的代价，而哈希散列需要非常繁琐的逻辑。
* 范围查询效率低下。举个例子，扫描所有在`kitty00000`到`kitty99999`之间的键非常不容易——你需要在哈希映射中挨个查找。

下一节我们会看到没有这些限制的索引结构。

### SSTable与LSM树
在图3-3中，每一个日志结构存储段都是一个键值对序列。这些键值对出现的顺序就是写入时的顺序，而日志中稍后出现的值优先于同一个键稍早之前出现的值。除此之外，文件中键值对的顺序完全无关。

现在我们对段文件的格式做一个简单的变化：我们要求键值对的次序是*按键排序的*。乍一看，这个要求好像使得我们无法继续使用顺序写入了，但是我们稍后再讨论这个问题。

我们把这种格式叫做*排序字符串表*，简称SSTable。我们还要求在每个合并后的段文件中每个键只能出现一次（压缩过程已经保证了这一点）。相比于有哈希索引的日志段，SSTable有几个大优势：
1. 合并段既简单效率又高，哪怕段文件比可用内存大。这种方式与*合并排序*算法用到的类似，如图3-4所示：开始的时候并列读取输入文件，取每个文件的第一个键，（根据排序顺序）拷贝顺序最小的的键到输入文件，然后重复这个过程。这样产生了一个新的合并段文件，同样按键排好了序。

    *图3-4 合并几个SSTable段，为每个键只保留了最新的值*

    如果同一个键出现在几个输入段呢？记住，每个段都包含了某个时间段内所有写入数据库的值。这意味着一个输入段中所有的值必然比其它段中所有的值都要新（假如我们一直合并相邻的段的话）。当多个段包含同一个键，我们可以保留最新的段中的值而丢弃在老的段中的值。

2. 为了找到文件中的某个特定键，你不用再在内存中保留所有键的索引了。看图3-5中的一个例子：假设你要找键`handiwork`，但是你不知道这个键再段文件中的偏移地址。然而，你却知道键*handbag*与*handsome*的偏移地址，由于排序你知道*handiwork*必然出现在这二者之间。这意味着你可以先跳到*handbag*的偏移地址然后从那里开始扫描，直到你找到*handiwork*（或者没有，如果这个键没有在这个文件中出现）。
    
    *图3-5 一个有内存索引的SSTable。*

    你仍然需要一个内存索引来告诉你某些键的偏移地址，它可以是很分散的：段文件内每几个KB存一个键就足够了，因为搜索几个KB是非常快的。

3. 因为不管怎样读取请求需要扫描请求范围内的一些键值对，把这些条目分组到一个数据块然后在写入磁盘前压缩它是可能的（图3-5中的暗影区域部分）。这样，每一个分散的内存索引条目都指向了一个压缩块的起始地址。除了节省了磁盘空间以外，压缩也降低了输入输出的带宽使用。

#### 构建与维护SSTable
目前为止还不错——但是首先你如何让数据按键排序？后续的写入可以是任意顺序的。

在磁盘上维护一个排好序的结构是可能的（见“B树”一节），但是在内存中维护会更简单一点。有足够多的已知的树结构可以用，比如红黑树或者AVL树。有这些数据结构，你可以以任何顺序插入键并且按顺序重新读回它们。

现在我们可以让我们的数据引擎按照下边的方式工作：
* 当一个写入发生时，把它添加到一个内存平衡树结构（比如，一个红黑树）中。这个内存树结构有时被叫做*内存表*。
* 当内存表的大小超过阙值时——一般几个MB——把内存表写到磁盘成为一个SSTable文件。因为树结构已经保持键值对按键排序，这个动作可以完成得很有效率。新的SSTable文件成为了数据库最新的段。在SSTable被写到磁盘的同时，写入动作可以继续进行，数据保存到了一个新的内存表实例中。
* 为了服务读取请求，首先尝试在内存表里查找键，然后是在磁盘上最新的段文件，然后是在第二新的段文件，等等。
* 时不时的在后台运行一个合并与压缩过程以合并段文件，并丢弃被复写或删除的值。

这个方案工作的非常出色。只受一个问题的影响：如果数据库崩溃，最近的写入（在内存表中还没有写入到磁盘）会丢失。为了防止这个问题，我们可以在磁盘上维护一个单独的日志，每一次写入都立即附加到这里，就像上一节里一样。这个日志不排序，但是这没关系，因为它的作用就是在崩溃之后恢复内存表。每一次内存表被写入到SSTable，这个对应的日志就可以被丢掉了。