# 第三章 存储与获取

*Wer Ordnung hält, ist nur zu faul zum Suchen*

（如果你喜欢保持事物整齐有序，你只是太懒不想去寻找罢了）

德国谚语

---

从最基础的层次来讲，数据库需要做两件事：当你给它某些数据，它应该存储这些数据，并且稍后当你问它这些数据时，它应该把数据给回你。

在第二张中我们讨论了数据模型和查询语言——比如，你（应用开发者）给数据库数据的格式，以及稍后问它再要回来的机制。在这一章我们讨论同样的东西，只是从数据库的角度出发：我们如何存储给定的数据，以及当我们被要求提供它时如何找到它。

为什么你，作为一个应用开发者，应当关心数据库内部是如何处理存储与获取的呢？你大概不会从头开始实现自己的存储引擎，但是你*确实*需要从一众可用选择中挑出适合你应用的存储引擎。为了让存储引擎在你的工作负载上运行出色，你需要对当前工作的存储引擎有一个粗略的概念。

特别的是，**为事务性负载优化的存储引擎与为分析优化的存储引擎是有很大差别的**。稍后在“事物处理还是分析？”一节探索这个差别，而在“面向列的存储”一节我们将讨论为分析优化的一个存储引擎家族。

然而，首先我们将通过讨论我们熟悉的数据库种类所使用的存储引擎开启这一章：传统的关系型数据库，以及大部分的NoSQL数据库。我们会查看储存引擎的两个家族：*日志结构*的存储引擎，以及*面向页*的存储引擎，比如B树。

## 为数据库助力的数据结构
想象一下世界上最简单的数据库，由两个Bash函数实现：
```Shell
#!/bin/bash

db_set () {
    echo "$1,$2" >> database
}

db_get () {
    grep "^$1," database | sed -e "s/^$1,//" | tail -n 1
}
```
这两个函数实现了一个键值对存储。你可以调用`db_set key value`，把`key`与`value`储存在数据库中。键与值（几乎）可以是你想要的任何事物——举个例子，值可以是一个JSON文档。之后你可以调用`db_get key`，它会查找这个键绑定的最新的值并返回它。

而它确实可以工作的：
```Shell
$ db_set 123456 '{"name":"London","attractions":["Big Ben","London Eye"]}'
$ db_set 42 '{"name":"San Francisco","attractions":["Golden Gate Bridge"]}'
$ db_get 42
```
底层存储格式非常简单：一个文本文件，每一行包含一个键值对，用逗号隔开（大致与一个CSV文件类似，除了转义字符问题）。每一个`db_set`调用把值附加在文件结尾处，所以加入你更新某个键对应的值好几次，旧版本的值没有被覆盖——你需要查找文件中键出现的最后一次从而定位到最新的值（也就是`db_get`中的`tail -n 1`）：
```Shell
$ db_set 42 '{"name":"San Francisco","attractions":["Exploratorium"]}'

$ db_get 42
'{"name":"San Francisco","attractions":["Exploratorium"]}'

$ cat database
123456 '{"name":"London","attractions":["Big Ben","London Eye"]}'
42 '{"name":"San Francisco","attractions":["Golden Gate Bridge"]}'
42 '{"name":"San Francisco","attractions":["Exploratorium"]}'
```
我们的`db_set`函数实际上对简单的事物有着相当不错的性能，因为附加到一个文件通常是非常有效率的。与`db_set`的行为类似，许多数据库在内部使用*日志*，一个只能附加的数据文件。真实的数据库有更多的问题要解决（比如并发控制、回收磁盘空间从而日志大小不会永远增长下去、以及处理错误与部分写入的条目），但是基本原则是一样的。日志出人意料的有用，在书的余下部分我们还会遇到它们几次。

> 注意
>
> *日志*这个词经常用于指代应用程序日志，那是应用程序输出描述发生了什么的文本。本书使用了*日志*更一般的含义：一个只追加的条目序列。它不必是人类可读；它也许是二进制的，只是为了让其它程序读取。

另一方面，如果在我们的数据库中有大量条目，我们的`db_get`函数性能会非常差。每一次要查找一个键，`db_get`都要从头到尾扫描整个数据库文件，查找键的出现。用算法术语的话，一次查询的代价是`O(n)`:如果数据库中的条目数`n`翻倍，那么查找也要花掉双倍的时间。这可不妙。

为了有效率地在数据库中查找特定地键，我们需要一个不一样地数据结构：*索引*。在这一章我们将看到一系列的索引结构并比较它们；它们背后的大概概念是另外保留某些额外的元数据作为路标，并帮助你定位到你想要的数据。如果你要用集中不同的方式搜索同一个数据，你也许需要几种由不同部分数据构成的索引。

索引是由主数据衍生出来的*额外的*数据结构。许多数据库允许添加和移除索引，而这并不影响数据库的内容；它只影响查询的性能。维护多余的数据结构导致额外的开销，尤其是在写入的时候。对写入来说，要击败只是附加内容到文件的性能是很难的，因为那就是最简单的写入操作。任何类型的索引通常都会使写入变慢，因为每次数据写入时都需要更新索引。

在数据系统中这是很重要的权衡：精心挑选的索引使读取查询更快，但是每一个索引都会使写入变慢。由于这个原因，数据库默认不为所有数据创建索引，而是要求你——应用开发者或是数据库管理员——手动选择索引，这需要借助你对应用的典型查询模式的理解。这样你可以选择带给应用最大便利的索引，而不必引入不必要的开销。

### 哈希索引
让我们从键值对数据索引开始。当然你不只是能为这类数据建立索引，但是它很常见，同时也是更复杂索引的有用组件。键值存储与大多数编程语言中的*字典*类型非常类似，通常实现为一个哈希映射（哈希表）。哈希映射在许多算法教科书里都有描述，所以我们在这里不会具体讨论它是怎么工作的。既然我们已经为内存内数据结构使用了哈希映射，为什么不用它们为磁盘上的数据建立映射呢？

Let’s say our data storage consists only of appending to a file, as in the preceding example. Then the simplest possible indexing strategy is this: keep an in-memory hash map where every key is mapped to a byte offset in the data file — the location at which the value can be found, as illustrated in Figure   3-1. Whenever you append a new key-value pair to the file, you also update the hash map to reflect the offset of the data you just wrote (this works both for inserting new keys and for updating existing keys). When you want to look up a value, use the hash map to find the offset in the data file, seek to that location, and read the value.

假如说我们的数据存储只是附加数据到文件，就像之前的例子一样。那么最简单可行的索引策略是这样的：维护一个在内存中的哈希映射，其中每一个键都映射到数据文件的一个字节偏移地址——在这个地址可以找到对应的值，如图3-1所示。一旦一个新键值对被附加到文件，同时更新这个哈希映射从而反映刚刚写入数据的偏移地址（这个策略对插入新键以及更新已有的键都有效）。当你需要查找一个值时，用这个哈希映射找到数据文件中的偏移地址，寻址并读取值。

*图3-1 用类似CSV格式储存键值对日志，并用在内存中的哈希映射建立索引*

这听起来很简单，但确实是一种可行的方法。实际上，Bitcask（Riak的默认存储引擎）就是这么做的。Bitcask提供了高性能的读写，满足了所有键都可以存储在可用内存的需求，因为哈希映射完全储存在内存中。值会用掉比可用内存更多的空间，因为只需要一次寻址就可以从磁盘加载这些值。如果部分数据文件已经在文件系统的缓存中的话，那么读取完全不需要任何磁盘输入输出。

类似Bitcask这样的存储引擎非常适合值经常更新的情况。举个例子，键也许是一个关于猫的视频的URL，而值也许是视频被播放的次数（每当有任点击了播放键就增加）。在这样的负载下，有许多的写入，但是没有太多不同的键——每个键写入次数很多，但是把所有键保存在内存中是可行的。

到目前位置所描述的，都只是附加数据到文件——那么我们如何避免最终耗光磁盘空间呢？一个好的解决方案是把日志拆分为特定大小的段，当段达到特定大小之后关闭这个段，并把后续数据写入到一个新的段文件中。这样我们就可以对这些段文件进行压缩，如图3-2所示。压缩意味着丢弃日志中重复的键，只保留每个键最新的更新。

*图3-2 压缩一个键值对更新日志（记录每一个猫视频的播放次数），只保留每个键最新的更新*

此外，由于压缩经常使段文件变得非常小（假设一个键在一个段中平均被复写了好几次），我们还可以在压缩的同时合并好几个段文件，如图3-3所示。段文件在被写入后不会再被修改，于是合并了的段被写入到一个新文件。合并与压缩被冻结的段可以在后台线程中完成，而同时，我们可以继续如往常一样用老的段文件服务读取和写入请求。当合并过程结束，读取请求从就的段文件切换到到新的合并过的段——在这之后旧的段文件就可以删除了。

*图3-3. 同时执行压缩与合并*

现在每一个段都有了自己的在内存中的哈希表，把键映射到了文件偏移地址。为了找到键对应的值，我们首先检查最新的段的哈希映射；如果键不存在我们检查第二新的段，以此类推。合并使得段的数量很小，所以查找并不需要检查太多哈希映射。

Lots of detail goes into making this simple idea work in practice. Briefly, some of the issues that are important in a real implementation are:

许多细节都把这个简单的想法付诸实践。简而言之，真正的实现中一些重要的问题是：

*文件格式*