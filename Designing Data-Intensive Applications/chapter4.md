# 第四章 编码与演化

*世事皆变，无有静止*

以弗所的赫拉克利特，柏拉图在克堤拉斯篇引用的

---

应用程序不可避免地随时间而改变。因为新产品发布、用户需求的理解更加深入或者商业环境的改变，功能被添加被更改。在第一章中我们介绍了可进化性：我们应该着眼于构建可以轻松引入变更的系统（详见“可进化性：使变更变得简单”）。

在大多数情况下，应用功能的变更也需要对存储的数据变更：也许需要获取一个新的字段或者新的记录类型，也许也有数据需要以一种新的方式表达。

我们在第二章讨论的数据模型有不一样的方式应对这种变化。关系型数据库一般假设数据库中的所有数据符合一个模式定义：虽然这个模式定义可以改变（通过模式迁移；比如，`ALTER`语句），但是在任何一个时间点都只有一个模式定义生效。相比之下，只读模式（“无模式”）大数据不强制要求一个模式定义，所以数据库可以包含不同时间写入的新旧数据格式（见“文档模型中的模式定义灵活性”一节）。

当数据格式或是模式定义变化的时候，对应的应用代码也会发生变化（比如，为记录添加一个新字段，然后应用程序代码读写这个字段）。然而，在一个大的应用中，代码变化不会立即发生：

* 对服务器应用程序你大概想要执行*滚动升级*（也叫做*分阶段推出*），一次部署新版到一部分节点，检查新版本是不是平稳运行，然后逐步部署到所有的节点。这使得新版本的部署没有离线，因而估计更频繁的发布以及更好的演进。

* 对于客户端应用程序，您可能会受到用户的摆布，他们可能不会在一段时间内安装更新。

这意味着新旧版本代码，以及新旧版本的数据格式，很可能同一时间存在于系统中。为了使系统继续平稳运行，需要同时在两个方向保持兼容性：

*向后兼容*

新代码可以读取旧代码写入的数据。

*向前兼容*

旧代码可以读取新代码写入的数据。

向后兼容通常并不难实现：作为新代码的作者，你知道旧代码写入的数据格式，于是你可以显式处理它（如果必要只是让旧代码读取旧数据）。向前兼容会复杂一些，因为它需要旧代码忽略新代码带来的添加。

在这一章我们会了解几种数据编码的格式，包括JSON、XML、Protocol Buffers、Thrift以及Avro。特别的是，我们会了解它们是如何处理模式变更以及如何支持新旧数据与新旧代码需要共存的系统。然后我们会讨论这些格式是如何用于数据存储以及通讯的：在web服务中，具象状态传输（REST）与远程过程调用（RPC），以及消息传递系统，比如参与者与消息队列。

## 数据编码的格式

程序通常使用（至少）两种表现形式的数据：

1. 在内存中，数据以对象、结构体、链表、数组、哈希表、树等形式保存。这些数据结构都为CPU的高效访问与处理优化（一般通过使用指针）了。

2. 把数据写入文件或者通过网络发送的时候，必须把它编码为某种自成体系的字节序列（比如，JSON文档）。由于指针对其它进程没有任何意义，这个字节序列形式与内存中常见的数据结构非常不同。

因而，我们需要两种表现形式之间的转换方式。从内存表现形式转为字节序列叫做*编码*（也叫做*序列化*或者*编组*），相反的处理叫做*解码*（*解析，反序列化，反编组*）。

> ##### 术语冲突
>
> 不幸的是*序列化*在事务中（见第七章）也用到了，但是有完全不同的含义。为了避免重载这个词我们将在本书中继续使用*编码*这个词，即使*序列化*也许是更常见的术语。

由于这是一个常见问题，因此可以选择多种不同的库和编码格式。让我们来做一个简要的概述。

### 编程语言特有的格式

许多编程语言都内置支持把编码内存对象编码为字节序列。举个例子，Java有`java.io.Serializable`，Ruby有`Marshal`，Python有`pickle`，等等。也有许多第三方库，比如Java的Kryo。

这些编码库非常方便，因为它们允许用最少的代码保存和恢复内存中的对象。然而，它们也有一些深层次的问题：

* 编码经常与特定编程语言绑定，而用另外一种语言读取数据非常困难。如果用这样一种编码保存或传输数据，你投身于当前编程语言也许太长时间了，而且没有把你的系统与其他组织的系统（也许用了其他语言）集成在一起。

* 为了把数据恢复成同一种对象类型，解码过程需要能初始化任意类型。这常常是安全问题的源头：如果攻击者可以使你的应用解码任意字节流，它们可以初始化任意类型，这经常导致允许它们干坏事，比如远程执行任意代码。

* 在这些库中，版本控制数据往往是事后考虑的事情：因为它们旨在快速简便地编码数据，所以它们通常会忽略向前和向后兼容这样不便的问题。

* 效率（编解码花费的CPU时间，以及编码后结构的大小）往往也是事后考虑的问题。举个例子，Java内置的序列化因其糟糕的性能和臃肿的编码而恶名远扬。

由于这些原因，通常使用编程语言内建的编码都是一个糟糕的注意，除非是临时性的原因。

### JSON，XML，和二进制变体

把目光转到可以被许多编程语言读写的标准化编码，JSON与XML显然是竞争者。它们广为人知，被广泛支持，也几乎是广泛地不受欢迎。XML经常被人诟病太冗长，不必要地复杂。JSON受欢迎主要是因为浏览器的内建支持（由于是JavaScript的一个子集），相对于XML也简单。CSV是另一种流行的语言无关格式，尽管不那么强大。

JSON、XML以及CSV是基于文本的格式，因而某种程度上是可读的（虽然语法是一个热门争论话题）。除了表面的语法问题，还有一些细微的问题：

* 数字的编码有许多不确定性。在XML与CSV中，你无法区分数字与数字构成的字符串（除非通过引用外部的模式定义）。JSON区分字符串与数字，然而它不区分整型数与浮点数，而且也不会指明精度。

    处理大数字也有问题；比如说，大于253的整型数没有办法用IEEE 754双精度浮点数精确表示，于是这些数字被使用单精度数的语言（比如JavaScript）解析时就变得不精确了。这样的例子发生在推特，它们用一个64位数表示每一条推文。推特API返回的JSON包含了两个推文ID，一个是JSON数字，另一个是十进制数的字符串，来避开数字无法被JavaScript应用正确解析的事实。

* JSON与XML有着很好的Unicode字符串支持（也就是可读文本），但是它们不支持二进制字符串（没有字符编码的字节序列）。二进制字符串是很有用的功能，于是人们通过把二进制数据以Base64编码为文本从而绕开这个局限。之后模式定义指出这个值应当被解读为Base64编码的。这样可以工作，但是从某种程度上说这样效果不好，数据尺寸大小增加了33%。

* XML与JSON都支持可选的模式定义。模式定义语言非常强大，也因而学习实现圈起来非常复杂。XML模式定义的使用相当广泛，但是需要基于JSON的工具懒得去使用模式定义。由于数据正确的解读（比如数字与二进制字符串）取决于模式定义中的信息，不使用XML/JSON的应用需要硬编码合适的编解码逻辑。

* CSV没有任何模式定义，所以每一行每一列的含义取决于应用程序的定义。如果应用变更添加新的行或者列，你需要手动处理这个变更。CSV也是种相当模糊的格式（如果一个值包含逗号或者新行字符会发生什么？）。虽然转义字符规则已经正式定义了，并不是所有的解析器都正确地实现了它们。

除了这些瑕疵，JSON、XML以及CSV对于许多用途来说都足够好了。很有可能它们会继续流行下去，特别是作为数据交换格式（比如从一个组织向另外一个组织发送数据）。在这样的情况下，只要人们一致同意使用哪种格式，格式本身是否漂亮或者高效经常是无所谓的。让不同的组织一致同意某件事的难度可比其它问题高多了。

#### 二进制编码

对于那些只在组织内部使用的数据，必须使用最小公分母编码格式的压力小了很多。比如，可以选择一种更紧凑或者解析更快的格式。对于小数据集，收益可以忽略不计，然而一旦上涨到TB级别，数据格式的选择就会产生重大影响。

相比于XML，JSON没有那么冗长，但是相比于二进制格式二者还是用到了许多空格。这导致了针对JSON（比如MessagePack、BSON、BJSON、UBJSON、BISON和Smile）与XML（比如WBXML与Fast Infoset）的二进制编码的大量开发。这些格式被引入了众多生态中，但是它们中没有一个如文本版本的JSON与XML一样被广泛采用。

这些格式中的一部分扩展了数据类型集合（比如，区分了整型数与浮点数，或者添加了对二进制字符串的支持），其它的则保留了JSON/XML数据模型没有变。特别的是，由于没有规定模式定义，它们需要在编码后的数据中包含所有的对象字段名。也就是说，在示例4-1的JSON文档的二进制编码中，需要在某个地方包含字符串`userName`、`favoriteNumber`、`interests`。

*示例4-1 示例记录，这一章中我们会用几种二进制格式对它编码*

```JSON
{
    "userName": "Martin",
    "favoriteNumber": 1337,
    "interests": ["daydreaming", "hacking"]
}
```

让我们来看MessagePack，一种JSON的二进制编码的例子。图4-1展示了用MessagePack编码示例4-1中JSON文档后得到的字节序列。最初的几个字节是：

1. 第一个字节，`0x83`，表示紧跟着的是一个对象（高4位 = `0x80`），有三个字段（低4位 = `0x03`）。（加入你在想如果对象有超过15个字段会发生什么，那么字段数用4位表示不了了，于是它有另外一个类型标识，而字段数被编码为了2到4个字节。）

2. 第二个字节，`0xa8`，表示紧跟着的是一个字符串（高4位 = `0xa0`），有八个字节长（低4位 = `0x08`）。

3. 接下来八个字节是ASCII编码的字段名`userName`。由于长度先前指明了，于是不需要任何标记位来告诉我们字符串在哪里结束（或是任何转义）。

4. 解析来七个字节编码了六个字母的字符串值`Martin`以及前缀`0xa6`，等等。

这个二进制编码有66个字节长，只比81个字节长的文本JSON（去掉了空格）编码少了一点点。所有JSON的二进制编码在这方面都类似。不确定这么小的空间节省（以及解析速度的提升）值不值得放弃可读性。

在接下来的几节我们会看到如何做得更好，同样的记录只用32个字节编码。

*图4-1 用MessagePack编码示例记录（示例4-1）*

### Thrift与Protocol Buffers

Apache Thrift与Protocol Buffers（protobuf）是基于同样原则二进制编码库。Protocol Buffers最初由谷歌开发，Thrift最初由Facebook开发，二者在2007到08年之间都开源了。

对于编码的数据，Thrift与Protocol Buffers二者都需要一个模式定义。为了用Thrift编码示例4-1中的数据，需要用Thrift接口定义语言（IDL）描述模式定义，类似这样：

```IDL
struct Person {
    1: required string          userName,
    2: optional i64             favoriteNumber,
    3: optional list < string > interests
}
```

等价的Protocol Buffers的模式定义看起来很类似：

```protobuf
message Person {
    required string user_name       = 1;
    optional int64  favorite_number = 2;
    repeated string interests       = 3;
}
```

Thrift与Protocol Buffers都自带代码生成工具，它接受一个类似这样的模式定义，然后用不同编程语言生成实现这个模式定义的类。应用程序可以调用这个生成的代码来编解码模式定义对应的记录。

用这个模式定义编码的数据是什么样子的？令人困惑的是，Thrift有两种不同的二进制编码格式，分别叫做*BinaryProtocol*与*CompactProtocol*。我们先来看BinaryProtocol。用这种格式编码示例4-1需要59个字节，如图4-2所示。

*图4-2 用Thrift的BinaryProtocol编码示例条目*

与图4-1类似，每个字段有一个类型标记（指出这是一个字符串、整型数、链表等等）以及必有的长度标记（字符串长度，链表中项目个数）。数据中出先得字符串（“Martin”、“Daydreaming”、“hacking”）也被编码为ASCII码（或者，UTF-8），与之前类似。

与图4-1的最大不同在于这里没有字段名（`userName`、`favoriteNumber`、`interests`）。相反，编码后的数据包含字段标签，它们是数字（`1`、`2`和`3`）。这些数字出现在模式定义中。字段标签类似字段的别名——这是一种描述字段的紧凑方式，不需要把字段名描述出来。

Thrift的CompactProtocol编码语义上与BinaryProtocol等价，但如你在图4-3中看到的，它打包同样的信息只用了34个字节。它通过把字段类型与标签打包到一个字节做到的，以及使用变化长度的整型数。数字1337不是使用全部八个字节，而是被编码为两个字节，其中每个字节的高位用来表示之后是否还有更多的字节需要处理。这意味着表示位于-64到63的数字只需要一个字节，表示位于-8192到8191的数字只需要两个字节，等等。更大的数字需要更多的字节。

*图4-3 用Thrift的CompactProtocol编码示例条目*

最后，Protocol Buffers（只有一种二进制编码格式）编码同样的数据如图4-4所示。它做打包位的方式有些许不同，但是与Thrift的CompactProtocol非常类似。Protocol Buffers用了33个字节编码了同样的条目。

*图4-4 用Protocol Buffers编码示例条目*

注意一个细节：早先展示的模式定义中，每个字段都标记了`required`或者`optional`，但是这不影响字段是如何编码的（二进制数据中没有办法表示一个字段是否为必须的）。区别只是在于`required`可以启动运行时检查，如果字段没有设置将会失败，方便捕获bug。

#### 字段标签与模式定义演进

我们之前说，模式定义无法避免地随着时间推移需要变更。我们把这叫做模式定义演进。Thrift与Protocol Buffers是如何处理模式定义变更且同时保持向后以及向前兼容地呢？

正如之前例子看到的，编码后的记录只是编码后字段的连接。每个字段通过它的标签号码标记（示例模式定义中的数字1，2，3）并用数据类型标注（例如字符串或者整型数）。如果一个字段值没有设，它只是简单地被编码后的条目忽略了。从这里你可以看出字段标签对于编码后数据的含义至关重要。你可以在模式定义中改变一个字段的名字，毕竟编码后的数据从不引用字段名字，但是你不能改变一个字段的标签，因为这将使得所有已经存在的编码后数据无效。

你可以添加新的字段到模式定义中，前提是你给每一个字段一个新的标签号码。如果旧代码（不知道你添加的新标签好吗）尝试读取新代码写入的数据，其中包含它不能识别的标签号码对应的字段，它可以简单地忽略那个字段。数据类型标记允许解析器判定多少字节需要忽略。这保持了向前兼容性：旧代码可以读取新代码写入的数据。

那么向后兼容性呢？只要每一个字段都有一个唯一的标签号码，新代码就总可以读取旧数据，因为标签号码依旧有相同的含义。唯一的细节在于如果你添加一个新字段，你无法要求它是强制的。否则，强制检查会失败，因为就代码不会写你新添加的字段。因而为了保持向后兼容性，每个模式定义初次部署之后添加的字段都必须是可选的，或者必须有默认值。

删除字段与添加字段类似，只是向前向后兼容性考虑反过来了。这意味着你只可以移除可选字段（强制字段不能被移除），也用用不能再使用同一个标签号码（因为有可能还有某处的数据包含旧的标签号码，而新代码必须忽略这个字段）。

#### 数据类型与模式定义演进

那改变字段的数据类型呢？这是由可能的——检查说明文档获取详细信息——但是有值丢失精度或者被截断的风险。举个例子，假设你把32位整型数变为64位整型数。新的代码可以很容易地读取旧代码写入地数据，因为解析器可以在缺失的位填入零。然而，如果就代码读取新代码写入的数据，旧代码仍然用32位变量储存值。如果解码后的64位值用32位放不下，它就会被截断了。

Protocol Buffers一个奇怪的细节是它没有链表或者数组数据类型，取而代之的是一个字段的`repeated`标记（它是与`required`和`optional`平齐的第三选项）。如你在图4-4中看到的，`repeated`字段的编码正如它的字面意思：条目中同一个字段标签出现了多次。这样做有一个不错的效果，就是可以把`optional`（单值）字段变成一个`repeated`（多值）字段。新代码读取旧数据看到的是一个有着零或一个元素的链表（取决于字段是否出现）；旧代码读取新数据只看到链表的最后一个元素。

Thrift有专门的链表数据类型，它可以被链表元素的数据类型参数化。类似Protocol Buffers的单值到多值演化是不允许的，但是它有它的优势：支持嵌套的链表。

### Avro

Apache Avro是另外一种二进制编码格式，与Protocol Buffers以及Thrift不同。作为Hadoop的子项目它启动于2009年，原因是Thrift不适合Hadoop的使用场景。

Avro也使用模式定义指明被编码数据的结构。它有两种模式定义语言：一种（Avro接口定义语言）是为了方便人们编辑，另一种（基于JSON）机器读取时更容易。

我们的示例模式定义，用Avro接口定义语言写的话，大概是这个样子的：

```Avro
record Person {
    string                  userName;
    union { null, long }    favoriteNumber = null;
    array<string>           interests;
}

```

与这个模式定义等价的JSON表示如下：

```JSON
{
    "type": "record",
    "name": "Person",
    "fields": [
        {"name": "userName",       "type": "string"},
        {"name": "favoriteNumber", "type": ["null", "long"], "default": null},
        {"name": "interests",      "type": {"type": "array", "items": "string"}}
    ]
}
```

首先，注意模式定义中没有标签号码。如果用这个模式定义编码示例条目（示例4-1），Avro二进制编码只有32个字节长——所有我们看到的编码中最紧凑的。编码后的字节序列的拆解如图4-5所示。

如果仔细检查字节序列，你会发现没有信息表示字段或是字段数据类型。编码只是简单地把值连接在了一起。字符串只是长度前缀外跟UTF-8字节，但是编码后地数据中没有信息告诉你这是一个字符串。它也可以是一个整型数，或者完全另外一个东西。整型数使用的是变长编码（这与Thrift的CompactProtocol一致）。

*图4-5 用Avro编码的示例条目*

为了解析二进制数据，按它们在模式定义中的次序遍历所有字段，然后使用模式定义告诉你每个字段的数据类型。这意味着二进制数据只有在读取数据的代码使用写入数据代码使用的一摸一样的模式定义才能正确解码。任何读写模式定义的不匹配都意味着解码错误。

那么Avro如何支持模式定义演进呢？

#### 写者模式定义与读者模式定义

在Avro，当应用想要编码某些数据时（把它写入到文件或者数据库，通过网络把它发送出去，等等），它使用它知道的任意版本的模式定义编码数据——比如说，编译到应用内部的模式定义。这叫做写者模式定义。

当应用要解码某些数据时（从文件或者数据库中读取，从网络上获得，等等），我们希望数据是符合某种模式定义的，它被称为读者模式定义。这是应用代码依赖的模式定义——代码也许是应用构建过程中由模式定义生成的。

Avro的核心思想是写者模式定义与读者模式定义不必完全相同——它们只需要兼容。当数据被解码（被读取）时，Avro库通过比对写者模式定义与读者模式定义解析差异，然后把数据从写者模式定义转化为读者模式定义。Avro的规范明确定义了解析如何工作，如图4-6所示。

举个例子，写者模式定义与读者模式定义的字段顺序不同是不会有问题的，因为模式定义解析通过字段名匹配。如果读取数据的代码遇到了一个出现在写者模式定义但是读者模式定义没有的字段，就忽略它。如果读取数据的代码期望某个字段，但是写者模式定义不包含名称对应的字段，那么字段会被填入读者模式定义声明的默认值。

*图4-6 Avro读者解析写者模式定义与读者模式定义*

#### 模式定义演进规则

在Avro，向前兼容意味着可以有新版本的模式定义作为写者，而旧版本的模式定义作为读者。相反的，向后兼容意味着可以有新版本的模式定义作为读者，而旧版本的作为写者。

为了维持兼容性，你只能添加或者删除有默认值的字段。（在示例的Avro模式定义中字段`favoriteNumber`有默认值为`null`。）举个例子，假设你添加一个有默认值的字段，那么这个新字段在新模式定义中存在而旧的没有。当读者用新模式定义读取用旧模式定义写入的记录，缺少的字段将填入默认值。

如果要添加一个没有默认值的字段，新的读者没有能力读取旧写者写入的数据，于是破坏了向后兼容性。如果删除了一个没有默认值的字段，旧的读者没有能力读取新写者写入的数据，于是破坏了向前兼容性。

在一些编程语言中，`null`是任意变量都可以接受的默认值，但是对于Avro来说不是的：如果要允许一个字段为空，你必须用*联合类型*。举个例子，`union { null, long, string } field;`表示这个字段可以是数字，字符串，或者空。只有在它是联合中的一个分支时你才可以用`null`作为默认值。这比所有字段都可以默认为空要冗余了些，但是通过明确什么可以为空什么不可以达到了防止错误的目的。

结果是，Avro没有Protocol Buffers和Thrift中有的`optional`和`required`标记（取而代之的是联合类型与默认值）。

改变字段的数据类型是可能的，前提是Avro可以转换这个类型。改变字段的名称是可能的，但是稍微复杂一些：读者的模式定义可以包含字段名称的别名，于是可以把旧写者的模式定义名称与这些别名匹配。这意味改变字段名称是向后兼容的，但不是向前兼容的。类似的，添加一个分支到联合类型是向后兼容但不是向前兼容的。

#### 但是，什么是写者模式定义？

有一个重要问题之前被我们一边带过：读者是怎么知道编码特定数据的写者模式定义的？我们不可能把整个模式定义包含在每条记录里，因为模式定义很可能比编码后的数据大多了，使得所有由于二进制编码而节省下来的空间都白费了。

答案取决于使用Avro的上下文。下面给出了一些例子：

*有许多条记录的大文件*

Avro的一种常见使用方式——尤其是在Hadoop上下文中——是用来存储包含上百万条记录的大文件，这些记录都用同样的模式定义进行了编码。（我们将在第十章讨论这种情况。）在这种情况下，文件的写者只用在文件开头包含一次写者模式定义。Avro定义了一个文件格式（对象容器文件）来做这件事。

*包含独立写入记录的数据库*

在数据库中，不同的记录也许是用不同写者模式定义在不同的时间点写入的——你不能假设所有的记录都有同样的模式定义。最简单的解决办法是在每条编码记录前加上版本号，同时在数据库中保存模式定义版本列表。读者能获取一条记录，抽取版本号，然后从数据库中获取对应的写者模式定义。使用这个写者模式定义，它可以解码其余的记录。（比如说，Espresso就是这样工作的。）

*通过网络连接发送记录*

当两个进程通过双向网络连接通信时，它们可以在建立连接时协商模式定义版本，之后在这个连接生命周期内使用这个定义。Avro远程过程调用协议（见“TODO：透过服务的数据流：REST和RPC”）是这样工作的。

任何情况下数据库的模式定义版本都是有用的，因为它就像说明文档，给机会检查模式定义兼容性。作为版本号，你可以使用简单的自增整型数，或者使用模式定义的哈希值。

#### 动态生成的模式定义

相比于Protocol Buffers和Thrift，Avro方式的优势是模式定义不包含任何标签号码。但是为什么这很重要呢？在模式定义中保留几个号码有什么问题呢？

差别在于Avro对动态生成的模式定义更加友好。举个例子，假设有一个关系型数据库，想把内容导出到文件，而且想用二进制格式从而避免文本格式（JSON、CSV、SQL）前面提到的问题。如果用Avro，从关系型模式定义生成Avro模式定义（用先前看到的JSON表现形式）是相当简单的，再用这个模式定义编码数据库内容，并导出到Avro对象容器文件。每个数据库表生成一个记录模式定义，而每个列变成了记录中的一个字段。数据库中列的名字对应成为了Avro中的字段名字。

现在，假如数据库模式定义变了（比如，表中添加了一列又删除了一列），你只需要从更新了的数据库模式定义生成一个新的Avro模式定义，然后用新的Avro模式定义导出数据。数据导出过程不需要关心模式定义的变化——只是每次运行简单地做模式定义转换。任何读取新数据文件的人将看到记录的字段发生了变化，然而由于字段是通过名字标记的，更新了的写者模式定义仍然可以与旧的读者定义匹配。

相比之下，如果用Thrift或者Protocol Buffers，字段标签很可能需要手动分配：每一次数据库模式定义变化的时候，管理员必须手动更新从数据库列名称到字段标签的映射关系。（这个过程有可能可以自动化，但是模式定义生成器必须非常小心，不能分配先前使用过的字段标记。）这种动态生成的模式定义不是Thrift或者Protocol Buffers的设计目标，但是是Avro的。

#### 代码生成与动态类型语言

Thrift与Protocol Buffers依赖代码生成：模式定义完毕之后，可以用你选择的编程语言生成实现了这个模式定义的代码。这对于比如Java、C++或C#之类的静态类型语言很有用，因为它可以使用高效的内存结构储存解码后的数据，在编写访问数据结构的代码时也使IDE中的类型检查与自动完成可用。

在类似JavaScript、Ruby或Python的动态类型语言中，代码生成就没有太大意义了，因为没有编译时类型检查问题。代码生成在这些语言中经常被忽视，因为它们明确地不需要编译这一步。此外，对于动态生成的模式定义（比如从数据库表中生成的Avro模式定义），代码生成对于获取数据来说完全没有必要。

虽然Avro对静态类型编程语言提供了可选的代码生成功能，但是没有它也可以良好工作。如果你有一个对象容器文件（其中嵌入了写者的模式定义），你可以用Avro库打开它然后用看JSON文件的同样方式看这些数据。这个文件是自描述的，因为它包含了所有必须的元数据。

这个特性在结合例如Apache Pig这样的动态类型数据处理语言时特别有用。在Pig中，你只需要打开Avro文件，开始分析它们，然后用Avro格式写出导出的数据集到输出文件而完全不用在意模式定义。

### 模式的优点

如我们所见，Protocol Buffers、Thrift以及Avro都使用模式定义来描述二进制编码格式。它们的模式定义语言要比XML模式或是JSON模式简单得多，后者支持许多细节验证规则（比如，“这个字段的字符串值必须符合这个正则表达式”或者“这个字段的整型数值必须在0到100之间”）。由于Protocol Buffers、Thrift以及Avro实现简单用起来也简单，它们已经支持了相当多数的编程语言。

这些编码所基于的理念绝非新鲜。举个例子，它们与ASN.1，一种在1984年首次标准化了的模式定义语言，有许多共同点。它被用来定义了许多网络协议，比如它的二进制编码（DER）仍然被用来编码SSL证书（X.509）。ASN.1通过标签号码支持模式演进，这与Protocol Buffers以及Thrift类似。然而，它也很复杂，文档很差，所以ASN.1也许对于新的应用来说不是一个很好的选择。

许多数据系统也为它们的数据实现了某些专有二进制编码。比如说，绝大部分关系型数据库都定义了网络协议，通过它可以发送查询请求到数据库并获取响应。这些协议通常是针对特定数据库的，而数据库厂商提供驱动（比如通过ODBC或者JDBC的API）把来自数据库网络协议的响应解码为内存数据结构。

所以，我们看到虽然文本的数据格式例如JSON、XML以及CSV被广泛使用，基于模式定义的二进制编码也是一个可选项。它们有一些不错的特性：

* 它们比诸多“二进制JSON”变种要紧凑得多，因为它们在编码后的数据中忽略字段名。

* 模式定义是有价值的文档形式，由于解码时模式定义是必须的，你可以确定它一定是最新的（而人为维护的文档很容易与实际情况不符）。

* 保存模式定义的数据库方便在部署任何东西之前检查模式定义变更的向前与向后兼容性。

* 对于静态类型编程语言的用户，从模式定义生成代码的功能很有用，因为它允许在编译时进行类型检查。

In summary, schema evolution allows the same kind of flexibility as schemaless/ schema-on-read JSON databases provide (see “Schema flexibility in the document model”), while also providing better guarantees about your data and better tooling.

总的来说，模式定义演进提供了与无模式定义/读时模式定义JSON数据库提供的同等灵活性（见“文档模型中的模式定义灵活性”），同时提供了数据更好保证以及更好的工具。