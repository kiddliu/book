# 第十二章 数据系统的未来

一個以他物為目的者，其最後目的不可能在於保存其自身之存在。為此，舵手不是以保存船為其最後目的，因為船有別的目的，即是為了航行。

（常被引作：如果一个船长的最高目标是保护他的船只，那么他就会让他的船永远停在港口。）

托马斯·阿奎那，*神学大全*（1265-1274）

---

到目前为止，这本书主要是描述事物的*现状*。在这最后一章中，我们将把视角转向未来，讨论事情*应该*是什么样子的：我会提出一些想法和方法，我相信，它们可能会从根本上改进我们设计和构建应用程序的方式。

对未来的看法和猜测当然是主观的，所以我将用本章的第一人称来写我的个人观点。欢迎你反对这些意见并形成你自己的，但我希望这一章中的想法至少能成为富有成效的讨论的起点，并且使经常被混淆的概念更加清晰。

我们在第1章概述了这本书的目标：探讨如何创建*可靠的*、*可扩展的*以及*可维护的*应用与系统。这些主题贯穿了所有章节：例如，我们讨论了许多提升可靠性的容错算法，分区提高可扩展性，以及用于提高可维护性的演进抽象机制。在这一章中，我们将把所有这些想法结合起来，并基于它们展望未来。我们的目标是发现如何设计比今天更好的应用程序——健壮、正确、可演化、最终对人类有益。

## 数据集成

本书中反复出现的一个主题是对于任何给定的问题，都有几种解决方案，它们都有不同的利弊以及取舍。举个例子，在第三章讨论存储引擎时，我们看到了日志结构存储、B树以及面向列的存储。在第五章中讨论复制时，我们看到了单主机、多主机，以及无主机的方法.

如果你有一个比如“我想存储一些数据，之后可以再查找它”的问题，是没有一个正确的解决方案，不同的方法适用于不同的情况。软件实现通常需要选择一种特定的方法。让一个代码路径既坚固又性能良好太难了——在一个软件中尝试做所有的事情几乎可以确保实现会很差。

因此，软件工具的最合适的选择也取决于环境。每款软件，甚至是一个所谓的“通用”数据库，都是为特定的使用模式而设计的。

面对如此众多的备选方案，第一个挑战是找出软件产品与适用环境之间的映射关系。可以理解的是，供应商不愿意告诉你他们的软件不适合的工作负载类型，但是希望前几章已经为你提供了一些问题，以便对其检视，并更好地理解两者之间的取舍。

然而，即使您完全理解了工具和适用它们的环境之间的映射，还有另一个挑战：在复杂的应用中，数据通常以几种不同的方式使用。不太可能有一个软件适合数据使用的*所有*情况，因此你最终不可避免地要拼凑几个不同的软件来提供应用程序的功能。

### 通过衍生数据组合专用的工具

例如，为了处理对任意关键字的查询，常常需要把OLTP数据库与全文搜索索引集成起来。虽然有些数据（比如PostgreSQL）包含对于简单应用足够了的全文索引功能，但是更复杂的搜索工具需要专门的信息检索工具。相反地，搜索索引通常不太适合作为持久的记录系统，因此许多应用程序需要组合两个不同的工具来满足所有的需求。

我们讨论了在“保持系统同步”一节中涉及了集成数据系统的问题。随着数据不同表示方式数量的增加，集成问题变得更加困难。除了数据库和搜索索引之外，您可能还需要在分析系统（数据仓库、批处理以及流处理系统）中保存数据的副本；维护缓存或是从原始数据派生的非规范化版本；通过机器学习、分类、排名或推荐系统传递数据；或者根据对数据的更改发送通知。

令人惊讶的是，我经常看到软件工程师说这样的话：“根据我的经验，99%的人只需要X”或是“…不需要X”（对于X的各种值）。我认为这样的话更多地反映了发言者的经验，而不是一项技术的实际用途。你想要用数据做的不同的事情的范围是非常广的。一个人认为是模糊的、毫无意义的特性很可能是另一个人的中心要求。数据集成的需求通常只有在放大并且考虑整个组织的数据流时才会变得明显。

#### 数据流的推理

当需要在多个存储系统中维护数个相同数据的副本以满足不同的访问模式时，您需要非常清楚地了解输入和输出：数据首先写入到了哪里，哪一种呈现形式衍生自哪个源？如何用正确的格式把数据存入所有正确的位置？

举个例子，您可以把数据先写入记录数据库系统，捕获对该数据库所做的便跟（见“变更数据捕获”一节），然后以相同的顺序把变更应用于搜索索引。如果变更数据捕获（CDC）是更新索引的唯一方法，您可以确信索引完全衍生自记录系统，并因此与它保持一致（排除软件中的错误）。写入数据库是向这个系统提供新输入的唯一途径。

允许应用程序同时直接写入搜索索引和数据库带来了图11-4中的问题，在那里两个客户端并发发送相互冲突的写入，而两个存储系统以不同的顺序处理它们。在这种情况下，数据库与搜索索引都不“负责”判定写入的顺序，因此它们会做出相互矛盾的决定，从而变得永远不一致。

如果你可以引导所有的用户输入到一个可以决定所有写入顺序的系统，那么按照相同顺序处理写入就可以更容易地导出数据的其他表示形式。这是我们在“全序广播”一节中见到过的状态机复制方法的一个应用。无论你是使用变更数据捕获还是事件溯源日志，都不如简单地确定全序原则那么重要。

基于事件日志的衍生数据系统的更新通常具有确定性和幂等性（见“幂等性”一节），因此很容易从故障中恢复。

#### 衍生数据 vs 分布式事务

保持不同数据系统相互一致的经典方法涉及分布式事务，正如“原子提交与两阶段提交（2PC）”一节中所讨论的那样。与分布式事务相比，那么使用派生数据系统的方式如何呢？

在抽象的层面上，它们通过不同的方式实现了相似的目的。分布式事务通过使用锁进行互斥来决定写入的顺序（见“两阶段锁定（2PL）”一节），而CDC以及事件溯源使用日志进行排序。分布式事务使用原子提交来确保更改只发生一次，而基于日志的系统通常是基于确定性重试以及幂等性。

它们最大的区别是事务系统通常提供可线性化（见“可线性化”一节），这意味着支持读取自己的写入这样的有用的保证（见“读取自己的写入”一节）。另一方面，派生数据系统通常是异步更新的，因此在默认情况下它们是不提供相同的时机保证的。

在有限的愿意支付分布式事务成本的环境中，它们的应用十分成功。但是，我认为XA的容错性与性能特性很差（见“实践中的分布式事务”一节），这极大限制了它的实用性。我相信为分布式事务构建一个更好的协议是可能的，但要让这样的协议被广泛采用，并且与现有工具集成起来将会是一项挑战，不太可能很快地实现。

在缺乏对好的分布式事务协议有广泛支持的情况下，我认为基于日志的衍生数据是集成不同数据系统最有希望的方法。然而，保证诸如读取自己的写入是有用的，并且我不认为告诉每个人“最终的一致性是不可避免的——接受它并学会应对它”（至少在没有好的指导如何处理它的情况下）是有效果的。

在“着眼正确性”一节中，我们将讨论在异步衍生系统之上实现更强保证的一些方法，并努力在分布式事务以及基于异步日志的系统之间找到一个中间地带。

#### 全序的限制

对于规模足够小的系统，构建一个全序的事件日志是完全可行的（具有单主机复制的数据库的流行就是很好的证明，它正式构建了这种日志）。然而，随着系统向更大和更复杂的工作负载扩展，限制开始显现出来：

* 在大多数情况下，构建一个全序的日志需要所有事件通过一个决定排序的*单主机节点*。如果事件的吞吐量大于单台设备能够处理的吞吐量，就需要对它进行分区，分散在多台设备上（见“分区日志”一节）。这样，两个不同分区中的事件顺序就不明确了。

* 如果服务器*分布在多个不同地理位置*的数据中心，比如是为了容忍整个数据中心离线，那么你通常在每个数据中心都有一个单独的主机，因为网络延迟会使得同步的跨数据中心的协调工作效率低下（见“多主机复制”一节）。这意味着来自两个不同数据中心的事件之间的顺序没有定义。

* 当应用被部署为*微服务*（见“服务的数据流：REST与RPC”)时，常见的设计选择是把每个服务及其持久状态部署为一个独立的单元，服务与服务之间不共享持久状态。当两个事件来自不同的服务时，这些事件没有定义好的顺序。

* 有些应用程序在用户输入时立即更新客户端状态（没有等待服务器确认），甚至可以继续离线工作（见“有离线操作的客户端”一节）。有了这样的应用程序，客户端与服务器很可能会看到不同顺序的事件。

用正式的术语来讲，确定事件的全序叫做*全序广播*，它与协商一致等价（见“协商一致算法与全序广播”一节）。大多数协商一致的算法都是针对单个节点的吞吐量足以处理整个事件流的情况设计的，而且这些算法没有提供多个节点共享事件排序结果的机制。设计可以扩展到单个节点的吞吐量之外，并且在地理分布的环境中运行良好的协商一致的算法仍然是一个开放性的研究问题。

#### 对时间排序以获取因果关系

在事件之间没有因果关系的场景下，全序的缺失并不是一个大问题，因为并发事件可以任意地排序。其他一些情况也很容易处理：比如说当同一个对象有多个更新时，可以通过把针对特定对象ID的所有更新导向同一个日志分区来进行完全排序。然而，因果依赖关系有时以更微妙的方式出现（见“排序与因果关系”一节）。

举个例子，设想一个社交网络服务，以及两个刚刚分手的用户。其中一个用户将另一个用户移除了好友，然后向其余的朋友发送一条信息，抱怨TA的前任。用户的意愿是，他们的前伴侣不应该看到这条粗鲁的信息，因为这条消息是在朋友身份被撤销之后发送的。

但是如果关系状态存储在一个地方，而信息储存在另外一个地方，那么*取消好友*事件与*发送消息*事件之间的顺序依赖关系可能会丢失。如果没有办法获取因果相关性，那么发送新消息的通知服务可能会在*取消好友*事件之前处理*发送消息*事件，这样就会错误地向前任推送通知。

在这个例子中，通知实际上是消息与好友列表之间的连接，使得它与前面讨论到的连接的时机问题有关（见“连接的时间依赖性”一节）。然而，对于这个问题似乎没有一个简单的答案。解决问题的出发点包括：

* 逻辑时间戳可以在没有协调的情况下提供全序（见“序号排序”一节），因此可以在全序广播不可行的情况下有所帮助。然而它们仍然要求接收方可以处理乱序的事件，并且需要传递额外的元数据。

* 如果您可以写一个事件日志来记录用户在作出决定之前看到的系统状态，并给这个事件一个唯一的标识符，那么之后的任何事件都可以引用这个事件标识符，从而记录因果依赖关系。我们会在“阅读也是事件”一节中回到这个想法。

* 冲突解决算法（见“自动化解冲突”一节）有助于处理以意外顺序传递的事件。它们对于维护状态是有用的，但是如果操作有外部副作用（比如向用户推送通知）就没有办法了。

也许随着时间的推移，会出现可以有效获取因果以来关系的应用开发的模式，并且可以正确地维护衍生的状态，而不会强迫所有事件都必须经过全序广播的瓶颈。

### 批处理与流处理

我认为数据集成的目标是确保数据最终以正确的形式出现在正确的地方。这样做需要消耗输入、转换、连接、过滤、聚合、训练模型、评估，然后最终写入适当的输出。批处理器与流处理器是实现这一目标的工具。

批处理和流过程的输出是衍生的数据集，比如搜索索引、物化视图、显示给用户的推荐、聚合指标，等等等等（见“批处理工作流的输出”与“流处理的使用”小节）。

正如我们在第10章和第11章中所看到，批处理与流处理有许多共同的原理，而根本区别在于流处理器工作在无界数据集上，而批处理过程输入的大小是有限已知的。在处理引擎的实现方式上也有许多细节上的差异，但这些差别越来越模糊了。

Spark通过把流分解成微型批次，在批处理引擎上执行流处理，而Apache Flink在流处理引擎上执行批处理。原则上，一种类型的处理可以用另一种进行模拟，尽管性能特性各不相同：比如说，微批处理在跳变或滑动窗口上的性能可能很差。