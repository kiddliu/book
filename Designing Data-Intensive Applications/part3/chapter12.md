# 第十二章 数据系统的未来

一個以他物為目的者，其最後目的不可能在於保存其自身之存在。為此，舵手不是以保存船為其最後目的，因為船有別的目的，即是為了航行。

（常被引作：如果一个船长的最高目标是保护他的船只，那么他就会让他的船永远停在港口。）

托马斯·阿奎那，*神学大全*（1265-1274）

---

到目前为止，这本书主要是描述事物的*现状*。在这最后一章中，我们将把视角转向未来，讨论事情*应该*是什么样子的：我会提出一些想法和方法，我相信，它们可能会从根本上改进我们设计和构建应用程序的方式。

对未来的看法和猜测当然是主观的，所以我将用本章的第一人称来写我的个人观点。欢迎你反对这些意见并形成你自己的，但我希望这一章中的想法至少能成为富有成效的讨论的起点，并且使经常被混淆的概念更加清晰。

我们在第1章概述了这本书的目标：探讨如何创建*可靠的*、*可扩展的*以及*可维护的*应用与系统。这些主题贯穿了所有章节：例如，我们讨论了许多提升可靠性的容错算法，分区提高可扩展性，以及用于提高可维护性的演进抽象机制。在这一章中，我们将把所有这些想法结合起来，并基于它们展望未来。我们的目标是发现如何设计比今天更好的应用程序——健壮、正确、可演化、最终对人类有益。

## 数据集成

本书中反复出现的一个主题是对于任何给定的问题，都有几种解决方案，它们都有不同的利弊以及取舍。举个例子，在第三章讨论存储引擎时，我们看到了日志结构存储、B树以及面向列的存储。在第五章中讨论复制时，我们看到了单主机、多主机，以及无主机的方法.

如果你有一个比如“我想存储一些数据，之后可以再查找它”的问题，是没有一个正确的解决方案，不同的方法适用于不同的情况。软件实现通常需要选择一种特定的方法。让一个代码路径既坚固又性能良好太难了——在一个软件中尝试做所有的事情几乎可以确保实现会很差。

因此，软件工具的最合适的选择也取决于环境。每款软件，甚至是一个所谓的“通用”数据库，都是为特定的使用模式而设计的。

面对如此众多的备选方案，第一个挑战是找出软件产品与适用环境之间的映射关系。可以理解的是，供应商不愿意告诉你他们的软件不适合的工作负载类型，但是希望前几章已经为你提供了一些问题，以便对其检视，并更好地理解两者之间的取舍。

然而，即使你完全理解了工具和适用它们的环境之间的映射，还有另一个挑战：在复杂的应用中，数据通常以几种不同的方式使用。不太可能有一个软件适合数据使用的*所有*情况，因此你最终不可避免地要拼凑几个不同的软件来提供应用程序的功能。

### 通过衍生数据组合专用的工具

例如，为了处理对任意关键字的查询，常常需要把OLTP数据库与全文搜索索引集成起来。虽然有些数据（比如PostgreSQL）包含对于简单应用足够了的全文索引功能，但是更复杂的搜索工具需要专门的信息检索工具。相反地，搜索索引通常不太适合作为持久的记录系统，因此许多应用程序需要组合两个不同的工具来满足所有的需求。

我们讨论了在“保持系统同步”一节中涉及了集成数据系统的问题。随着数据不同表示方式数量的增加，集成问题变得更加困难。除了数据库和搜索索引之外，你可能还需要在分析系统（数据仓库、批处理以及流处理系统）中保存数据的副本；维护缓存或是从原始数据派生的非规范化版本；通过机器学习、分类、排名或推荐系统传递数据；或者根据对数据的更改发送通知。

令人惊讶的是，我经常看到软件工程师说这样的话：“根据我的经验，99%的人只需要X”或是“…不需要X”（对于X的各种值）。我认为这样的话更多地反映了发言者的经验，而不是一项技术的实际用途。你想要用数据做的不同的事情的范围是非常广的。一个人认为是模糊的、毫无意义的特性很可能是另一个人的中心要求。数据集成的需求通常只有在放大并且考虑整个组织的数据流时才会变得明显。

#### 数据流的推理

当需要在多个存储系统中维护数个相同数据的副本以满足不同的访问模式时，你需要非常清楚地了解输入和输出：数据首先写入到了哪里，哪一种呈现形式衍生自哪个源？如何用正确的格式把数据存入所有正确的位置？

举个例子，你可以把数据先写入记录数据库系统，捕获对该数据库所做的便跟（见“变更数据捕获”一节），然后以相同的顺序把变更应用于搜索索引。如果变更数据捕获（CDC）是更新索引的唯一方法，你可以确信索引完全衍生自记录系统，并因此与它保持一致（排除软件中的错误）。写入数据库是向这个系统提供新输入的唯一途径。

允许应用程序同时直接写入搜索索引和数据库带来了图11-4中的问题，在那里两个客户端并发发送相互冲突的写入，而两个存储系统以不同的顺序处理它们。在这种情况下，数据库与搜索索引都不“负责”判定写入的顺序，因此它们会做出相互矛盾的决定，从而变得永远不一致。

如果你可以引导所有的用户输入到一个可以决定所有写入顺序的系统，那么按照相同顺序处理写入就可以更容易地导出数据的其他表示形式。这是我们在“全序广播”一节中见到过的状态机复制方法的一个应用。无论你是使用变更数据捕获还是事件溯源日志，都不如简单地确定全序原则那么重要。

基于事件日志的衍生数据系统的更新通常具有确定性和幂等性（见“幂等性”一节），因此很容易从故障中恢复。

#### 衍生数据 vs 分布式事务

保持不同数据系统相互一致的经典方法涉及分布式事务，正如“原子提交与两阶段提交（2PC）”一节中所讨论的那样。与分布式事务相比，那么使用派生数据系统的方式如何呢？

在抽象的层面上，它们通过不同的方式实现了相似的目的。分布式事务通过使用锁进行互斥来决定写入的顺序（见“两阶段锁定（2PL）”一节），而CDC以及事件溯源使用日志进行排序。分布式事务使用原子提交来确保更改只发生一次，而基于日志的系统通常是基于确定性重试以及幂等性。

它们最大的区别是事务系统通常提供可线性化（见“可线性化”一节），这意味着支持读取自己的写入这样的有用的保证（见“读取自己的写入”一节）。另一方面，派生数据系统通常是异步更新的，因此在默认情况下它们是不提供相同的时机保证的。

在有限的愿意支付分布式事务成本的环境中，它们的应用十分成功。但是，我认为XA的容错性与性能特性很差（见“实践中的分布式事务”一节），这极大限制了它的实用性。我相信为分布式事务构建一个更好的协议是可能的，但要让这样的协议被广泛采用，并且与现有工具集成起来将会是一项挑战，不太可能很快地实现。

在缺乏对好的分布式事务协议有广泛支持的情况下，我认为基于日志的衍生数据是集成不同数据系统最有希望的方法。然而，保证诸如读取自己的写入是有用的，并且我不认为告诉每个人“最终的一致性是不可避免的——接受它并学会应对它”（至少在没有好的指导如何处理它的情况下）是有效果的。

在“着眼正确性”一节中，我们将讨论在异步衍生系统之上实现更强保证的一些方法，并努力在分布式事务以及基于异步日志的系统之间找到一个中间地带。

#### 全序的限制

对于规模足够小的系统，构建一个全序的事件日志是完全可行的（具有单主机复制的数据库的流行就是很好的证明，它正式构建了这种日志）。然而，随着系统向更大和更复杂的工作负载扩展，限制开始显现出来：

* 在大多数情况下，构建一个全序的日志需要所有事件通过一个决定排序的*单主机节点*。如果事件的吞吐量大于单台设备能够处理的吞吐量，就需要对它进行分区，分散在多台设备上（见“分区日志”一节）。这样，两个不同分区中的事件顺序就不明确了。

* 如果服务器*分布在多个不同地理位置*的数据中心，比如是为了容忍整个数据中心离线，那么你通常在每个数据中心都有一个单独的主机，因为网络延迟会使得同步的跨数据中心的协调工作效率低下（见“多主机复制”一节）。这意味着来自两个不同数据中心的事件之间的顺序没有定义。

* 当应用被部署为*微服务*（见“服务的数据流：REST与RPC”)时，常见的设计选择是把每个服务及其持久状态部署为一个独立的单元，服务与服务之间不共享持久状态。当两个事件来自不同的服务时，这些事件没有定义好的顺序。

* 有些应用程序在用户输入时立即更新客户端状态（没有等待服务器确认），甚至可以继续离线工作（见“有离线操作的客户端”一节）。有了这样的应用程序，客户端与服务器很可能会看到不同顺序的事件。

用正式的术语来讲，确定事件的全序叫做*全序广播*，它与协商一致等价（见“协商一致算法与全序广播”一节）。大多数协商一致的算法都是针对单个节点的吞吐量足以处理整个事件流的情况设计的，而且这些算法没有提供多个节点共享事件排序结果的机制。设计可以扩展到单个节点的吞吐量之外，并且在地理分布的环境中运行良好的协商一致的算法仍然是一个开放性的研究问题。

#### 对时间排序以获取因果关系

在事件之间没有因果关系的场景下，全序的缺失并不是一个大问题，因为并发事件可以任意地排序。其他一些情况也很容易处理：比如说当同一个对象有多个更新时，可以通过把针对特定对象ID的所有更新导向同一个日志分区来进行完全排序。然而，因果依赖关系有时以更微妙的方式出现（见“排序与因果关系”一节）。

举个例子，设想一个社交网络服务，以及两个刚刚分手的用户。其中一个用户将另一个用户移除了好友，然后向其余的朋友发送一条信息，抱怨TA的前任。用户的意愿是，他们的前伴侣不应该看到这条粗鲁的信息，因为这条消息是在朋友身份被撤销之后发送的。

但是如果关系状态存储在一个地方，而信息储存在另外一个地方，那么*取消好友*事件与*发送消息*事件之间的顺序依赖关系可能会丢失。如果没有办法获取因果相关性，那么发送新消息的通知服务可能会在*取消好友*事件之前处理*发送消息*事件，这样就会错误地向前任推送通知。

在这个例子中，通知实际上是消息与好友列表之间的连接，使得它与前面讨论到的连接的时机问题有关（见“连接的时间依赖性”一节）。然而，对于这个问题似乎没有一个简单的答案。解决问题的出发点包括：

* 逻辑时间戳可以在没有协调的情况下提供全序（见“序号排序”一节），因此可以在全序广播不可行的情况下有所帮助。然而它们仍然要求接收方可以处理乱序的事件，并且需要传递额外的元数据。

* 如果你可以写一个事件日志来记录用户在作出决定之前看到的系统状态，并给这个事件一个唯一的标识符，那么之后的任何事件都可以引用这个事件标识符，从而记录因果依赖关系。我们会在“阅读也是事件”一节中回到这个想法。

* 冲突解决算法（见“自动化解冲突”一节）有助于处理以意外顺序传递的事件。它们对于维护状态是有用的，但是如果操作有外部副作用（比如向用户推送通知）就没有办法了。

也许随着时间的推移，会出现可以有效获取因果以来关系的应用开发的模式，并且可以正确地维护衍生的状态，而不会强迫所有事件都必须经过全序广播的瓶颈。

### 批处理与流处理

我认为数据集成的目标是确保数据最终以正确的形式出现在正确的地方。这样做需要消耗输入、转换、连接、过滤、聚合、训练模型、评估，然后最终写入适当的输出。批处理器与流处理器是实现这一目标的工具。

批处理和流过程的输出是衍生的数据集，比如搜索索引、物化视图、显示给用户的推荐、聚合指标，等等等等（见“批处理工作流的输出”与“流处理的使用”小节）。

正如我们在第10章和第11章中所看到，批处理与流处理有许多共同的原理，而根本区别在于流处理器工作在无界数据集上，而批处理过程输入的大小是有限已知的。在处理引擎的实现方式上也有许多细节上的差异，但这些差别越来越模糊了。

Spark通过把流分解成微型批次，在批处理引擎上执行流处理，而Apache Flink在流处理引擎上执行批处理。原则上，一种类型的处理可以用另一种进行模拟，尽管性能特性各不相同：比如说，微批处理在跳变或滑动窗口上的性能可能很差。

#### 维护衍生状态

批处理具有很强的函数式特色（哪怕代码不是用函数式编程语言编写的）：它鼓励确定性的纯函数，它的输出只依赖于输入，除了显式输出以外没有任何副作用，将输入视为不可变的，将输出视为附加的。流处理也类似，但是它扩展了运算符使得状态变得可以管理可以容错（见“失效之后重新构建状态”一节）。

有着定义良好的输入与输出的确定性函数原理不仅有利于容错（见“幂等性”一节），还简化了组织中对数据流的推理。无论衍生数据是搜索索引、统计模型还是缓存，把它想象成从一种事物衍生出另外一种的数据管道都是有益的，它可以把一个系统中的状态变更推送到函数式应用代码然后把这些效果应用到衍生系统。

原则上，衍生数据系统可以同步地维护，就像关系数据库在事务写入建立了索引的表的同时更新次级索引一样。然而，异步使基于事件日志的系统更加健壮：它允许在本地控制系统某一部分的故障，而在分布式事务中如果任何参与者失败，那么整个事务会中止，因此它们倾向通过把故障扩散到系统的其余部分来放大故障（见“分布式事务的限制”一节）。

我们在“分区和次级索引”一节中看到，辅助索引通常跨越了分区边界。具有辅助索引的分区系统要么需要向多个分区发送写入请求（如果索引是按词语分区的），要么需要发送读取请求到所有分区（如果索引是文档分区的）。哪怕索引是异步维护的，这种跨分区通信也是最可靠以及最可以扩展的（也见“多分区数据处理”一节）。

#### 针对应用演进重新处理数据

在维护衍生数据时，批处理和流处理都很有用。流处理可以很快地在衍生视图中反映输入的变化，而批处理可以重新处理大量累积的历史数据，从而把新的视图衍生到现有的数据集上。

特别的是，重新处理现有数据提供了维护系统一个良好的机制，使它可以支持新的特性以及变更了的需求（见第4章）。如果没有重新处理，模式定义的演进会仅限于简单的更改，比如向记录添加一个新的可选字段，或者添加一种新的记录类型。无论是在写时模式还是读式模式都是如此（见“文档模型中模式的灵活性”一节）。另一方面，通过重新处理，可以把数据集重构为一个完全不同的模型，以便更好地满足新的需求。

> **铁路领域的“模式迁移”**
>
> 大规模的“模式迁移”也发生在计算机外的其它系统中。例如，在19世纪英国修建铁路的早期，就有各种不同的轨距（两条铁轨之间的距离）标准相互竞争。为一个轨距而建的列车不能在另一个轨距的轨道上运行，这会限制铁路网中的互连。
>
> 在1846年最终确定了一种标准轨距之后，其他轨距的铁路必须进行转换——但是如何在不关闭铁路数个月甚至数年的情况下做到这一点呢？解决方案是通过添加第三条轨道先把轨道转换为双轨距或混合轨距。这个转换可以逐步完成，完成时，两个轨距的列车都可以在线路上运行，使用三条铁轨中的两条。最终，一旦所有列车都被转换成标准轨距，非标准轨距的铁轨就可以被拆除了。
>
> 以这种方式对现有轨道进行“再加工”，并允许新旧版本肩并肩地共存，使得有可能在几年内逐渐改变轨距。然而，这是一项昂贵的工程，这就是为什么今天仍然存在非标准量规的原因。例如，旧金山湾区的BART系统使用与美国大多数地区不同的量规。

衍生视图允许*渐进式*的演进。如果要重构数据集，你不需要突然切换执行迁移。取而代之的是，你可以同时维护新旧模式，视其为同一份底层数据的两个独立的衍生视图。之后，你可以开始把少量用户转移到新视图，用来测试其性能并发现任何bug，而大多数用户仍然被导向到旧视图。逐渐地，你可以增加用户访问新视图的比例，并最终可以放弃旧视图。

这种渐进迁移的美妙之处在于如果出现问题，那么这个过程的每个阶段都很容易回滚：你总可以回到一个可用的系统。通过减少不可逆损害的风险你可以更加自信地前进，从而可以更快地改进你的系统。

#### Lambda架构

如果批处理是用来重新处理历史数据，而流处理是用来处理最近的更新的，那么如何把二者结合起来？*lambda架构*是这个领域中引起广泛关注的一项建议。

Lambda架构的核心思想是，输入的数据应该通过把不可变的事件添加到不断增长的数据集中来记录，类似于事件溯源（见“事件溯源”一节）。从这些事件中，衍生出了为读取而优化的视图。Lambda架构建议并行运行两个不同的系统：一个批处理系统，比如Hadoop MapReduce，一个单独的流处理系统，比如Storm。

在lambda方法中，流处理器消费事件并快速生成视图的大致更新；批处理器稍后消费*相同*的事件集，并生成衍生视图的修正版本。这种设计背后的理由是，批处理更简单，因此不太容易出现bug，而流处理器被认为不太可靠，实现容错（见“容错”一节）更难。此外，流处理可以使用快速近似算法，而批处理过程使用较慢的精确算法。

Lambda架构是一个有影响力的想法，它改善了数据系统的设计，特别在推广在不可变事件流上衍生视图并且在需要的时候重新处理实践的原则方面。然而我也觉得它有一些现实的问题：

* 必须在批处理和流处理框架中维护相同的逻辑，这显然是额外的工作。虽然像Summingbird这样的库可以在批处理或流处理上提供抽象运算，但是调试、调优以及维护两个不同系统的运营复杂性仍然是存在的。

* 由于流管道和批处理管道产生独立的输出，因此在响应用户请求时需要合并它们。如果计算是一个翻滚窗口上的简单聚合，那么合并相当容易，但是如果视图是使用比如连接与会话化这样更复杂的操作衍生的，或者如果输出不是一个时间序列，它会变得非常困难。

* 尽管能够重新处理整个历史数据集是很棒的，但是在大型数据集上频繁这么做的代价是很高的。因此，通常需要设置批处理管道来处理增量批次（比如，在每个小时结束时处理一个小时的数据），而不是重新处理所有数据。这引发了在“时间的推理”一节中讨论的问题，比如处理散乱事件，以及处理跨越批次间边界的窗口问题。增量批处理计算增加了复杂性，使其更类似于流层，这与保持批处理层尽可能简单的目标背道而驰。

#### 统一批处理与流处理

更新进的工作通过允许在同一个系统中同时实现批计算（重新处理历史数据）以及流计算（在事件到达时处理它们），让我们在享受lambda架构带来的好处的同时避开了它的缺点。

把批处理和流处理统一在一个系统中需要下面这些越来越广泛应用的功能：

* 在处理新近事件流的引擎中处理历史事件的能力。例如，基于日志的消息代理有能力重播消息（见“重播旧消息”一节），而且一些流处理器可以从像HDFS这样的分布式文件系统中读取输入。

* 针对流处理器的精确一次语义——也就是，保证输出与没有任何故障发生的情况一致，哪怕事实上故障确实发生了（见“容错”一节）。与批处理一样，这要求丢弃任何失败任务的不完整输出。

按事件时间而不是按处理时间划分窗口工具，因为在重新处理历史事件时，处理时间是没有意义的（见“关于时间的推理”一节）。例如，Apache Beam提供了一个用于表示此类计算的API，这之后可以使用Apache Flink或是Google Cloud Dataflow运行这些计算。

## 拆散数据库

在最抽象的层次上，数据库、Hadoop以及操作系统都执行相同的功能：它们存储数据，并且允许你处理、查询这些数据。数据库把数据存在某种数据模型的记录中（比如表中的行，文档，图中的顶点），而操作系统的文件系统把数据存储在文件中——但是在核心部分，它们都是“信息管理”系统。正如我们在第10章中看到的，Hadoop生态系统有点像分布式版本的Unix。

当然，它们有许多实际的差别。比如，许多文件系统不能很好地处理有一千万个小文件的目录，而包含一千万条小记录的数据库则是再寻常不过的。然而，操作系统与数据库之间的异同是值得探讨的。

Unix与关系型数据库处理信息管理问题的哲学非常不同。Unix的目的是向程序员提供一个有逻辑但相当低级的硬件抽象层，而关系型数据库想要为应用开发者提供高级别的抽象，从而掩盖磁盘上数据结构的复杂性、并发问题、崩溃恢复等等。Unix开发出了管道和文件，它们只是些字节序列，而数据库开发出了SQL以及事务。

哪种方法更好？当然这取决于你想要什么。Unix“更简单”是因为它只是硬件资源的简单封装；关系型数据库“更简单”是因为一个简短的声明性查询语句可以利用许多强大的基础设施（查询优化、索引、连接方法、并发控制、复制，等等），而查询语句的作者不需要理解实现细节。

这两种哲学之间的矛盾已经持续了几十年（Unix与关系模型二者都出现在20世纪70年代初），至今尚未解决。例如，我会把NoSQL运动解释为希望将低级抽象这种Unix风格的方法应用于分布式OLTP数据存储领域。在这一节中，我将尝试调和这两种哲学，希望我们可以把这两个领域的优点结合起来。

### 数据存储技术的构成

在这本书展开的过程中，我们讨论了数据库提供的各种特性以及它们是如何工作的，包括：

* 次级索引，让你能够根据字段的值高效地搜索记录（见“其他索引结构”一节）

* 物化视图，是预先计算好的查询结果的缓存（见“聚合操作：数据立方体与物化视图”一节）

* 复制日志，让其他节点上的数据副本保持最新（见“复制日志的实现”一节）

* 全文搜索索引，允许在文本中搜索关键字（见“全文搜索与模糊索引”一节），这些索引被内置到了一些关系数据库中。

在第10章和第11章中，出现了类似的主题。我们讨论了构建全文搜索索引（见“批处理工作流的输出”一节）、物化视图维护（见“维护物化视图”一节）以及将变更从数据库复制到衍生数据系统（见“变更数据捕获”一节）。

看起来数据库中内建的特性与人们用批处理器和流处理器构建的衍生数据系统之间存在着相似之处。

#### 创建索引

想象一下在关系型数据库中执行`CREATE INDEX`创建新索引时会发生什么。数据库必须扫描表的一致性快照，选出所有要建立索引的字段值，对它们排序，然后写出索引。之后，它必须处理自获取一致性快照以来积累的写入请求（假设表在创建索引时没有被锁定，所以写入可以继续）。一旦完成之后，每当事务写入表时，数据库都必须保持索引的更新。

这个过程非常类似于设置一个新的从机副本（见“设置新的从机”一节），也非常类似于在流系统中引导启动变更数据捕获（见“初始快照”一节）。

无论何时运行`CREATE INDEX`，数据库基本上都会重新处理现有的数据集（就如“为应用演进而重新处理数据”一节中所讨论的那样），并且导出索引，这是基于现有数据的新视图。现有的数据可能是状态的快照，而不是曾经发生的所有变更的日志，但二者是密切相关的（见“状态、流与不可变性”一节）。

#### 所有事物的元数据库

有鉴于此，我认为穿过整个组织的数据流开始看起来像一个巨大的数据库。每当批处理、流处理或ETL处理将数据从一个位置的一种形式传输到另一个位置的另一种形式，它的作用就好像是数据库子系统，保持索引或是物化视图的更新。

这样看，批处理器与流处理器就像精心实现的触发器、存储过程和物化视图维护例程。它们维护的衍生数据系统类似于不同的索引类型。比如说，关系型数据库可能支持B树索引、哈希索引、空间索引（见“多列索引”一节），以及其他类型的索引。在新兴的衍生数据系统架构中，它们不再作为单一综合数据库产品的特性来实现这些能力，而是由各种不同的软件提供的，运行在不同的机器上，由不同的团队管理。

未来这些改进将带领我们走向何方？如果我们从没有任何一种访问模式适合所有的访问模式这一前提出发，我推测有两种途径可以把不同的存储与处理工具组合成一个统一的系统：

*联合数据库：将读取统一*

可以为各种各样的底层存储引擎与处理方法提供统一的查询接口是可行的，这种方法被称为*联合数据库*或*多存储区*。比如，PostgreSQL的外部数据包装功能符合这种模式。需要专用数据模型或是查询接口的应用程序仍然可以直接访问底层存储引擎，而希望组合来自不同地方数据的用户可以通过联合接口轻松地完成任务。联合查询接口遵循单一集成系统的关系传统，有高级查询语言以及优雅的语义，但实现复杂。

*拆散数据库: 将写入统一*

虽然联合解决了横跨几个不同系统的只读查询，但对于横跨这些系统同步写入却没有一个很好的解决方案。我们说过，在单个数据库中，创建一致性索引是内置的特性。当我们在组合几个存储系统时，我们同样需要确保所有的数据变更都发生在正确的地方，甚至在遇到故障时也是如此。让可靠地连接存储系统（比如通过更改数据捕获与事件日志）变得更容易，就像以一种可以同步跨不同技术的写入方式拆解数据库的索引维护功能一样。

这种拆解方法遵循Unix使用小工具的传统，它可以很好地完成一件事情，这些工具通过统一的低级别API（管道）进行通信，并且可以使用更高级别的语言（命令行）。

#### 使拆散工作

联合和拆解是同一枚硬币的两个面：用不同的组件组成一个可靠的、可扩展的和可维护的系统。联合的只读查询需要把一个数据模型映射到另一个数据模型，这需要一些思考，但最终是一个可管理的问题。我认为，保证对多个存储系统的写入是同步的是一个更困难的工程问题，所以我会重点讨论它。

同步写入的传统方法需要跨异构存储系统的分布式事务，我认为这是错误的解决方案（见“派生数据与分布式事务”一节）。在单个存储系统或是流处理系统中的事务是可行的，但是当数据跨越不同技术之间的边界时，我相信有着幂等写入的异步事件日志是一种更加健壮和实用的方法。

例如，在某些流处理器中用到分布式事务来实现精确一次语义（见“再回到原子提交的问题”一节），这可以很好地工作。然而当事务涉及到由不同组人编写的系统时（比如，当数据从流处理器写入分布式键值存储或搜索索引时），标准化事务协议的缺失使得集成变得更加困难。有着幂等消费者的有序事件日志（见“幂等性”一节）是个简单得多的抽象，因此在异构系统之间实现更加可行。

基于日志集成的最大优势在于各个组件之间的*松散耦合*，这体现在以下两方面：

1. 在系统级别上，异步事件流使整个系统作为一个整体，对各个组件的中断或是性能降级更加健壮。如果一个消费者运行缓慢或是失效，那么事件日志可以缓存消息（见“磁盘空间使用情况”一节），允许生产者与其他消费者继续运行，不受影响。出故障的消费者可以在修复后赶上，所以它不会遗漏任何数据，于是故障被控制住了。相反地，分布式事务的同步交互往往把本地故障提升为大规模失效（见“分布式事务的限制”一节）。

2. 在人的层面上，拆解数据系统允许不同的软件组件和服务由不同的团队独立地开发、改进和维护。专业化允许每个团队专注于做好一件事情，与其他团队的系统有定义良好的接口。事件日志提供了一个强大到足以捕获相当强的一致性属性的接口（由于事件的持久性以及顺序），但也具有足够的通用性，几乎适用于任何类型的数据。

#### 拆解的 vs 集成的系统

如果拆解确实会是未来的方式，它不会取代当前形式的数据库——对它们的需求仍将像以往一样。仍然需要数据库来维护流处理器中的状态，并且用来服务对批处理器和流处理器输出的查询（见“批处理工作流的输出”以及“流的处理”一节）。对于特定的工作负载，专用查询引擎仍然会很重要：比如说，MPP数据仓库中的查询引擎对探索性分析查询进行了优化，很好地处理了这种类型的工作负载（见“把Hadoop与分布式数据库进行比较”一节）。

运行几个不同的基础设施的复杂性会是一个问题：每个软件都有学习曲线、配置问题以及奇怪的操作，因此应当部署尽可能少的运动部件。相比于你用应用代码组合数个工具而成的系统，单个的集成软件产品也可以在为其设计的工作负载类型上获得更好更可预测的性能。正如我在序言中所说的，为你不需要的规模而构建系统浪费精力，并且把自己限制在一个不灵活的设计中。实际上，这是不成熟优化的一种形式。

拆解的目的不是在针对特定负载的性能上与独立数据库竞争；目标是通过组合几个不同的数据库，以便在更广泛的工作负载范围内获得比单个软件更好的性能。它是与广度相关的，而不是深度——与我们在“将Hadoop与分布式数据库进行比较”一节中讨论的存储与处理模型的多样性一脉相承。

因此，如果有单个技术可以满足你所需要的一切，那么你最好的方法就是直接使用它，而不是尝试用低级组件中重新实现它。拆建与组合的优点只有在没有任何单个软件可以满足你的所有需求时才会显现。

#### 还缺了什么？

合成数据系统的工具正在变得越来越好，但我认为缺少了一个主要部分：我们还没有类似Unix命令行的拆散的数据库（即，一种简单的声明式方式组合存储和处理系统的高级语言）。

例如，我希望我们可以简单地声明`mysql | elasticsearch`，类比Unix管道，这将是`CREATE INDEX`的松散等价：它将接受MySQL数据库中的所有文档，并在Elasticearch集群中对它们建立索引。之后，它将继续抓取对数据库所做的所有变更，然后自动地把它们应用到搜索索引中，而我们无需编写自定义的应用程序代码。这种集成应该对几乎任何类型的存储或索引系统都是可能的。

同样地，能够更容易地预先计算、更新缓存也是很棒的。回忆一下，物化视图本质上是预先计算的缓存，因此你可以想象通过声明地方式为复杂查询指定物化视图来创建缓存，包括对图形（见“类似图的数据模型”一节）以及应用程序逻辑的递归查询。在这一领域有了有趣的早期研究，比如差异数据流]，而我希望这些想法可以找到他们进入生产环境的方法。

### 围绕数据流设计应用程序

通过用应用程序代码组合专门的存储与处理系统拆解数据库的方法也被称为“数据库反转”方法[26]，来自于我在2014年发表的一次会议演讲标题。然而，称它是一种“新架构”就太夸张了。我认为它更像是种设计模式，一个讨论的起点，给它起了一个名字只是方便我们更好地讨论它。

这些想法不是我的，我只是把别人的想法融合在一起，觉得我们应该从中学习。尤其是，它与类似Oz和Juttle等的*数据流*语言，类似Elm的*函数式反应性编程*（FRP）语言以及类似Bloom
的*逻辑编程*语言有许多重叠。在这种背景下，杰·克莱普思提议使用*拆解*这个术语。

即使是电子表格也有数据流编程功能，这比大多数主流编程语言都要先进很多。在电子表格中，你可以把公式放入一个单元格（比如另一列单元格之和），每当公式的输入发生变化，结果都会自动重新计算。这正是我们在数据系统层面所需要的：当数据库中的记录发生变化时，我们希望记录的所有索引都可以自动更新，并且自动刷新依赖于记录的任何缓存视图或聚合。你不用考虑这种刷新发生的技术细节，只需要相信它是可以正确工作的。

因此我认为，大多数数据系统仍然可以从1979年VisiCalc就拥有的特性中学到一些东西。与电子表格不同的是，当今的数据系统要可以容错，可以扩展，而且可以长久存储数据。随着时间的推移，它们还要能够集成不同人编写的不同技术，重用已有的库与服务：期望所有的软件是使用一种特定的语言、框架或工具开发是不现实的。

在这一节中，我会详细介绍这些想法，并探索一些围绕着拆解数据库与数据流的思想构建应用程序的方法。

#### 应用程序代码作为衍生函数

当一个数据集是从另一个数据集衍生出来时，它会经过某种类型的转换函数。例如：

* 二级索引是一种有直接转换函数的衍生数据集：对于基础表中的每一行或文档，它挑选出要建立索引的列或字段中的值，并根据这些值进行排序（假设是一个B树或SSTable索引，按键排序，正如我们在第3章讨论的）。

* 全文搜索索引是通过应用各种自然语言处理函数，比如语言检测、分词、取词干或词形还原、拼写更正以及同义词识别，然后为了高效查找构建数据结构，比如倒排索引。

* 在机器学习系统中，我们可以认为模型是通过应用各种特征提取与统计分析函数从训练数据中提取出来的。当模型应用在新的输入数据上时，模型的输出是来自输入以及模型本身（也因此，间接地，来自于训练数据）。

* 缓存通常包含了数据聚合，它是以即将在用户界面（UI）中显示的形式存在的。因此，生成缓存需要了解UI引用了哪些字段；UI的变化也许需要更新缓存生成的方式，并重新构建缓存。

次级索引的衍生函数是非常必要的，因此它作为核心特性集成到了许多数据库中，于是你只需要用`CREATE INDEX`就可以调用它。对于全文索引，一般语言的基本语言也许可以内建到数据库中，但更复杂的功能通常需要特定领域的调优。在机器学习中，众所周知，特征工程是特定于应用程序的，并且常常需要结合关于应用程序的用户交互以及部署的详细知识。

如果创建衍生数据集的函数不像用于创建次级索引那样的标准函数，就需要自定义代码来处理应用程序独有的问题。而这些自定义代码是许多数据库努力的地方。尽管关系型数据库通常支持触发器、存储过程以及用户定义的函数，这些函数可以在数据库中执行应用程序代码，然而在数据库设计中它们某种程度上是事后才考虑到的事情（见“传输事件流”一节）。

#### 应用程序代码与状态的分离

理论上，数据库可以是任意应用程序代码的部署环境，就像操作系统一样。然而在实践中，事实证明它们并不适合这一目的。它们不适合现代应用程序开发的需求，例如依赖关系和包管理、版本控制、滚动升级、可进化性、监控、数据指标、对网络服务的调用，以及与外部系统的集成。

另一方面，部署和集群管理工具，比如Mesos、YARN、Docker、Kubernetes等等，是专门为运行应用程序代码而设计的。只要专注于做好一件事，它们就能做得比提供执行用户定义函数作为其功能之一的数据库好得多。

我认为，让系统的某些部分专注于持久化的数据存储，而其他部分专注于运行应用程序代码是很有意义的。二者在互动的同时依旧保持独立性。

今天的大多数Web应用都是作为无状态服务部署的，在这种服务中，任何用户请求都可以路由到任何应用服务器，一旦发送了响应，服务器就会忘记所有与请求相关的内容。这种部署方式很方便，因为服务器可以随时添加或移除，但是状态必须要有去处：通常是数据库。目前的趋势是把无状态的应用程序逻辑与状态管理（数据库）分开：不把应用程序的逻辑放在数据库中，也不把持久性的状态放在应用程序中。正如函数式编程社区中的人们喜欢开的玩笑那样，“我们相信政教分离”。

在这种典型的Web应用模型中，数据库可以当作是一种可以通过网络同步访问的可变共享变量。应用程序可以读取、更新变量，而数据库负责使数据持久化，同时提供一些并发控制和容错功能。

然而在大多数编程语言中，你不能订阅可变变量中的变化——你只能定期读取它。与电子表格不同的是，如果变量的值发生变化，变量的读者不会收到通知。（你可以在自己的代码中实现这样的通知——这称为*观察者模式*——但大多数语言都没有把这个模式作为内置功能。）

数据库继承了这种对可变数据的被动方法：如果你想知道数据库的内容是否已经更改，通常唯一的选择就是轮询（即定期重复查询）。对变更的订阅才刚刚开始成为一项功能（见“对变更流的API支持”一节）。

#### 数据流：状态变更与应用程序代码之间的相互作用

从数据流角度考虑应用程序，意味着重新协调应用程序代码与状态管理之间的关系。相比于把数据库视为应用程序操作的被动变量，我们更多地考虑状态、状态变更以及处理它们的代码之间的相互作用与协作。应用程序代码通过触发另一个地方的状态变更来响应一个地方的状态变更。

我们在“数据库与流”一节中看到过这种思路，那个时候我们讨论了把数据库的变更日志作为我们可以订阅的事件流来处理。消息传递系统，比如参与者（见“消息传递的数据流”一节），也有响应事件的概念。早在1980年代，*元组空间*模型就探索了用观察状态变化并对它们作出反应的进程来表示分布式计算。

如前所述，当触发器因数据更改而触发时，或者当次级索引被更新以反映建立了索引的表中的更改时，数据库中也会发生类似的事情。将数据库拆解意味着采纳这一思想，然后把它应用于主数据库之外衍生数据集的创建过程：缓存、全文搜索索引、机器学习或分析系统。为此，我们可以使用流处理系统与消息传递系统。

要记住的重点是，维护衍生数据与异步作业执行不一样，因为传统上消息传递系统是为异步作业执行设计的（见“拿日志与传统消息传递相比”一节）：

* 在维护衍生数据时，状态更改的顺序通常很重要（如果从事件日志衍生出多个视图，那么它们需要以相同的顺序处理事件，从而使它们彼此之间保持一致）。正如“确认与重传”一节中所讨论的，许多消息代理在重发未确认的消息时不具有此属性。双写也被排除在外（见“保持系统之间同步”一节）。

* 容错是衍生数据的关键：只丢失一条消息就会导致衍生数据集与其它的据源再也无法同步。消息传递与衍生状态更新都必须是可靠的。举个例子，许多参与者系统默认在内存中维护参与者的状态与消息，因此如果运行参与者的机器崩溃，它们就会消失。

稳定的消息排序以及可容错的消息处理都是相当严格的要求，但是与分布式事务相比它们代价小得多，操作更健壮。现代的流处理器可以成规模的提供排序与可靠性保证，并且允许应用程序代码作为流运算符运行。

这些应用程序代码可以做数据库内置的衍生函数通常不提供的任意处理。就像用管道连接起来的Unix工具一样，流操作符可以组合，围绕数据流大型系统。每个运算符把状态变更流作为输入，生成其他状态变更流作为输出。

#### 流处理器与服务

当前流行的应用程序开发风格的趋势，是把功能拆解为一组*服务*，服务之间通过同步网络请求，比如REST API，进行通信（见“通过服务的数据流：REST与RPC”）。这种面向服务的体系结构相对于单个整体应用程序的优势主要是通过松散耦合实现组织的可伸缩性：不同的团队可以在不同的服务上工作，这减少了团队之间的协作（只要服务都可以独立地部署与更新）。

把流运算符组合到数据流系统中具有许多与微服务方法相似的特性。然而底层的通信机制非常不同：它用的是单向异步消息流，而不是同步的请求/响应式交互。

除了在“消息传递的数据流”一节中列出的，比如更好的容错性的优点以外，数据流系统还可以获得更好的性能。举个例子，假设客户正在购买的商品是以一种货币定价，但是客户以另一种货币支付。为了执行货币换算，你需要知道当前的汇率。这个操作可以通过两种方式实现：

1. 在微服务方法中，处理购买的代码会查询汇率服务或数据库，从而获得特定货币的当前汇率。

2. 在数据流方法中，处理购买的代码将事先订阅汇率流更新，每当汇率发生变化就把当前汇率记录在本地数据库中。处理购买时，它只需要查询本地数据库。

第二种方法用对本地数据库的查询（可能在同一台机器上，甚至在同一进程中）取代了对另一个服务的同步网络请求。不仅数据流方法更快，而且它对另一个服务的失效也更健壮。最快速最可靠的网络请求是根本没有网络请求！不用RPC，我们现在有一个在购买事件和汇率更新事件之间的流连接（见“流-表连接（流的丰化）一节”）。

连接是时间依赖的：如果在稍后的时间点重新处理购买事件，那么汇率就已经变了。如果要重建原始输出，就需要在原始购买时获得历史汇率。无论是查询服务还是订阅汇率更新流，你都需要处理这种时间依赖（见“连接的时间依赖性”一节）。
订阅变更的流，而不是在需要时查询当前状态，让我们更接近类似电子表格的计算模型：当某些数据发生变化时，任何依赖它的衍生数据都可以快速地更新。还有许多悬而未决的问题，例如与依赖于时间的连接等问题，但我相信，构建基于数据流思想的应用程序是一个非常有希望的方向。
