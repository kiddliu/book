# 第十二章 数据系统的未来

一個以他物為目的者，其最後目的不可能在於保存其自身之存在。為此，舵手不是以保存船為其最後目的，因為船有別的目的，即是為了航行。

（常被引作：如果一个船长的最高目标是保护他的船只，那么他就会让他的船永远停在港口。）

托马斯·阿奎那，*神学大全*（1265-1274）

---

到目前为止，这本书主要是描述事物的*现状*。在这最后一章中，我们将把视角转向未来，讨论事情*应该*是什么样子的：我会提出一些想法和方法，我相信，它们可能会从根本上改进我们设计和构建应用程序的方式。

对未来的看法和猜测当然是主观的，所以我将用本章的第一人称来写我的个人观点。欢迎你反对这些意见并形成你自己的，但我希望这一章中的想法至少能成为富有成效的讨论的起点，并且使经常被混淆的概念更加清晰。

我们在第1章概述了这本书的目标：探讨如何创建*可靠的*、*可扩展的*以及*可维护的*应用与系统。这些主题贯穿了所有章节：例如，我们讨论了许多提升可靠性的容错算法，分区提高可扩展性，以及用于提高可维护性的演进抽象机制。在这一章中，我们将把所有这些想法结合起来，并基于它们展望未来。我们的目标是发现如何设计比今天更好的应用程序——健壮、正确、可演化、最终对人类有益。

## 数据集成

本书中反复出现的一个主题是对于任何给定的问题，都有几种解决方案，它们都有不同的利弊以及取舍。举个例子，在第三章讨论存储引擎时，我们看到了日志结构存储、B树以及面向列的存储。在第五章中讨论复制时，我们看到了单主机、多主机，以及无主机的方法.

如果你有一个比如“我想存储一些数据，之后可以再查找它”的问题，是没有一个正确的解决方案，不同的方法适用于不同的情况。软件实现通常需要选择一种特定的方法。让一个代码路径既坚固又性能良好太难了——在一个软件中尝试做所有的事情几乎可以确保实现会很差。

因此，软件工具的最合适的选择也取决于环境。每款软件，甚至是一个所谓的“通用”数据库，都是为特定的使用模式而设计的。

面对如此众多的备选方案，第一个挑战是找出软件产品与适用环境之间的映射关系。可以理解的是，供应商不愿意告诉你他们的软件不适合的工作负载类型，但是希望前几章已经为你提供了一些问题，以便对其检视，并更好地理解两者之间的取舍。

然而，即使你完全理解了工具和适用它们的环境之间的映射，还有另一个挑战：在复杂的应用中，数据通常以几种不同的方式使用。不太可能有一个软件适合数据使用的*所有*情况，因此你最终不可避免地要拼凑几个不同的软件来提供应用程序的功能。

### 通过衍生数据组合专用的工具

例如，为了处理对任意关键字的查询，常常需要把OLTP数据库与全文搜索索引集成起来。虽然有些数据（比如PostgreSQL）包含对于简单应用足够了的全文索引功能，但是更复杂的搜索工具需要专门的信息检索工具。相反地，搜索索引通常不太适合作为持久的记录系统，因此许多应用程序需要组合两个不同的工具来满足所有的需求。

我们讨论了在“保持系统同步”一节中涉及了集成数据系统的问题。随着数据不同表示方式数量的增加，集成问题变得更加困难。除了数据库和搜索索引之外，你可能还需要在分析系统（数据仓库、批处理以及流处理系统）中保存数据的副本；维护缓存或是从原始数据派生的非规范化版本；通过机器学习、分类、排名或推荐系统传递数据；或者根据对数据的更改发送通知。

令人惊讶的是，我经常看到软件工程师说这样的话：“根据我的经验，99%的人只需要X”或是“…不需要X”（对于X的各种值）。我认为这样的话更多地反映了发言者的经验，而不是一项技术的实际用途。你想要用数据做的不同的事情的范围是非常广的。一个人认为是模糊的、毫无意义的特性很可能是另一个人的中心要求。数据集成的需求通常只有在放大并且考虑整个组织的数据流时才会变得明显。

#### 数据流的推理

当需要在多个存储系统中维护数个相同数据的副本以满足不同的访问模式时，你需要非常清楚地了解输入和输出：数据首先写入到了哪里，哪一种呈现形式衍生自哪个源？如何用正确的格式把数据存入所有正确的位置？

举个例子，你可以把数据先写入记录数据库系统，捕获对该数据库所做的便跟（见“变更数据捕获”一节），然后以相同的顺序把变更应用于搜索索引。如果变更数据捕获（CDC）是更新索引的唯一方法，你可以确信索引完全衍生自记录系统，并因此与它保持一致（排除软件中的错误）。写入数据库是向这个系统提供新输入的唯一途径。

允许应用程序同时直接写入搜索索引和数据库带来了图11-4中的问题，在那里两个客户端并发发送相互冲突的写入，而两个存储系统以不同的顺序处理它们。在这种情况下，数据库与搜索索引都不“负责”判定写入的顺序，因此它们会做出相互矛盾的决定，从而变得永远不一致。

如果你可以引导所有的用户输入到一个可以决定所有写入顺序的系统，那么按照相同顺序处理写入就可以更容易地导出数据的其他表示形式。这是我们在“全序广播”一节中见到过的状态机复制方法的一个应用。无论你是使用变更数据捕获还是事件溯源日志，都不如简单地确定全序原则那么重要。

基于事件日志的衍生数据系统的更新通常具有确定性和幂等性（见“幂等性”一节），因此很容易从故障中恢复。

#### 衍生数据 vs 分布式事务

保持不同数据系统相互一致的经典方法涉及分布式事务，正如“原子提交与两阶段提交（2PC）”一节中所讨论的那样。与分布式事务相比，那么使用派生数据系统的方式如何呢？

在抽象的层面上，它们通过不同的方式实现了相似的目的。分布式事务通过使用锁进行互斥来决定写入的顺序（见“两阶段锁定（2PL）”一节），而CDC以及事件溯源使用日志进行排序。分布式事务使用原子提交来确保更改只发生一次，而基于日志的系统通常是基于确定性重试以及幂等性。

它们最大的区别是事务系统通常提供可线性化（见“可线性化”一节），这意味着支持读取自己的写入这样的有用的保证（见“读取自己的写入”一节）。另一方面，派生数据系统通常是异步更新的，因此在默认情况下它们是不提供相同的时机保证的。

在有限的愿意支付分布式事务成本的环境中，它们的应用十分成功。但是，我认为XA的容错性与性能特性很差（见“实践中的分布式事务”一节），这极大限制了它的实用性。我相信为分布式事务构建一个更好的协议是可能的，但要让这样的协议被广泛采用，并且与现有工具集成起来将会是一项挑战，不太可能很快地实现。

在缺乏对好的分布式事务协议有广泛支持的情况下，我认为基于日志的衍生数据是集成不同数据系统最有希望的方法。然而，保证诸如读取自己的写入是有用的，并且我不认为告诉每个人“最终的一致性是不可避免的——接受它并学会应对它”（至少在没有好的指导如何处理它的情况下）是有效果的。

在“着眼正确性”一节中，我们将讨论在异步衍生系统之上实现更强保证的一些方法，并努力在分布式事务以及基于异步日志的系统之间找到一个中间地带。

#### 全序的限制

对于规模足够小的系统，构建一个全序的事件日志是完全可行的（具有单主机复制的数据库的流行就是很好的证明，它正式构建了这种日志）。然而，随着系统向更大和更复杂的工作负载扩展，限制开始显现出来：

* 在大多数情况下，构建一个全序的日志需要所有事件通过一个决定排序的*单主机节点*。如果事件的吞吐量大于单台设备能够处理的吞吐量，就需要对它进行分区，分散在多台设备上（见“分区日志”一节）。这样，两个不同分区中的事件顺序就不明确了。

* 如果服务器*分布在多个不同地理位置*的数据中心，比如是为了容忍整个数据中心离线，那么你通常在每个数据中心都有一个单独的主机，因为网络延迟会使得同步的跨数据中心的协调工作效率低下（见“多主机复制”一节）。这意味着来自两个不同数据中心的事件之间的顺序没有定义。

* 当应用被部署为*微服务*（见“服务的数据流：REST与RPC”)时，常见的设计选择是把每个服务及其持久状态部署为一个独立的单元，服务与服务之间不共享持久状态。当两个事件来自不同的服务时，这些事件没有定义好的顺序。

* 有些应用程序在用户输入时立即更新客户端状态（没有等待服务器确认），甚至可以继续离线工作（见“有离线操作的客户端”一节）。有了这样的应用程序，客户端与服务器很可能会看到不同顺序的事件。

用正式的术语来讲，确定事件的全序叫做*全序广播*，它与协商一致等价（见“协商一致算法与全序广播”一节）。大多数协商一致的算法都是针对单个节点的吞吐量足以处理整个事件流的情况设计的，而且这些算法没有提供多个节点共享事件排序结果的机制。设计可以扩展到单个节点的吞吐量之外，并且在地理分布的环境中运行良好的协商一致的算法仍然是一个开放性的研究问题。

#### 对时间排序以获取因果关系

在事件之间没有因果关系的场景下，全序的缺失并不是一个大问题，因为并发事件可以任意地排序。其他一些情况也很容易处理：比如说当同一个对象有多个更新时，可以通过把针对特定对象ID的所有更新导向同一个日志分区来进行完全排序。然而，因果依赖关系有时以更微妙的方式出现（见“排序与因果关系”一节）。

举个例子，设想一个社交网络服务，以及两个刚刚分手的用户。其中一个用户将另一个用户移除了好友，然后向其余的朋友发送一条信息，抱怨TA的前任。用户的意愿是，他们的前伴侣不应该看到这条粗鲁的信息，因为这条消息是在朋友身份被撤销之后发送的。

但是如果关系状态存储在一个地方，而信息储存在另外一个地方，那么*取消好友*事件与*发送消息*事件之间的顺序依赖关系可能会丢失。如果没有办法获取因果相关性，那么发送新消息的通知服务可能会在*取消好友*事件之前处理*发送消息*事件，这样就会错误地向前任推送通知。

在这个例子中，通知实际上是消息与好友列表之间的连接，使得它与前面讨论到的连接的时机问题有关（见“连接的时间依赖性”一节）。然而，对于这个问题似乎没有一个简单的答案。解决问题的出发点包括：

* 逻辑时间戳可以在没有协调的情况下提供全序（见“序号排序”一节），因此可以在全序广播不可行的情况下有所帮助。然而它们仍然要求接收方可以处理乱序的事件，并且需要传递额外的元数据。

* 如果你可以写一个事件日志来记录用户在作出决定之前看到的系统状态，并给这个事件一个唯一的标识符，那么之后的任何事件都可以引用这个事件标识符，从而记录因果依赖关系。我们会在“阅读也是事件”一节中回到这个想法。

* 冲突解决算法（见“自动化解冲突”一节）有助于处理以意外顺序传递的事件。它们对于维护状态是有用的，但是如果操作有外部副作用（比如向用户推送通知）就没有办法了。

也许随着时间的推移，会出现可以有效获取因果以来关系的应用开发的模式，并且可以正确地维护衍生的状态，而不会强迫所有事件都必须经过全序广播的瓶颈。

### 批处理与流处理

我认为数据集成的目标是确保数据最终以正确的形式出现在正确的地方。这样做需要消耗输入、转换、连接、过滤、聚合、训练模型、评估，然后最终写入适当的输出。批处理器与流处理器是实现这一目标的工具。

批处理和流过程的输出是衍生的数据集，比如搜索索引、物化视图、显示给用户的推荐、聚合指标，等等等等（见“批处理工作流的输出”与“流处理的使用”小节）。

正如我们在第10章和第11章中所看到，批处理与流处理有许多共同的原理，而根本区别在于流处理器工作在无界数据集上，而批处理过程输入的大小是有限已知的。在处理引擎的实现方式上也有许多细节上的差异，但这些差别越来越模糊了。

Spark通过把流分解成微型批次，在批处理引擎上执行流处理，而Apache Flink在流处理引擎上执行批处理。原则上，一种类型的处理可以用另一种进行模拟，尽管性能特性各不相同：比如说，微批处理在跳变或滑动窗口上的性能可能很差。

#### 维护衍生状态

批处理具有很强的函数式特色（哪怕代码不是用函数式编程语言编写的）：它鼓励确定性的纯函数，它的输出只依赖于输入，除了显式输出以外没有任何副作用，将输入视为不可变的，将输出视为附加的。流处理也类似，但是它扩展了运算符使得状态变得可以管理可以容错（见“失效之后重新构建状态”一节）。

有着定义良好的输入与输出的确定性函数原理不仅有利于容错（见“幂等性”一节），还简化了组织中对数据流的推理。无论衍生数据是搜索索引、统计模型还是缓存，把它想象成从一种事物衍生出另外一种的数据管道都是有益的，它可以把一个系统中的状态变更推送到函数式应用代码然后把这些效果应用到衍生系统。

原则上，衍生数据系统可以同步地维护，就像关系数据库在事务写入建立了索引的表的同时更新次级索引一样。然而，异步使基于事件日志的系统更加健壮：它允许在本地控制系统某一部分的故障，而在分布式事务中如果任何参与者失败，那么整个事务会中止，因此它们倾向通过把故障扩散到系统的其余部分来放大故障（见“分布式事务的限制”一节）。

我们在“分区和次级索引”一节中看到，辅助索引通常跨越了分区边界。具有辅助索引的分区系统要么需要向多个分区发送写入请求（如果索引是按词语分区的），要么需要发送读取请求到所有分区（如果索引是文档分区的）。哪怕索引是异步维护的，这种跨分区通信也是最可靠以及最可以扩展的（也见“多分区数据处理”一节）。

#### 针对应用演进重新处理数据

在维护衍生数据时，批处理和流处理都很有用。流处理可以很快地在衍生视图中反映输入的变化，而批处理可以重新处理大量累积的历史数据，从而把新的视图衍生到现有的数据集上。

特别的是，重新处理现有数据提供了维护系统一个良好的机制，使它可以支持新的特性以及变更了的需求（见第4章）。如果没有重新处理，模式定义的演进会仅限于简单的更改，比如向记录添加一个新的可选字段，或者添加一种新的记录类型。无论是在写时模式还是读式模式都是如此（见“文档模型中模式的灵活性”一节）。另一方面，通过重新处理，可以把数据集重构为一个完全不同的模型，以便更好地满足新的需求。

> **铁路领域的“模式迁移”**
>
> 大规模的“模式迁移”也发生在计算机外的其它系统中。例如，在19世纪英国修建铁路的早期，就有各种不同的轨距（两条铁轨之间的距离）标准相互竞争。为一个轨距而建的列车不能在另一个轨距的轨道上运行，这会限制铁路网中的互连。
>
> 在1846年最终确定了一种标准轨距之后，其他轨距的铁路必须进行转换——但是如何在不关闭铁路数个月甚至数年的情况下做到这一点呢？解决方案是通过添加第三条轨道先把轨道转换为双轨距或混合轨距。这个转换可以逐步完成，完成时，两个轨距的列车都可以在线路上运行，使用三条铁轨中的两条。最终，一旦所有列车都被转换成标准轨距，非标准轨距的铁轨就可以被拆除了。
>
> 以这种方式对现有轨道进行“再加工”，并允许新旧版本肩并肩地共存，使得有可能在几年内逐渐改变轨距。然而，这是一项昂贵的工程，这就是为什么今天仍然存在非标准量规的原因。例如，旧金山湾区的BART系统使用与美国大多数地区不同的量规。

衍生视图允许*渐进式*的演进。如果要重构数据集，你不需要突然切换执行迁移。取而代之的是，你可以同时维护新旧模式，视其为同一份底层数据的两个独立的衍生视图。之后，你可以开始把少量用户转移到新视图，用来测试其性能并发现任何bug，而大多数用户仍然被导向到旧视图。逐渐地，你可以增加用户访问新视图的比例，并最终可以放弃旧视图。

这种渐进迁移的美妙之处在于如果出现问题，那么这个过程的每个阶段都很容易回滚：你总可以回到一个可用的系统。通过减少不可逆损害的风险你可以更加自信地前进，从而可以更快地改进你的系统。

#### Lambda架构

如果批处理是用来重新处理历史数据，而流处理是用来处理最近的更新的，那么如何把二者结合起来？*lambda架构*是这个领域中引起广泛关注的一项建议。

Lambda架构的核心思想是，输入的数据应该通过把不可变的事件添加到不断增长的数据集中来记录，类似于事件溯源（见“事件溯源”一节）。从这些事件中，衍生出了为读取而优化的视图。Lambda架构建议并行运行两个不同的系统：一个批处理系统，比如Hadoop MapReduce，一个单独的流处理系统，比如Storm。

在lambda方法中，流处理器消费事件并快速生成视图的大致更新；批处理器稍后消费*相同*的事件集，并生成衍生视图的修正版本。这种设计背后的理由是，批处理更简单，因此不太容易出现bug，而流处理器被认为不太可靠，实现容错（见“容错”一节）更难。此外，流处理可以使用快速近似算法，而批处理过程使用较慢的精确算法。

Lambda架构是一个有影响力的想法，它改善了数据系统的设计，特别在推广在不可变事件流上衍生视图并且在需要的时候重新处理实践的原则方面。然而我也觉得它有一些现实的问题：

* 必须在批处理和流处理框架中维护相同的逻辑，这显然是额外的工作。虽然像Summingbird这样的库可以在批处理或流处理上提供抽象运算，但是调试、调优以及维护两个不同系统的运营复杂性仍然是存在的。

* 由于流管道和批处理管道产生独立的输出，因此在响应用户请求时需要合并它们。如果计算是一个翻滚窗口上的简单聚合，那么合并相当容易，但是如果视图是使用比如连接与会话化这样更复杂的操作衍生的，或者如果输出不是一个时间序列，它会变得非常困难。

* 尽管能够重新处理整个历史数据集是很棒的，但是在大型数据集上频繁这么做的代价是很高的。因此，通常需要设置批处理管道来处理增量批次（比如，在每个小时结束时处理一个小时的数据），而不是重新处理所有数据。这引发了在“时间的推理”一节中讨论的问题，比如处理散乱事件，以及处理跨越批次间边界的窗口问题。增量批处理计算增加了复杂性，使其更类似于流层，这与保持批处理层尽可能简单的目标背道而驰。

#### 统一批处理与流处理

更新进的工作通过允许在同一个系统中同时实现批计算（重新处理历史数据）以及流计算（在事件到达时处理它们），让我们在享受lambda架构带来的好处的同时避开了它的缺点。

把批处理和流处理统一在一个系统中需要下面这些越来越广泛应用的功能：

* 在处理新近事件流的引擎中处理历史事件的能力。例如，基于日志的消息代理有能力重播消息（见“重播旧消息”一节），而且一些流处理器可以从像HDFS这样的分布式文件系统中读取输入。

* 针对流处理器的精确一次语义——也就是，保证输出与没有任何故障发生的情况一致，哪怕事实上故障确实发生了（见“容错”一节）。与批处理一样，这要求丢弃任何失败任务的不完整输出。

按事件时间而不是按处理时间划分窗口工具，因为在重新处理历史事件时，处理时间是没有意义的（见“关于时间的推理”一节）。例如，Apache Beam提供了一个用于表示此类计算的API，这之后可以使用Apache Flink或是Google Cloud Dataflow运行这些计算。

## 拆散数据库

在最抽象的层次上，数据库、Hadoop以及操作系统都执行相同的功能：它们存储数据，并且允许你处理、查询这些数据。数据库把数据存在某种数据模型的记录中（比如表中的行，文档，图中的顶点），而操作系统的文件系统把数据存储在文件中——但是在核心部分，它们都是“信息管理”系统。正如我们在第10章中看到的，Hadoop生态系统有点像分布式版本的Unix。

当然，它们有许多实际的差别。比如，许多文件系统不能很好地处理有一千万个小文件的目录，而包含一千万条小记录的数据库则是再寻常不过的。然而，操作系统与数据库之间的异同是值得探讨的。

Unix与关系型数据库处理信息管理问题的哲学非常不同。Unix的目的是向程序员提供一个有逻辑但相当低级的硬件抽象层，而关系型数据库想要为应用开发者提供高级别的抽象，从而掩盖磁盘上数据结构的复杂性、并发问题、崩溃恢复等等。Unix开发出了管道和文件，它们只是些字节序列，而数据库开发出了SQL以及事务。

哪种方法更好？当然这取决于你想要什么。Unix“更简单”是因为它只是硬件资源的简单封装；关系型数据库“更简单”是因为一个简短的声明性查询语句可以利用许多强大的基础设施（查询优化、索引、连接方法、并发控制、复制，等等），而查询语句的作者不需要理解实现细节。

这两种哲学之间的矛盾已经持续了几十年（Unix与关系模型二者都出现在20世纪70年代初），至今尚未解决。例如，我会把NoSQL运动解释为希望将低级抽象这种Unix风格的方法应用于分布式OLTP数据存储领域。在这一节中，我将尝试调和这两种哲学，希望我们可以把这两个领域的优点结合起来。

### 数据存储技术的构成

在这本书展开的过程中，我们讨论了数据库提供的各种特性以及它们是如何工作的，包括：

* 次级索引，让你能够根据字段的值高效地搜索记录（见“其他索引结构”一节）

* 物化视图，是预先计算好的查询结果的缓存（见“聚合操作：数据立方体与物化视图”一节）

* 复制日志，让其他节点上的数据副本保持最新（见“复制日志的实现”一节）

* 全文搜索索引，允许在文本中搜索关键字（见“全文搜索与模糊索引”一节），这些索引被内置到了一些关系数据库中。

在第10章和第11章中，出现了类似的主题。我们讨论了构建全文搜索索引（见“批处理工作流的输出”一节）、物化视图维护（见“维护物化视图”一节）以及将变更从数据库复制到衍生数据系统（见“变更数据捕获”一节）。

看起来数据库中内建的特性与人们用批处理器和流处理器构建的衍生数据系统之间存在着相似之处。

#### 创建索引

想象一下在关系型数据库中执行`CREATE INDEX`创建新索引时会发生什么。数据库必须扫描表的一致性快照，选出所有要建立索引的字段值，对它们排序，然后写出索引。之后，它必须处理自获取一致性快照以来积累的写入请求（假设表在创建索引时没有被锁定，所以写入可以继续）。一旦完成之后，每当事务写入表时，数据库都必须保持索引的更新。

这个过程非常类似于设置一个新的从机副本（见“设置新的从机”一节），也非常类似于在流系统中引导启动变更数据捕获（见“初始快照”一节）。

无论何时运行`CREATE INDEX`，数据库基本上都会重新处理现有的数据集（就如“为应用演进而重新处理数据”一节中所讨论的那样），并且导出索引，这是基于现有数据的新视图。现有的数据可能是状态的快照，而不是曾经发生的所有变更的日志，但二者是密切相关的（见“状态、流与不可变性”一节）。

#### 所有事物的元数据库

有鉴于此，我认为穿过整个组织的数据流开始看起来像一个巨大的数据库。每当批处理、流处理或ETL处理将数据从一个位置的一种形式传输到另一个位置的另一种形式，它的作用就好像是数据库子系统，保持索引或是物化视图的更新。

这样看，批处理器与流处理器就像精心实现的触发器、存储过程和物化视图维护例程。它们维护的衍生数据系统类似于不同的索引类型。比如说，关系型数据库可能支持B树索引、哈希索引、空间索引（见“多列索引”一节），以及其他类型的索引。在新兴的衍生数据系统架构中，它们不再作为单一综合数据库产品的特性来实现这些能力，而是由各种不同的软件提供的，运行在不同的机器上，由不同的团队管理。

未来这些改进将带领我们走向何方？如果我们从没有任何一种访问模式适合所有的访问模式这一前提出发，我推测有两种途径可以把不同的存储与处理工具组合成一个统一的系统：

*联合数据库：将读取统一*

可以为各种各样的底层存储引擎与处理方法提供统一的查询接口是可行的，这种方法被称为*联合数据库*或*多存储区*。比如，PostgreSQL的外部数据包装功能符合这种模式。需要专用数据模型或是查询接口的应用程序仍然可以直接访问底层存储引擎，而希望组合来自不同地方数据的用户可以通过联合接口轻松地完成任务。联合查询接口遵循单一集成系统的关系传统，有高级查询语言以及优雅的语义，但实现复杂。

*拆散数据库: 将写入统一*

虽然联合解决了横跨几个不同系统的只读查询，但对于横跨这些系统同步写入却没有一个很好的解决方案。我们说过，在单个数据库中，创建一致性索引是内置的特性。当我们在组合几个存储系统时，我们同样需要确保所有的数据变更都发生在正确的地方，甚至在遇到故障时也是如此。让可靠地连接存储系统（比如通过更改数据捕获与事件日志）变得更容易，就像以一种可以同步跨不同技术的写入方式拆解数据库的索引维护功能一样。

这种拆解方法遵循Unix使用小工具的传统，它可以很好地完成一件事情，这些工具通过统一的低级别API（管道）进行通信，并且可以使用更高级别的语言（命令行）。

#### 使拆散工作

联合和拆解是同一枚硬币的两个面：用不同的组件组成一个可靠的、可扩展的和可维护的系统。联合的只读查询需要把一个数据模型映射到另一个数据模型，这需要一些思考，但最终是一个可管理的问题。我认为，保证对多个存储系统的写入是同步的是一个更困难的工程问题，所以我会重点讨论它。

同步写入的传统方法需要跨异构存储系统的分布式事务，我认为这是错误的解决方案（见“派生数据与分布式事务”一节）。在单个存储系统或是流处理系统中的事务是可行的，但是当数据跨越不同技术之间的边界时，我相信有着幂等写入的异步事件日志是一种更加健壮和实用的方法。

例如，在某些流处理器中用到分布式事务来实现精确一次语义（见“再回到原子提交的问题”一节），这可以很好地工作。然而当事务涉及到由不同组人编写的系统时（比如，当数据从流处理器写入分布式键值存储或搜索索引时），标准化事务协议的缺失使得集成变得更加困难。有着幂等消费者的有序事件日志（见“幂等性”一节）是个简单得多的抽象，因此在异构系统之间实现更加可行。

基于日志集成的最大优势在于各个组件之间的*松散耦合*，这体现在以下两方面：

1. 在系统级别上，异步事件流使整个系统作为一个整体，对各个组件的中断或是性能降级更加健壮。如果一个消费者运行缓慢或是失效，那么事件日志可以缓存消息（见“磁盘空间使用情况”一节），允许生产者与其他消费者继续运行，不受影响。出故障的消费者可以在修复后赶上，所以它不会遗漏任何数据，于是故障被控制住了。相反地，分布式事务的同步交互往往把本地故障提升为大规模失效（见“分布式事务的限制”一节）。

2. 在人的层面上，拆解数据系统允许不同的软件组件和服务由不同的团队独立地开发、改进和维护。专业化允许每个团队专注于做好一件事情，与其他团队的系统有定义良好的接口。事件日志提供了一个强大到足以捕获相当强的一致性属性的接口（由于事件的持久性以及顺序），但也具有足够的通用性，几乎适用于任何类型的数据。

#### 拆解的 vs 集成的系统

如果拆解确实会是未来的方式，它不会取代当前形式的数据库——对它们的需求仍将像以往一样。仍然需要数据库来维护流处理器中的状态，并且用来服务对批处理器和流处理器输出的查询（见“批处理工作流的输出”以及“流的处理”一节）。对于特定的工作负载，专用查询引擎仍然会很重要：比如说，MPP数据仓库中的查询引擎对探索性分析查询进行了优化，很好地处理了这种类型的工作负载（见“把Hadoop与分布式数据库进行比较”一节）。

运行几个不同的基础设施的复杂性会是一个问题：每个软件都有学习曲线、配置问题以及奇怪的操作，因此应当部署尽可能少的运动部件。相比于你用应用代码组合数个工具而成的系统，单个的集成软件产品也可以在为其设计的工作负载类型上获得更好更可预测的性能。正如我在序言中所说的，为你不需要的规模而构建系统浪费精力，并且把自己限制在一个不灵活的设计中。实际上，这是不成熟优化的一种形式。

拆解的目的不是在针对特定负载的性能上与独立数据库竞争；目标是通过组合几个不同的数据库，以便在更广泛的工作负载范围内获得比单个软件更好的性能。它是与广度相关的，而不是深度——与我们在“将Hadoop与分布式数据库进行比较”一节中讨论的存储与处理模型的多样性一脉相承。

因此，如果有单个技术可以满足你所需要的一切，那么你最好的方法就是直接使用它，而不是尝试用低级组件中重新实现它。拆建与组合的优点只有在没有任何单个软件可以满足你的所有需求时才会显现。

#### 还缺了什么？

合成数据系统的工具正在变得越来越好，但我认为缺少了一个主要部分：我们还没有类似Unix命令行的拆散的数据库（即，一种简单的声明式方式组合存储和处理系统的高级语言）。

例如，我希望我们可以简单地声明`mysql | elasticsearch`，类比Unix管道，这将是`CREATE INDEX`的松散等价：它将接受MySQL数据库中的所有文档，并在Elasticearch集群中对它们建立索引。之后，它将继续抓取对数据库所做的所有变更，然后自动地把它们应用到搜索索引中，而我们无需编写自定义的应用程序代码。这种集成应该对几乎任何类型的存储或索引系统都是可能的。

同样地，能够更容易地预先计算、更新缓存也是很棒的。回忆一下，物化视图本质上是预先计算的缓存，因此你可以想象通过声明地方式为复杂查询指定物化视图来创建缓存，包括对图形（见“类似图的数据模型”一节）以及应用程序逻辑的递归查询。在这一领域有了有趣的早期研究，比如差异数据流]，而我希望这些想法可以找到他们进入生产环境的方法。

### 围绕数据流设计应用程序

通过用应用程序代码组合专门的存储与处理系统拆解数据库的方法也被称为“数据库反转”方法[26]，来自于我在2014年发表的一次会议演讲标题。然而，称它是一种“新架构”就太夸张了。我认为它更像是种设计模式，一个讨论的起点，给它起了一个名字只是方便我们更好地讨论它。

这些想法不是我的，我只是把别人的想法融合在一起，觉得我们应该从中学习。尤其是，它与类似Oz和Juttle等的*数据流*语言，类似Elm的*函数式反应性编程*（FRP）语言以及类似Bloom
的*逻辑编程*语言有许多重叠。在这种背景下，杰·克莱普思提议使用*拆解*这个术语。

即使是电子表格也有数据流编程功能，这比大多数主流编程语言都要先进很多。在电子表格中，你可以把公式放入一个单元格（比如另一列单元格之和），每当公式的输入发生变化，结果都会自动重新计算。这正是我们在数据系统层面所需要的：当数据库中的记录发生变化时，我们希望记录的所有索引都可以自动更新，并且自动刷新依赖于记录的任何缓存视图或聚合。你不用考虑这种刷新发生的技术细节，只需要相信它是可以正确工作的。

因此我认为，大多数数据系统仍然可以从1979年VisiCalc就拥有的特性中学到一些东西。与电子表格不同的是，当今的数据系统要可以容错，可以扩展，而且可以长久存储数据。随着时间的推移，它们还要能够集成不同人编写的不同技术，重用已有的库与服务：期望所有的软件是使用一种特定的语言、框架或工具开发是不现实的。

在这一节中，我会详细介绍这些想法，并探索一些围绕着拆解数据库与数据流的思想构建应用程序的方法。

#### 应用程序代码作为衍生函数

当一个数据集是从另一个数据集衍生出来时，它会经过某种类型的转换函数。例如：

* 二级索引是一种有直接转换函数的衍生数据集：对于基础表中的每一行或文档，它挑选出要建立索引的列或字段中的值，并根据这些值进行排序（假设是一个B树或SSTable索引，按键排序，正如我们在第3章讨论的）。

* 全文搜索索引是通过应用各种自然语言处理函数，比如语言检测、分词、取词干或词形还原、拼写更正以及同义词识别，然后为了高效查找构建数据结构，比如倒排索引。

* 在机器学习系统中，我们可以认为模型是通过应用各种特征提取与统计分析函数从训练数据中提取出来的。当模型应用在新的输入数据上时，模型的输出是来自输入以及模型本身（也因此，间接地，来自于训练数据）。

* 缓存通常包含了数据聚合，它是以即将在用户界面（UI）中显示的形式存在的。因此，生成缓存需要了解UI引用了哪些字段；UI的变化也许需要更新缓存生成的方式，并重新构建缓存。

次级索引的衍生函数是非常必要的，因此它作为核心特性集成到了许多数据库中，于是你只需要用`CREATE INDEX`就可以调用它。对于全文索引，一般语言的基本语言也许可以内建到数据库中，但更复杂的功能通常需要特定领域的调优。在机器学习中，众所周知，特征工程是特定于应用程序的，并且常常需要结合关于应用程序的用户交互以及部署的详细知识。

如果创建衍生数据集的函数不像用于创建次级索引那样的标准函数，就需要自定义代码来处理应用程序独有的问题。而这些自定义代码是许多数据库努力的地方。尽管关系型数据库通常支持触发器、存储过程以及用户定义的函数，这些函数可以在数据库中执行应用程序代码，然而在数据库设计中它们某种程度上是事后才考虑到的事情（见“传输事件流”一节）。

#### 应用程序代码与状态的分离

理论上，数据库可以是任意应用程序代码的部署环境，就像操作系统一样。然而在实践中，事实证明它们并不适合这一目的。它们不适合现代应用程序开发的需求，例如依赖关系和包管理、版本控制、滚动升级、可进化性、监控、数据指标、对网络服务的调用，以及与外部系统的集成。

另一方面，部署和集群管理工具，比如Mesos、YARN、Docker、Kubernetes等等，是专门为运行应用程序代码而设计的。只要专注于做好一件事，它们就能做得比提供执行用户定义函数作为其功能之一的数据库好得多。

我认为，让系统的某些部分专注于持久化的数据存储，而其他部分专注于运行应用程序代码是很有意义的。二者在互动的同时依旧保持独立性。

今天的大多数Web应用都是作为无状态服务部署的，在这种服务中，任何用户请求都可以路由到任何应用服务器，一旦发送了响应，服务器就会忘记所有与请求相关的内容。这种部署方式很方便，因为服务器可以随时添加或移除，但是状态必须要有去处：通常是数据库。目前的趋势是把无状态的应用程序逻辑与状态管理（数据库）分开：不把应用程序的逻辑放在数据库中，也不把持久性的状态放在应用程序中。正如函数式编程社区中的人们喜欢开的玩笑那样，“我们相信政教分离”。

在这种典型的Web应用模型中，数据库可以当作是一种可以通过网络同步访问的可变共享变量。应用程序可以读取、更新变量，而数据库负责使数据持久化，同时提供一些并发控制和容错功能。

然而在大多数编程语言中，你不能订阅可变变量中的变化——你只能定期读取它。与电子表格不同的是，如果变量的值发生变化，变量的读者不会收到通知。（你可以在自己的代码中实现这样的通知——这称为*观察者模式*——但大多数语言都没有把这个模式作为内置功能。）

数据库继承了这种对可变数据的被动方法：如果你想知道数据库的内容是否已经更改，通常唯一的选择就是轮询（即定期重复查询）。对变更的订阅才刚刚开始成为一项功能（见“对变更流的API支持”一节）。

#### 数据流：状态变更与应用程序代码之间的相互作用

从数据流角度考虑应用程序，意味着重新协调应用程序代码与状态管理之间的关系。相比于把数据库视为应用程序操作的被动变量，我们更多地考虑状态、状态变更以及处理它们的代码之间的相互作用与协作。应用程序代码通过触发另一个地方的状态变更来响应一个地方的状态变更。

我们在“数据库与流”一节中看到过这种思路，那个时候我们讨论了把数据库的变更日志作为我们可以订阅的事件流来处理。消息传递系统，比如参与者（见“消息传递的数据流”一节），也有响应事件的概念。早在1980年代，*元组空间*模型就探索了用观察状态变化并对它们作出反应的进程来表示分布式计算。

如前所述，当触发器因数据更改而触发时，或者当次级索引被更新以反映建立了索引的表中的更改时，数据库中也会发生类似的事情。将数据库拆解意味着采纳这一思想，然后把它应用于主数据库之外衍生数据集的创建过程：缓存、全文搜索索引、机器学习或分析系统。为此，我们可以使用流处理系统与消息传递系统。

要记住的重点是，维护衍生数据与异步作业执行不一样，因为传统上消息传递系统是为异步作业执行设计的（见“拿日志与传统消息传递相比”一节）：

* 在维护衍生数据时，状态更改的顺序通常很重要（如果从事件日志衍生出多个视图，那么它们需要以相同的顺序处理事件，从而使它们彼此之间保持一致）。正如“确认与重传”一节中所讨论的，许多消息代理在重发未确认的消息时不具有此属性。双写也被排除在外（见“保持系统之间同步”一节）。

* 容错是衍生数据的关键：只丢失一条消息就会导致衍生数据集与其它的据源再也无法同步。消息传递与衍生状态更新都必须是可靠的。举个例子，许多参与者系统默认在内存中维护参与者的状态与消息，因此如果运行参与者的机器崩溃，它们就会消失。

稳定的消息排序以及可容错的消息处理都是相当严格的要求，但是与分布式事务相比它们代价小得多，操作更健壮。现代的流处理器可以成规模的提供排序与可靠性保证，并且允许应用程序代码作为流运算符运行。

这些应用程序代码可以做数据库内置的衍生函数通常不提供的任意处理。就像用管道连接起来的Unix工具一样，流操作符可以组合，围绕数据流大型系统。每个运算符把状态变更流作为输入，生成其他状态变更流作为输出。

#### 流处理器与服务

当前流行的应用程序开发风格的趋势，是把功能拆解为一组*服务*，服务之间通过同步网络请求，比如REST API，进行通信（见“通过服务的数据流：REST与RPC”）。这种面向服务的体系结构相对于单个整体应用程序的优势主要是通过松散耦合实现组织的可伸缩性：不同的团队可以在不同的服务上工作，这减少了团队之间的协作（只要服务都可以独立地部署与更新）。

把流运算符组合到数据流系统中具有许多与微服务方法相似的特性。然而底层的通信机制非常不同：它用的是单向异步消息流，而不是同步的请求/响应式交互。

除了在“消息传递的数据流”一节中列出的，比如更好的容错性的优点以外，数据流系统还可以获得更好的性能。举个例子，假设客户正在购买的商品是以一种货币定价，但是客户以另一种货币支付。为了执行货币换算，你需要知道当前的汇率。这个操作可以通过两种方式实现：

1. 在微服务方法中，处理购买的代码会查询汇率服务或数据库，从而获得特定货币的当前汇率。

2. 在数据流方法中，处理购买的代码将事先订阅汇率流更新，每当汇率发生变化就把当前汇率记录在本地数据库中。处理购买时，它只需要查询本地数据库。

第二种方法用对本地数据库的查询（可能在同一台机器上，甚至在同一进程中）取代了对另一个服务的同步网络请求。不仅数据流方法更快，而且它对另一个服务的失效也更健壮。最快速最可靠的网络请求是根本没有网络请求！不用RPC，我们现在有一个在购买事件和汇率更新事件之间的流连接（见“流-表连接（流的丰化）一节”）。

连接是时间依赖的：如果在稍后的时间点重新处理购买事件，那么汇率就已经变了。如果要重建原始输出，就需要在原始购买时获得历史汇率。无论是查询服务还是订阅汇率更新流，你都需要处理这种时间依赖（见“连接的时间依赖性”一节）。
订阅变更的流，而不是在需要时查询当前状态，让我们更接近类似电子表格的计算模型：当某些数据发生变化时，任何依赖它的衍生数据都可以快速地更新。还有许多悬而未决的问题，例如与依赖于时间的连接等问题，但我相信，构建基于数据流思想的应用程序是一个非常有希望的方向。

### 观察衍生的状态

在抽象级别上，上一节中讨论的数据流系统为你提供了创建衍生数据集（比如搜索索引、物化视图和预测模型）并保持它们最新的过程。让我们将这个过程称为*写入路径*：每当某个信息写入系统时，它可能会经历多个批处理和流处理阶段，并最终更新每个衍生数据集从而包含写入的数据。图12-1展示了一个更新搜索索引的示例.

*图12-1. 在一个搜索索引中，写入（文档更新）遇上了读取（查询）。*

但是为什么首先要创建衍生数据集？很可能是因为你希望稍后再查询它。这是*读取路径*：当服务用户请求时你读取衍生数据集，或许再对结果进行一些处理，然后构建返回给用户的响应。

综合起来，写入路径和读取路径包含了数据的整个旅程，从数据被收集的那一刻到数据最终被（也许是另一个人）消费的那一刻。写入路径是旅程中数据被预先计算出来的部分——也就是说，不管是否有人请求查看它，只要有数据输入写入路径就立即完成了。阅读路径是旅程中只有在有人请求时才会发生的一部分。如果熟悉函数式编程语言，你可能会注意到写入路径类似于及早求值，读取路径类似于惰性求值。

衍生的数据集是写入路径与读取路径相遇的地方，如图12-1所示。它代表了写入时需要完成的工作量与读取时需要完成的工作量之间的取舍。

#### 物化视图与缓存

全文搜索索引就是一个很好的例子：写入路径更新索引，读取路径在索引中搜索关键字。读写都需要做一些工作。写入需要针对文档中出现的所有术语更新索引。读取需要搜索查询语句中的每个单词，并应用布尔逻辑查找包含查询语句中所有单词的文档（`AND`操作符），或是包含每个单词任何的同义词的文档（`OR`操作符）。

如果没有索引，搜索查询语句就必须扫描所有文档（就好像`grep`），如果你有大量的文档，这样做代价会非常高。没有索引意味着在写入路径上的工作较少（没有需要更新的索引），但在读取路径上的工作量多了非常多。

另一方面，你可以想象为所有可能的查询预先计算搜索结果。在这种情况下，在读取路径上要做的工作就少了：没有布尔逻辑，只需要找到查询的结果然后返回它们。然而写入路径上的代价要高得多：可能发起的搜索查询集合是无限的，因此预先计算所有可能的搜索结果就需要无限的时间与存储空间。这样就不太好了。

另一种选择是只为一组固定的最常见的查询预先计算搜索结果，这样就可以快速地处理这些查询而不必转到索引中。不常见的查询仍然可以在索引中进行。这样做通常被称为常见查询的*缓存*，尽管我们也可以称它为物化视图，因为当出现新的文档，常见查询的结果需要包含它们的时候就需要对它进行更新。

从这个例子中我们可以看到，索引并不是写入路径与读取路径之间唯一的边界。缓存常见的搜索结果是可能的，在没有索引的情况下进行类似`grep`一样的扫描也可以在少量文档上进行。这样看，缓存、索引和物化视图的作用很简单：它们移动了读取路径和写入路径之间的边界。它们允许我们通过预先计算结果在写入路径上做更多的工作，从而节省读取路径上的工作量。

改变写入路径与读取路径上完成的工作实际上是本书开头在“描述符在”一节中推特示例的主题。在这个例子中，我们还看到了对于名人来说，写入路径与读取路径之间的边界可能与普通用户的不同。经过了500页之后，我们已经走了一个完整的循环！

#### 有状态的，可离线工作的客户端

我发现写读路径之间有边界的想法很有趣，因为我们可以讨论移动这个边界，并从实际的角度探讨这个变化意味着什么。让我们从另外一个的背景来看这个想法。

在过去的二十年里，Web应用的流行使我们对应用程序开发做了一些很容易被认为是理所当然的假设。特别是，客户端/服务器模型——其中客户机基本上是无状态的，服务器对数据有绝对的权限——是如此普遍以至于我们几乎忘记了任何其它模型的存在。然而技术在继续发展，我认为时不时地质疑现状是很重要的。

传统上，Web浏览器一直是无状态客户端，只有在有互联网连接时才能做有用的事情（离线时你唯一能做的就是上下滚动你之前在线时就加载好的页面）。然而，最近的“单页面”JavaScript Web应用有了许多有状态功能，包括客户端的用户界面交互以及在Web浏览器中的持久本地存储。移动应用同样可以在设备上存储大量状态，并且大多数用户交互不需要与服务器交互。

这些还在持续变化的功能让人们对*离线优先*的应用程序重新产生兴趣，它在不需要互联网连接的情况下使用同一设备上的本地数据库可以做尽可能的事情，之后在网络连接可用时再与后台的远程服务器同步。由于移动设备通常有的是缓慢且不可靠的蜂窝互联网连接，如果用户界面不需要等待同步网络请求，而且应用大部分功能可以离线工作（见“有连线操作的客户端”一节），这对用户来说是一个巨大的优势。

当我们不再假设只有与中央数据库通信的无状态客户端，而是转向状态是可以在最终用户的设备上维护的时侯，就打开了一个充满机会的新世界。尤其是，我们可以把设备上的状态视为*服务器上的状态的缓存*。屏幕上显式的是客户端应用模型对象的物化视图；而模型对象是位于远程数据中心里状态的本地副本。

#### 推送状态变更到客户端

在典型的网页中，如果你在Web浏览器中加载页面随后数据在服务器上变了，除非你重新加载页面否则浏览器是不会发现这个变化的。浏览器只会读取某一时间点的数据，假设它是静态的——它不订阅来自服务器的更新。因此，设备上的状态是一个不会更新的陈旧缓存，除非你显式轮询变更。（基于HTTP的摘要订阅协议，比如RSS，实际上只是一种轮询的简单形式。）

最近的协议已经超越了HTTP基本的请求/响应模式：服务器发送的事件（EventSource API）与WebSocket提供了通信通道，通过这些通道Web浏览器可以保持一个打开的TCP连接到服务器，只要连接还在，服务器就可以主动地推送消息到浏览器。这为服务器提供了一个机会，可以主动通知终端用户客户端其本地存储状态发生了变化，从而降低了客户端状态的陈旧程度。

根据我们的写入路径与读取路径模型，主动推送状态更改到客户端设备意味着把写入路径一直延展到了最终用户。当客户端第一次初始化时，它仍然需要使用读取路径来获得它的初始状态，但之后它可以依赖于服务器推送的状态变更流。我们讨论的关于流处理和消息传递的想法并不局限于仅在数据中心中运行：我们可以进一步研究这些想法，并且把它扩展到终端用户设备。

这些设备某些时候会处于脱机状态，在此期间无法从服务器接收任何状态变更的通知。但我们已经解决了这个问题：在“消费者偏移量”一节中，我们讨论了基于日志的消息代理使用者如何在失败或是断开连接后重新连接，并且确保它在断开连接时不会丢失任何到达的消息。同样的技术也适用于单个用户，其中的每个设备都是一个小事件流的订阅者。

#### 端到端的事件流

最近用于开发有状态的客户端与用户界面的工具，比如Elm语言以及Facebook的React\Flux\Redux工具链，都已经通过订阅代表用户输入或服务器响应的事件流来管理内部客户端状态，其结构类似于事件源（见“事件溯源”一节）。

把这个编程模型扩展成允许服务器把状态变更事件推送到客户端的事件管道，是非常自然的。因此，状态变更可以流过端到端的写入路径：从一个触发状态变更设备上的交互，通过事件日志和几个衍生的数据系统和流处理器，一直到另一个设备上观察状态的人的用户界面。这些状态变化能以相当低的延迟传播——比如，端到端一秒以内。

一些应用，比如即时通讯软件与网游，已经有了这样一种（在低延迟的交互意义上，而不是在“响应时间保证”的意义上）“实时”的架构。但是为什么我们不用这种方式构建所有的应用程序呢？

挑战在于，无状态客户端以及请求/响应式交互的假设深深地依赖于我们的数据库、框架和协议。许多数据存储支持一个请求返回一个响应的情况下进行读写操作，但是只有极少数提供订阅变更的能力——也就是，一个请求返回的是随着时间的推移的响应流（见“对变更流的API支持”一节）。

为了把写入路径一路扩展到最终用户，我们需要从根本上重新考虑构建这些系统的方式：远离请求/响应式交互而转向发布/订阅数据流。我认为更具响应性的用户界面与更好的离线支持的优点值得我们为之付出努力。如果你正在设计数据系统，我希望你时刻谨记订阅变化的选择，而不只是查询当前状态。

#### 读也是事件

我们讨论了当流处理器把派生数据写入存储（数据库、缓存或索引），以及用户请求这些存储时，这些存储扮演了写入路径与读取路径之间的边界。存储允许随机查询数据，不然的话就需要扫描整个事件日志。

在许多情况下，数据存储与流传输系统是分开的。但是回想一下，流处理器也需要维护状态来执行聚合以及连接（见“流连接”一节）。这种状态通常隐藏在流处理器内部，但是一些框架也允许它被外部客户端查询，从而把流处理器本身变成一种简单的数据库。

我想让这个想法更进一步。根据截至到目前所讨论到的，对存储的写入请求经过事件日志，而读取请求是直接发送到存储被查询数据节点的短暂网络请求。这是一个合理的设计，但不是唯一的设计。还可以把读取请求表现为事件流，然后既把读取事件也把写入事件发送到流处理起；处理器通过把读取得结果发送到输出流从而响应读事件。

当写入与读取都被表示为事件，并被转发到相同的流操作符进行处理时，我们实际上是在读取查询流与数据库之间执行流-表连接。读取事件需要发送到保有数据的数据库分区（见“请求的转发”一节），就像批处理器与流处理器在连接时需要按相同的键对输入进行分区一样（见“归纳端的连接与分组”一节）。

服务请求与执行连接之间的这种对应关系是很基本的。一次性读取请求只是把请求传递给连接操作符，然后立即忘记它；订阅请求是一个持久连接，连接另一端是过去以及未来的事件。

记录读取事件的日志对于追踪系统中的因果依赖关系和数据来源也是有好处的：它可以让你在用户做出决定之前重新构建他们看到的内容。例如在网上商店中，预测的发货日期以及向客户显示的库存状态很可能会影响他们是否选择购买某一商品。要分析这个连接，你需要记录用户查询的发货以及库存状态的结果。

因此，把读取事件写入持久性存储可以更好地朱总因果关系（见“对事件排序以获取因果关系”一节），但这会导致额外的存储和I/O成本。优化这些系统以减少开销仍然是一个开放性的研究问题[2]。但是如果你已经因为运营的目的记录了读取请求，作为处理请求的副产品，那么把日志改为请求的源并不是什么大改变。

#### 多分区数据的处理

对于只涉及单个分区的查询，通过流发送查询然后收集响应流也许太过了。然而，这种思想为需要组合多个分区数据的复杂查询的分布式执行开启了可能性，同时利用了流处理器提供的消息转发、分区以及连接的架构。

Storm的分布式RPC特性支持这种使用模式（见“消息传递与RPC”一节）。例如，它被用来计算在推特上有多少人看到了一个URL——也就是每个在推特上转发这个URL的人的粉丝集合的联合。因为推特用户的集合是分了区的，那么这个计算需要组合来自多个分区的结果。

这种模式的另一个例子发生在预防欺诈中：为了评估某个购买事件是否具有欺骗性的风险，你可以检查用户IP地址、电子邮件地址、账单地址、发货地址等等的信誉评分。由于每个信誉数据库本身都是分了区的，因此收集特定购买事件的分数需要在不同分区的数据集上进行一系列的连接。

MPP数据库的内部查询执行图具有类似的特性（见“把Hadoop与分布式数据库进行比较”一节）。如果你需要执行这种多分区的连接，那么使用提供这个功能的数据库可能比使用流处理器实现它更简单。然而，将查询看作流提供了一种实现大规模应用程序的选择，这种应用打破了传统现成解决方案的限制。

## 为了正确性

对于只读取数据的无状态服务，如果出错那没什么大不了的：你可以修复错误然后重新启动服务，之后一切都会恢复正常。数据库等有状态系统就没那么简单了：它的设计目的就是（或多或少的）永远记住事情，因此如果出了问题，这种影响也有可能永远持续下去——这意味着它们需要更仔细的思考。

我们希望构建既可靠又正确的应用（即，即使在遇到各种故障的情况下，它的语义也被很好地定义与理解的程序）。大约四十年来，事物的原子性、隔离性与持久性属性（第7章）一直是构建正确应用的首选工具。然而，这些基础比它们看起来的要弱：比如说弱隔离级别的混乱（见“弱隔离级别”）。

在某些领域，事务被完全抛弃，取而代之的是具有更好性能和扩展性、但语义却要混乱得多的模型（见“无主机复制”）。我们经常提到*一致性*，但是对它的定义却很差（见“一致性”与第9章）。有些人认为为了更好的可用性我们应该“拥抱弱一致性”，然而在实践中这到底意味着什么却没有明确的概念。

对于一个是如此重要的主题，我们的理解与工程方法都令人惊讶地支离破碎。例如，很难确定在特定事务隔离级别或复制配置上运行特定应用是否安全。通常当并发性很低且没有故障时，简单的解决方案看起来是正确的，但在更苛刻的环境中却有许多微妙的bug。

比如说，凯尔·金斯伯里的Jepsen实验强调了一些产品所声称的安全保证与它们在网络问题和崩溃面前的实际行为之间的明显差异。即使像数据库这样的基础设施产品没有问题，应用程序代码仍然需要正确地使用它们提供的特性，如果配置很难理解的话，这是很容易出错的（比如弱隔离级别与仲裁配置等等）。

如果你的应用可以容忍偶尔毫无预期的数据损坏或丢失，那么事情就会简单得多，你也许只需要简单地祈祷然后期望最好的结果。另一方面，如果你需要更强的正确性保证，那么可序列化以及原子提交是已经证明了的方法，但是使用它们是要付出代价的：它们通常只能工作在一个数据中心里（因此排除了不同位置的分布式架构），并且限制了你可以实现的规模以及容错属性。

虽然传统的事务处理方法并没有消失，但我也相信，它不是使应用程序正确并适应故障的最终方法。在这一节中，我会在数据流架构下给出一些思考正确性的方法。

### 端到端的数据库参数

仅仅是因为应用使用的数据系统提供了相对较强的安全属性，比如可序列化的事务，这并不意味着应用可以保证不受数据丢失或损坏的影响。举个例子，如果应用有bug，导致它写入不正确的数据，或是从数据库中删除数据，那么可序列化的事务也无能为力。

这个例子看起来很无聊，但值得认真对待：应用程序会有bug，人们会犯错误。我在“状态、流与不可变性”中用过这个例子，以支持不可变和仅附加的数据，因为一旦移除了破坏好数据的有故障的代码，就很容易从这些错误中恢复。

尽管不变性很有用，但是它本身并不是一种万能药。让我们看一个可能发生数据损坏的更微妙的例子。

Although immutability is useful, it is not a cure-all by itself. Let’s look at a more subtle example of data corruption that can occur.

#### 操作的恰好一次执行

在“容错”一节中，我们遇到了一个名为*恰好一次*（或是*有效一次*）语义的概念。如果在处理消息时出了问题，你要么放弃（丢弃消息——即，导致数据丢失），或者再试一次。如果你再试一次，就有实际上第一次就成功了，只是你没有发现它成功的风险，于是消息最终会被处理两次。

两次处理是数据损坏的一种形式：同一个服务向客户收取两次费用（对他们收费过高）或两次增加计数器（夸大某个指标）都是不可取的。在这种情况下，*恰好一次*意味着使计算的最终效果与没有发生故障是一样的，即使操作实际上因为某个故障而重试过。我们以前讨论了实现这一目标的几种方法。

最有效的方法之一是使操作幂等（见“幂等性”一节），即无论是执行一次还是多次，都确保它具有相同的效果。但是，使天然非幂等的操作成为幂等操作需要耗费一定的精力，并且需要很小心：你可能需要维护一些额外的元数据（比如更新了值的操作ID集合），并确保在从一个节点到另一个节点进行故障迁移时进行隔离（见“主机与锁”一节）。

#### 抑制重复

除了流处理之外，在许多其他地方也存在需要抑制重复的相同模式。比如说，TCP对于数据包使用序列号，从而在接收端将数据以正确顺序排序，并且判断网络上是否丢失或复制了任何数据包。在TCP堆栈将数据提交给应用程序之前，任何丢失的数据包都会被重新传输，任何重复的数据包都会被删除。

但是，这种抑制重复的方式只在单个TCP连接的上下文中起作用。假设TCP连接是客户端到数据库的连接，并且它正在执行示例12-1中的事务。在许多数据库中，事务是绑定到客户端连接的（如果客户端发送了几个查询，因为它们是在同一个TCP连接上发送的，所以数据库知道它们是属于同一个事务）。如果客户端在发送`COMMIT`后获取数据库服务器返回之前遭遇网络闪断，它就不知道事务是否已经提交还是中止了（图8-1）。

*示例12-1. 非幂等性的跨账户转账*

```SQL
BEGIN TRANSACTION
UPDATE accounts SET balance = balance + 11.00 WHERE account_id = 1234;
UPDATE accounts SET balance = balance - 11.00 WHERE account_id = 4321;
COMMIT;
```

客户端可以重新连接到数据库然后重试事务，但现在这超出了TCP抑制重复的范围。由于例12-1中的事务不是幂等的，所以可能转账了22美元，而不是期望的11美元。因此，即使示例12-1是事务原子性的标准示例，它实际上是不正确的，而且真实的银行并不是这样工作的。

两阶段提交（见“原子提交与两阶段提交（2PC）”一节）协议打破了TCP连接与事务之间的1对1的映射，因为它们必须允许事务协调程序在网络故障后重新连接到数据库，并告诉它是提交还是中止可疑事务。这是否足以确保事务只执行一次？可惜没有。

即使我们可以抑制数据库的客户端和服务器之间的事务复制，我们还需要担心终端用户设备与应用服务器之间的网络。举个例子，如果用户的客户端是一个Web浏览器，它可能使用HTTP POST请求向服务器提交指令。也许用户正在使用弱蜂窝数据连接，发送`POST`成功后信号变得太弱，无法从服务器接收到响应。

在这种情况下，用户大概会看到一条错误信息，然后他们可能会手动重试。Web浏览器警告说，“你确定要再次提交此表单吗？”——用户回答是，因为他们希望操作发生。(POST/Redirect/GET模式在正常操作中可以避免这个警告，但是如果POST请求超时就没有用了。）从Web服务器的角度来看，重试是一个单独的请求，而从数据库的角度来看，它是一个单独的事务。通常的去重复机制没有用。

#### 操作标识符

为了使操作在经过几次跳跃后保持幂等性，仅仅依靠数据库提供的事务机制是不够的——你需要把端到端请求的流考虑在内。

例如，你可以为操作生成唯一标识符，比如UUID，然后把它作为隐藏的表单字段包含在客户端应用中，或者计算所有相关表单字段的哈希值以衍生操作ID。如果Web浏览器两次提交POST请求，则这两个请求具有相同的操作ID。之后你可以将该操作ID一直传递到数据库，并检查你是否只使用给定的ID执行了一次操作，如示例12-2所示。

*示例12-2. 使用唯一标识符抑制重复请求*
*Example 12-2. Suppressing duplicate requests using a unique ID*

```SQL
ALTER TABLE requests ADD UNIQUE (request_id);

BEGIN TRANSACTION;

INSERT INTO
    requests (request_id, from_account, to_account, amount)
    VALUES('0286FDB8-D7E1-423F-B40B-792B3608036C', 4321, 1234, 11.00);

UPDATE accounts SET balance = balance + 11.00 WHERE account_id = 1234;
UPDATE accounts SET balance = balance - 11.00 WHERE account_id = 4321;

COMMIT;
```

示例12-2依赖于`request_id`列的唯一性约束。如果事务试图插入一个已经存在的ID，那么`INSERT`会失败，事务会中止，从而阻止其两次生效。关系型数据库一般可以正确地维护唯一性约束，哪怕是在弱隔离级别（而应用程序级别的检查后插入操作也许会在不可序列化的隔离级别下失败，正如我们在“写偏与幻影”一节讨论的那样）。

除了抑制重复请求之外，示例12-2中的`requests`表用作了一种事件日志，暗示了事件溯源的可能性（见“事件溯源”一节）。对帐户余额的更新实际上没有必要发生在插入事件的同一事务中，因为它们是多余的，是可以从下游使用者中的请求事件衍生出来的——只要事件正确地恰好处理一次，就可以使用请求ID再次强制执行。

#### 端到端的参数

这种抑制重复事务的情况只是*端到端*参数这个更普遍原则的一个例子，萨策尔、里德和克拉克在1984年提出了这一论点：

    只有有了在通信系统端点上应用程序的知识与帮助，才能完全和正确地实现有疑问的函数。因此，提供有疑问的函数作为通信系统本身的一个功能是不可能的。（有时通信系统提供的不完整版本的函数可能有助于提高性能。)

在我们的示例中，这个*有疑问的函数*是抑制重复。我们看到TCP协议在TCP连接级别上抑制重复的数据包，而一些流处理器在消息处理级别提供了所谓的恰好一次语义，但是这都不足以防止用户在首次请求超时的情况下重复提交请求。TCP、数据库事务以及流处理器自身并不能完全排除这些重复。解决这个问题需要一个端到端的解决方案：一个从终端客户端一直传递到数据库的事务标识符。

端到端的参数也适用于检查数据的完整性：内置于以太网、TCP以及TLS中的冗余校验可以检测网络中数据包的损坏，但它们不能检测网络连接发送与接收端软件中的bug，或者存储数据磁盘上的损坏。如果要捕获所有可能的数据损坏源，你还需要端到端的冗余校验。

同样的参数也适用于加密：家庭WiFi网络的密码可以防止人们窥探你的WiFi流量，但不能防止Internet上其他地方的攻击者；你的客户端和服务器之间的TLS/SSL可以防止网络攻击，但不能防止服务器被攻陷。只有端到端加密与身份验证才能防止所有这些事情发生。

虽然低级别功能（TCP抑制重复、以太网冗余校验、WiFi加密）本身不能提供所需的端到端功能，但它们仍然很有用，因为它们降低了在更高级别出现问题的可能性。例如，如果TCP没有把数据包按正确的顺序放置，HTTP请求通常会受到破坏。我们只需要记住，低级别的可靠性功能本身并不足以确保端到端的正确性。

#### 在数据系统中应用端到端的思想

这让我回到了我最初的论断：仅仅因为应用程序使用了一个拥有相对强大安全属性的数据系统，例如可序列化的事务，并不意味着应用程序可以保证不会发生数据丢失或损坏。应用程序本身也需要采取端到端的措施，比如抑制重复。

这很遗憾，因为容错机制很难调整正确。低级别的可靠性机制，如TCP中的哪些，工作得相当好，因此余下更高级别的故障很少发生。把余下的高级容错机制封装抽象，这样应用程序代码就不必担心它会是非常棒的——但我担心我们还没有找到正确的抽象。

长期以来，事务一直被视为是很好的抽象，我确实认为它们是有用的。正如在第7章的介绍中谈到的，它们带来了许多可能的问题（并发写入、约束冲突、崩溃、网络中断、磁盘故障），并将它们归结为两种可能的结果：提交或是中止。这是对编程模型的极大简化，但是我担心这还是不够。

事务的代价很高，特别是当它们涉及到异构的存储技术的时候（见“实际中的分布式事务”一节）。当我们因为分布式事务代价太高而拒绝使用它们时，我们最终不得不在应用程序代码中重新实现容错机制。正如本书中的大量示例证明的，关于并发性和部分失效的推理相当困难，而且违反直觉，因此我怀疑大多数应用级别的机制是不能正确工作的。结果是数据的丢失或损坏。

由于这些原因，我认为可以简单地提供针对特定应用端到端正确性，同时还能在大型分布式环境中保持良好的性能和运营特性的容错抽象是值得探索的。

### 强制约束

让我们在拆解数据库（见“拆解数据库”一节）的思路下思考一下正确性。我们看到，端到端抑制重复可以通过一个从客户端一直传到记录写入的数据库的请求ID实现。那么其他类型的约束呢？

特别是，让我们关注唯一性约束——比如我们在示例12-2中用到的约束。在“约束和唯一性保证”一节中，我们看到了应用程序特性需要强制唯一性的其它几个例子：用户名或电子邮件地址必须唯一地标识用户，文件存储服务不能有多个同名文件，两个人不能在同一个航班上或剧院中预订相同的座位。

其他类型的约束也是非常相似的：比如，确保帐户余额不会为负数，你不会卖出比仓库库存更多的物品，会议室不会有相互重叠的预订。强制唯一性的技术通常也可以用于这类约束。

#### 唯一性约束需要协商一致

在第9章中我们看到在分布式环境中，执行唯一性约束需要协商一致：如果有几个并发请求具有相同的值，系统需要以某种方式决定哪个冲突操作被接受，并且认定其它操作违反了约束条件而拒绝。

实现协商一致最常见方式是让一个节点成为主机，让它负责所有决策。只要你不介意所有的请求都通过单个节点（即使客户端在世界的另一端），只要这个节点没有失效，就可以工作地很好。如果你需要容忍主机失效，就又回到了协商一致问题上（见“单主机复制与协商一致”一节）。

唯一性检查可以根据需要唯一的值进行分区进行横向扩展。比如说，如果需要通过请求ID确保唯一性，就好像例12-2中一样，那么可以确保所有有着相同请求ID的请求都被转发到同一个分区（见第6章）。如果你需要用户名是唯一的，那么你可以基于用户名的哈希值进行分区。

然而，异步的多主机复制被排除在外，因为可能会发生不同的主程序并发地接受了相互冲突的写入，因此这些值不再是唯一的（见“实现可线性化的系统”一节）。如果你希望能够立即拒绝任何违反约束的写入，那么同步协调就是不可避免的。

#### 基于日志的消息传递系统中的唯一性

日志确保所有消费者都以相同的顺序查看消息——这是一种正式称为*全序广播*的保证，它等效于协商一致（见“全序广播”一节）。如果拆解数据库的方法有基于日志的消息传递，我们可以使用非常类似的方法来强制唯一性约束。

流处理器在单个线程上顺序地消费一个日志分区中的所有消息（见“把日志与传统消息传递相比”一节）。因此，如果对日志进行的分区操作是基于值必须唯一，那么流处理器可以明确地决定几个冲突操作中哪一个最先出现。比如说，在几个用户试图占有相同用户名的情况下：

1. 申请用户名的每个请求都被编码为一条消息，然后被添加到由用户名的哈希值确定的分区中。

2. 流处理器顺序地读取日志中的众多请求，并使用本地数据库追踪哪些用户名已经被占用了。对于每个可用的用户名请求，它都会把用户名标记为已占用，并向输出流发送一条成功的消息。而对于每个已经被占用的用户名请求，它都会向输出流发出一条拒绝的消息。

3. 请求用户名的客户端监视输出流，等待与其请求相对应的成功或是拒绝的消息。

这个算法与“使用全序广播实现可线性化的存储”一节中的基本相同。由于每个分区可以独立地处理，所以通过增加分区的数目，它可以很容易地扩容，应对更大的请求吞吐量。

这种方法不仅适用于唯一性约束，也适用于许多其他类型的约束。它的基本原则是，任何可能冲突的写入都被转发到了同一个分区，然后按顺序处理。正如“什么是冲突？”以及“写偏与幻影”两节中所讨论的，冲突的定义可能取决于应用程序，但是流处理器可以使用任意逻辑来验证请求。这种想法与巴尤在1990年代开创的方法很类似。

#### 多分区的请求处理

当涉及多个分区时，在满足约束的同时确保操作的执行是原子性的就变得更加有趣了。在示例12-2中，可能有三个分区：包含请求ID的分区、包含收款方帐户的分区以及包含支付方帐户的分区。三者没有理由放在同一个分区里，因为它们都是相互独立的。

在传统的数据库方法中，执行这个事务需要在所有三个分区上执行原子提交，相对于这个分区上其它事务这本质上强行把它转化成了全序的。由于现在存在跨分区协调的问题，不同的分区不能再独立处理了，于是吞吐量很可能会受到影响。

然而事实证明，等效的正确性可以在没有原子提交的情况下用分区日志实现：

1. 客户端为将资金从帐户A转移到帐户B的请求赋予了一个唯一的请求ID，然后添加到了基于请求ID的日志分区中。

2. 流处理器读取请求日志。对于每个请求消息它会向输出流发出两条消息：向付款人帐户A（由A分区）发出借贷指令，向收款人帐户B发出信用指示（由B分区）。原始请求ID包含在这些发出的消息中。

3. 后续的处理器消费信用与借贷指令流，按请求ID去重，然后把变更应用到帐户余额。

步骤1与步骤2是必要的，因为如果客户端直接发送信用指令和借贷指令，就需要在这两个分区上进行原子提交，以确保两者都会发生，或者都不会发生。为了避免对分布式事务的需要，我们首先把请求作为单个消息持久地记录下来，然后从第一条消息中派生出信用与借贷指令。在几乎所有的数据系统中，单对象写入都是原子的（见“单对象写入”一节），因此请求要么出现在日志中，要么没有，而不需要多分区的原子提交。

如果步骤2中的流处理器崩溃，它将从上一个检查点处恢复处理。这样做，它不会跳过任何请求消息，但它有可能会多次处理请求，产生重复的信用和借贷指令。但是，由于它是确定性的，它只会再次产生相同的指令，步骤3中的处理器可以很容易地使用端到端的请求ID对它们进行去重。

如果要确保支付者帐户不会因此这次转账而透支，你可以使用额外的流处理器（按支付者的帐号进行分区）来维护帐户余额和验证事务。然后在步骤1中，只有有效的事务才会放在请求日志中。

通过把多分区事务分解为两个不同的分区阶段，并且使用端到端请求ID，我们实现了相同的正确性属性（每个请求恰好应用于付款人与受款人帐户一次），哪怕这是在存在故障的情况下，而且没有使用原子提交协议。使用多个不同分区阶段的想法类似于我们在“多分区数据处理”一节中讨论的内容（也参考“并发控制”一节）。

### 及时性与完整性

事务一个很方便的属性是它们通常是可线性化的（见“可线性化”一节）：也就是说，写者等待事务提交，之后它的写入对所有读者都是立即可见的。

在拆解横跨多个阶段流处理器的操作时，情况就不是这样的了：日志的消费者在设计上就是异步的，所以发送方不会等待消费者对消息的处理。然而客户端可以等待消息出现在输出流上。这就是我们在“基于日志的消息系统中的唯一性”一节中检查唯一性约束是否满足时的做法。

在这个例子里，唯一性检查的正确性不取决于消息的发送方是否等待结果。等待的目的只是可以同步通知发送方唯一性检查是否成功，但这个通知可以与消息的处理产生的效果解耦。

更广泛地说，我认为一致性一词把两个不同的需求混为一谈，值得分开考虑：

*及时性*

及时性意味着确保用户看到系统处于最新的状态。我们之前看到，如果用户从陈旧的数据副本中读取数据，他们可能会看到数据处于不一致的状态（见“复制滞后的问题”一节）。然而这种不一致是暂时的，最终只要等待然后再次尝试就可以解决。

CAP定理（见“可线性化的成本”一节）使用了可线性化意义上的一致性，这是实现及时性的有力途径。稍弱的及时性，比如写入后读取一致性（见“读取你自己的写入”一节）也是有用的。

*完整性*

完整性意味着没有损坏；即，没有数据丢失，也没有矛盾或是错误的数据。特别是，如果某些衍生数据集是某些底层数据的视图（见“从事件日志衍生当前状态”一节），那么衍生必须是正确的。举个例子，数据库索引必须正确地反映数据库的内容——缺少一些记录的索引是没有什么用的。

如果违反了完整性，那么这种不一致性就是永久的了：在大多数情况下，等待之后再次尝试不会修复数据库损坏。相反地，我们需要显式检查与修复。在ACID事务的情景下（见“ACID的含义”一节），一致性通常被理解为某种应用特定的完整性概念。原子性以及持久性是保持完整性的重要工具。

用短语的形式说：违反及时性的行为是“最终一致的”，而违反完整性的行为则是“永久不一致”。

我判断在大多数应用程序中，完整性比及时性更重要。违反及时性可能会很烦人，令人困惑，但违反了完整性会是灾难性的。

例如，在你的信用卡账单中，如果没有出现在过去24小时内发生的事务，这并不奇怪——这些系统有一定的滞后是正常的。我们知道银行以异步方式调节和结算交易，而及时性在这里并不是很重要。但是，如果账户余额不等于交易的总和加上先前的账户余额（总金额有错误），或者交易向你收取了费用但没有支付给商家（钱消失了），那将是非常糟糕的。这些问题都违反了系统的完整性。

#### 数据流系统的正确性

ACID事务通常同时提供及时性（比如，可线性化）与完整性（比如，原子提交）保证。因此，如果你从ACID事务的角度来处理应用程序的正确性，那么及时性和完整性之间的区别是相当无关紧要的。

另一方面，我们在本章中讨论到的基于事件的数据流系统的一个有趣的特性是，它们把时效性和完整性解耦。异步处理事件流时，及时性是无法保证的，除非你显式地构建那种在返回之前等待消息到达的消费者。但是完整性实际上是流系统的核心。

*恰好一次*或是*有效一次*语义（见“容错”一节）是一种维护完整性的机制。如果丢失了一个事件，或者一个事件生效了两次，数据系统的完整性就会被破坏。因此，可容错的消息传递与抑制重复（比如，幂等操作）对于在遇到故障时保持数据系统的完整性非常重要。

正如我们在上一节中所看到的，可靠的流处理系统可以在不需要分布式事务和原子提交协议的情况下保持完整性，这意味着它们可以以更好的性能与操作健壮性实现类似的正确性。实现这种完整性是通过多种机制的组合完成的：

* 把写操作的内容表示为单个消息，这可以很容易做原子地写入——一种非常适合事件溯源的方法（见“事件溯源”一节）

* 使用确定性衍生函数从单个消息衍生出其余所有的状态更新，类似于存储过程（见“实际串行执行”与“应用程序代码作为衍生函数”一节）

* 通过在所有的处理级别之间传递客户端生成的请求ID，从而启用端到端的抑制重复与幂等性操作

* 使消息变得不可变，并且允许时不时地重新处理衍生数据，使得从bug中恢复变得更容易（见“不可变事件的优点”一节）

在我看来，这种组合机制对于未来构建可容错的应用程序来说是一个非常有希望的方向。

#### 松散解读的约束条件

正如前面所讨论的，强制执行唯一性约束需要协商一致，通常是通过把特定分区中的所有事件发送到单个节点实现的。如果我们想要传统形式的唯一性约束，这种限制无法避免，流处理也无法避免。

然而，另一件需要认识到的事情是，许多真实世界里的应用程序实际上可以用很弱的唯一性概念来解决：

* 如果两个人同时注册了相同的用户名，或是预订了相同的座位，你可以向其中一人发送一条消息表示歉意，然后要求他们选择不同的位置。这种纠正错误的变更称为补偿事务。

* 如果顾客订购的物品数量比你仓库里的还要多，你可以订购更多的库存，为延误向顾客道歉，并给他们打折。这实际上与叉车在仓库里撞翻了一些物品，从而使你的库存比想象的要少之后你必须做的是一样的。因此无论如何，道歉工作流程都必须成为业务流程的一部分，因此可能不需要对库存中的项目数量有可线性化的约束。

* 同样，许多航空公司超售机票，期望一些乘客会错过他们的航班，还有许多酒店会超售房间，预计一些客人会取消预订。在这些情况下，由于商业原因故意违反了“每个座位一人”的限制，因此补偿流程（退款、升仓、在邻近酒店提供免费房间）就是用来处理供不应求的情况的。即使没有超售，也需要道歉和赔偿流程来处理因恶劣天气或是员工罢工而被取消的航班——从这些问题中恢复只是正常业务的一部分。

* 如果有人取出了比他的帐户余额更多的钱，银行可以向他们收取透支费，并要求他们偿还他们所欠的钱。通过限制每天的提款总额，银行的风险是有限的。

在许多业务环境中，暂时地违反约束条件，稍后再通过道歉来修复实际上是可以接受的。道歉的成本（在金钱或名誉方面）各不相同，但通常都很低：你不能撤销一封电子邮件，但你可以通过发送一封后续更正的邮件。如果你不小心向信用卡收取了两次费用，你可以退还其中一笔费用，而对你来说，费用只是手续费外加可能的客户投诉。一旦自动取款机中支付了钱，你无法直接取回，哪怕原则上如果账户透支而客户不偿还，你可以派收债人来收回这笔钱。

道歉的代价是否可以承受是一个商业上的决定。如果可以，那么在写入数据之前传统的检查所有约束的模型就是没有必要的限制，并且也不需要一个可线性化的约束。先乐观地进行一次写入然后再检查约束，也可以是一个合理的选择。你仍然可以保证验证发生在需要花费很大代价恢复的事情之前，但这并不意味着你必须在写入数据之前进行验证。

这些应用*确实*需要完整性：你不会想失去预订，或是因为不匹配的贷方和借方而让钱消失。但是它们在强制约束时*不*要求及时性：如果你卖出的物品比仓库里有的还多，你可以先道歉，事后再修复这个问题。这样做与我们在“处理写入冲突”一节中讨论的冲突解决方法类似。

#### 避免协调的数据系统

现在我们有了两项有趣的发现：

1. 数据流系统可以在没有原子提交、可线性化或者同步的跨分区协调机制下保持衍生数据的完整性保证。

2. 尽管严格的唯一性约束需要及时性与协调机制，然而只要在整个过程中都保持完整性，许多应用程序实际上都可以使用松散的约束条件，可以暂时地违反条件，之后再进行修复。

综上所述，这些发现意味着数据流系统可以为许多不需要协调机制的应用提供数据管理服务，同时仍然提供强的完整性保证。这种*避免协调机制*的数据系统有很大的吸引力：相比于需要执行同步协调的系统，它们可以有更好的性能和容错。

比如说，这样的系统可以在多个数据中心之间以多主机配置进行分布式操作，在不同地区之间进行异步复制。因为不需要同步的跨区域协调，任何一个数据中心都可以独立于其他数据中心运行。这种系统的及时性保证很弱——不引入协调机制就不可能是可线性化的——但是它仍然可以有强的完整性保证。

在这种情况下，可序列化的事务作为维护衍生状态的一部分仍然很有用，但它们可以在工作良好的小范围内运行。异构的分布式事务，比如XA事务（见“实践中的分布式事务”一节），就不需要了。在需要的地方仍然可以采用同步协调（举个例子，在无法恢复的操作之前强制执行严格的限制条件），但如果应用程序中只有一小部分需要同步协调，就不需要整个程序都付出协调的代价。

另一种看待协调机制与约束条件的方法是：它们减少了因为不一致而必须道歉的次数，但也有可能降低系统的性能和可用性，从而可能增加因为不可用而不得不道歉的次数。你不能把道歉的次数减少到零，但你可以为你的需求找到最好的妥协方案——一个既不存在太多不一致性，也不存在太多可用性问题的最佳选择。

### 信任，但是需要验证

我们所有关于正确性、完整性以及容错性的讨论都是在假设某些事情可能会出错，但其他事情不会的前提下进行的。我们把这些假设称为我们的*系统模型*（见“把系统模型映射到现实世界”一节）：举个例子，我们应该假设进程是会崩溃的，机器可能会突然失去电力，网络可以任意延迟或是丢弃消息。但是，我们也可能假设写入磁盘的数据在`fsync`之后不会丢失，内存中的数据不会损坏，CPU的乘法指令总是返回正确的结果。

这些假设是相当合理的，因为它们在大多数情况下都是正确的，如果我们必须不断地担心计算机会出错，就很难完成任何事情。传统上，系统模型采用二分法来处理错误：我们假设有些事情会发生的，而另一些事情则永远不会发生。实际上，这更多地是一个概率问题：有些事情更有可能发生，而另一些事情则不太可能发生。问题是，违反我们假设的情况是否经常发生，以致于我们在实践中会遇到它们。

我们已经看到，数据即使在磁盘上没有访问过的情况下就会损坏（见“复制和持久性”)，网络上的数据损坏有时可以绕过TCP冗余校验（见“弱形式的谎言”一节）。也许这是我们应该关注更多的事情？

我过去做过的一个应用程序收集了客户端的崩溃报告，其中一些只能用设备内存中的随机位翻转来解释。这似乎不太可能，但是如果你有足够的设备运行你的软件，即使是非常不可能的事情也会发生。除了由于硬件故障或辐射引起的随机内存损坏外，某些有问题的内从访问模式甚至可以在没有故障的内存中翻转比特——这种结果可以用来打破操作系统中的安全机制(这种技术称为*比特翻转攻击*)。一旦在更近的位置观察，硬件并不像它看上去的那样，是完美的抽象。

需要明确的是，随机比特翻转在现代硬件上仍然是非常少见的。我只想指出它们并非超出了可能的范围，因此它们值得注意。

#### 面对软件bug时维持完整性

除了这些硬件问题外，软件bug这种风险总是存在，它们不会被底层网络、内存或文件系统冗余校验捕获。即使是广泛使用的数据库软件也有bug：我亲历过MySQL未能正确维护唯一性约束，还有PostgreSQL的可序列化隔离级别出现了不正常的写偏，尽管MySQL和PostgreSQL是健壮的、受人好评的数据库，多年来一直历经过各种洗礼。在不太成熟的软件中，情况会更糟。

尽管在小心仔细的设计、测试和评审方面付出了很大的努力，但bug仍在蔓延。虽然它们很少见，而且最终会被发现并修复，但在这段时间内，这些bug仍会破坏数据。

当涉及到应用程序代码时，我们必须假设有更多的bug，因为大多数应用都没有经历过数据库代码经历过的的审查与测试量。许多应用甚至没有正确地使用数据库为保持完整性而提供的特性，例如外键或是唯一性约束。

ACID意义上的一致性（见“一致性”一节）基于这样的思想：数据库从一致状态开始，一个事务将其从一个一致状态转换到另一个一致状态。因此，我们期望数据库始终处于一致状态。但是，只有假设事务没有bug时这个概念才有意义。如果应用程序以某种错误的方式使用数据库，比如使用了弱的隔离级别，那么数据库的完整性就无法保证了。

#### 不要盲目相信它们答应你的事

由于硬件和软件并不总能达到我们期望的理想状态，数据损坏似乎迟早是不可避免的。因此，我们至少应该有一种找出数据是否已损坏的方法，以便我们可以修复它并试图追踪错误的来源。检查数据的完整性称为*审核*。

正如在“不可变事件的优点”一点中所讨论到的，审计不仅仅适用于财务应用。然而，可审计性在金融中是非常重要的，因为每个人都知道错误会发生，我们也都认识到需要能够检测和解决问题。

成熟的系统同样也倾向于考虑不太会出错的可能性，并管理这种风险。例如，诸如HDFS以及Amazon S3这样的大型存储系统并不完全信任磁盘：它们运行后台进程不断地读取文件，将它们与其他副本进行比较，并且把文件从一个磁盘移动到另一个以减少无声损坏的风险。

如果您想确保数据仍然在那里，就必须真正地读取并检查。大多数情况下它仍然在那，但如果不是你一定希望尽早发现。由于同样的原因，尝试时不时地从备份中恢复是很重要的——否则，当数据已经丢失的时候才发现备份也虽坏，就太晚了。不要盲目地相信所有一切都正常工作。

#### 验证的文化

像HDFS和S3这样的系统仍然需要假设磁盘大部分时间都能正常工作——这是一个合理的假设，但是与假设它们总是正确工作是不同的。然而，目前没有多少系统有这种“信任，但是需要验证”的方法，不停地审计自己。许多人认为，正确性保证是绝对的，没有对罕见的数据损坏可能性做任何规定。我希望在未来我们将看到更多不断检查自己的完整性的*自我验证*或*自我审计*系统，而不是依赖盲目的信任。

我担心ACID数据库的文化已经导致我们在盲目信任技术（比如事务机制）的基础上开发应用程序，并且忽略了过程中的任何类型的可审计性。由于我们所信赖的技术大部分时间运作得足够良好，审计机制不被认为是值得投资的。

但是后来数据库大环境发生了变化：在NoSQL的旗帜下，较弱的一致性保证成为规范，较为不成熟的存储技术得到广泛应用。然而，由于审计机制尚未开发出来，我们继续在盲目信任的基础上构建应用，尽管这种方法现在变得更加危险。让我们考虑一下关于可审核性的设计。

#### 为可审计性而设计

如果一个事务改变了数据库中的多个对象，那么很难在事后知道该事务意味着什么。即使你抓取了事务日志（见“变更数据捕获”），在各张表中的插入、更新与删除不一定可以清晰给出为什么做了这些操作的原因。决定了这些突变的应用逻辑的调用是临时的，不能重现。

相比之下，基于事件的系统可以提供更好的可审计性。在事件溯源的方法中，用户对系统的输入被表示为单个不可变事件，而任何导致的状态更新都是从该事件衍生的。派生可以有确定性和可重复性，从而在相同的事件日志上运行相同版本的衍生代码可以导致相同的状态更新。

明确数据流（见“批处理输出的哲学”一节）使得数据的*来源*更加清晰，这使得完整性检查更加可行。对于事件日志，我们可以用哈希值来检查事件存储是否已损坏。对于任何衍生状态，我们可以重新运行把它衍生出来的批处理器和流处理器，检查我们是否获得了相同的结果，或者甚至同时并行运行多余的衍生过程。

是确定性的且定义明确的数据流还可以更容易地跟踪调试系统的执行过程，从而判断它为什么做某件事。如果出现意外的情况，那么具备诊断能力，重现导致意外事件的确切情况是很有假直的——这是一种穿越时间的调试能力。
