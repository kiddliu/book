# 第十章 流处理

*一个切实可行的复杂系统势必是从一个切实可行的简单系统发展而来的。从头开始设计的复杂系统根本不切实可行，无法修修补补让它切实可行。你必须由一个切实可行的简单系统重新开始。*

约翰·盖尔，*系统学*（1975）

---

在第10章中，我们讨论了批处理——这是读取一组文件作为输入并生成一组输出文件的技术。输出是*衍生数据*的一种形式；也就是说，如果有必要，可以通过再次运行批处理过程重新创建的数据集。我们看到了如何使用这个简单而强大的想法来创建搜索索引、推荐系统、分析等等。

然而一个大前提贯穿整个第10章：即，输入是有界的——即已知且有限的大小——因此批处理过程知道它什么时候完成了对输入的读取。例如，位于MapReduce核心位置的排序操作必须先读取整个输入，然后才能开始产生输出：可能会发生最后一个输入记录按键排序值最小的情况，因此它就是是第一条输出记录，所以不可能提早启动输出。

实际上许多数据是没有限制的，因为它是随着时间的推移逐渐到达的：你的用户昨天和今天产生了数据，他们明天会继续生成更多的数据。除非你退出业务，否则这个过程永远没有尽头，因此数据集永远不会以任何有意义的方式“完成”。因此，批处理程序必须人为地把数据按固定时间间隔划分成块：例如，在每天结束时处理一天的数据值，或在每小时结束时处理这一小时的数据。

日常批处理遇到的问题是，输入的更改只会在一天之后的输出中反映出来，这对于许多不耐烦的用户来说太慢了。为了减少延迟，我们可以更频繁地运行处理——比如说，在每秒结束时处理一秒钟的数据——甚至是连续地处理，完全放弃固定的时间片而只处理发生的每一个事件。这就是*流处理*背后的理念。

一般来说，“流”指的是随着时间的推移逐渐可用的数据。这个概念出现在许多地方：在Unix的`stdin`和`stdout`中，编程语言（延迟加载列表）、文件系统API（例如Java的`FileInputStream`）、TCP连接、通过互联网发送音频视频等等。

在本章中，我们将把*事件流*看作一种数据管理机制：与我们在上一章中看到的批处理数据进行无界、增量处理的对应。我们首先会讨论如何在网络上表示、存储和传输流。在“数据库和流”一节中，我们将研究流和数据库之间的关系。最后，在“流的处理”一节中，我们会探索持续处理这些流的方法和工具，以及它们可用于构建应用程序的方法。

## 事件流的发送

在批处理的世界里，作业的输入和输出是文件（或许是在分布式文件系统上）。与流等价的东西是什么样子的？

当输入是文件（字节序列）的时侯，第一个处理步骤通常是把它解析为一系列的记录。在流处理中，记录更常见的名字是*事件*，但本质上是一个东西：一个小的、独立的、不可变的对象，包含了在某个时间点发生的事情的细节。事件通常包含一个时间戳，指的是事件发生时的现世时钟时间（见“单调时钟与现世时钟”）。

例如，发生的事情可能是用户采取的一个操作，例如查看页面或购买。它也可能来自于设备，比如温度传感器的周期性测量，或者是CPU利用率指标。在“使用Unix工具进行批处理”一节的示例中，Web服务器日志的每一行都是一个事件。

如第4章所述，事件可能被编码为文本字符串，或者JSON，或者以某种二进制形式编码。这种编码使得你可以存储事件，比如说可以把它附加到文件，插入到关系性表格，亦或是写入文档型数据库。它还允许你通过网络把事件发送到另一个节点处理。

在批处理中，文件被写入一次，然后会被多个作业读取。类似地，在流的术语中，事件由*生产者*（也称为*发布者*或*发件人*）生成一次，然后可能被多个*消费者*（*订阅者*或*收件人*）处理。在文件系统中，文件名标识一组相关的记录；在流系统中，相关事件通常被分组成为一个*主题*或是*流*。

原则上，文件或是数据库足以连接生产者和消费者：生产者把它生成的每个事件都写入数据存储，而每个消费者定期轮询数据存储以检查自上次运行以来出现的新事件。这基本上是批处理过程在每天结束时处理一整天产生的数据时所做的事情。

然而，向低延迟连续处理发展的时侯，如果数据存储不是为了这一类使用而设计的，轮询的代价就会变得非常高。轮询次数越多，请求返回新事件的百分比就越低，开销因此也就越高。相反地，在新事件出现的时侯通知消费者就好很多。

数据库向来对这种通知机制支持得不是很好：关系型数据库通常有*触发器*，可以对更改作出反应（比如新的一行插入到表中），但它们所能做的非常有限，是数据库设计中之后才考虑到的。取而代之的是，已经有了专门的工具来传递事件通知。

### 消息系统

通知消费者新事件的一种常见方法是使用*消息传递系统*：生产者发送包含这个事件的消息，之后把这个事件推送给消费者。我们之前曾经在“用于消息传递的数据流”一节中讨论过这些系统，现在我们会更详细地讨论这些系统。

生产者和消费者之间直接通信的通道，比如Unix管道或者是TCP连接，是实现消息系统的一种简单方法。然而，大多数消息系统都是在这个基本模型上扩展的。特别的是，Unix管道与TCP都只连接一个发件人与一个收件人，而消息系统则允许多个生产者节点向同一主题发送消息，也允许多个消费者节点在主题中接收消息。

在这个*发布/订阅模型*中，不同的系统采用了各种各样的方法，也没有一个正确的方法可以满足所有的目的。为了区分这些系统，问下面两个问题特别有帮助：

1. *如果生产者发送消息的速度超过了消费者处理的速度，会发生什么？*广义地说有三种选择：系统可以丢弃消息、在队列中缓冲消息或应用*反向压力*（也称为*流量控制*；即，阻止生产者发送更多消息)。例如，Unix管道和TCP使用反向压力：它们有一小块固定大小的缓冲区，如果它被填满，发送方会被阻塞直到接收方从缓冲区中取出数据（请参阅“网络拥塞和排队”）。

    如果消息缓冲在队列中，那么了解队列增长时会发生什么是很重要的。如果内存放不下队列系统会崩溃么，还是它会把消息写入磁盘？如果会写入磁盘，那么这样做是如何影响消息传递系统的性能的？

2. *如果节点崩溃或是暂时离线，会发生什么？有丢失任何消息吗？*与数据库一样，耐久性会要求要么写入磁盘，要么复制到其它设备，或者二者都有（见“复制与耐久性”的边栏），这都是有代价的。如果你可以接受有时消息会丢失，那么在同样的硬件上你会获得更高的吞吐量和更低的延迟。

消息丢失是否可以接受，很大程度上取决于应用程序。例如，对于周期性传输的传感器读数和指标，偶尔丢失数据可能并无大碍，因为不管怎样更新的值晚些就会发出。然而需要注意的是，如果大量消息被丢弃，有可能没有办法立即发现这些指标是不正确的。如果你正在对事件计数，那么可靠地传递是更重要的，因为每一条丢失的消息都意味着不正确的计数值。

我们在第10章中研究的批处理系统有一个优点，那就是它们提供了很强的可靠性保证：失败的任务自动重试，失败任务的部分输出自动丢弃。这意味着如果没有发生错误，输出都是一样的，这有助于简化编程模型。在这一章稍后，我们将研究如何在流中提供类似的保证。

#### 生产者直接向消费者传递信息

许多消息传递系统使用生产者和消费者之间的直接网络通信，而不通过中间节点：

* UDP组播在金融行业中被广泛应用于诸如股票市场提要这样的流中，在这些流中低延迟是非常重要的。尽管UDP本身是不可靠的，但应用程序级别的协议可以恢复丢失的数据包（生产者必须记住它发送的数据包，以便按需重新传输它们）。

* 诸如ZeroMQ和nanomsg这样的无代理消息库采取了类似的方法，通过TCP或IP多播实现发布/订阅消息传递。

* StatsD与Brubeck使用不可靠的UDP消息来收集网络上所有设备的指标，并监视它们。（在StatsD协议中，只有在接收到所有消息时计数器值才是正确的；使用UDP使得指标只是最好的近似值。也请参阅“TCP与UDP”一节）

* 如果消费者在网络上公开了一个服务，生产者可以直接发出HTTP或RPC请求（见“透过服务的数据流：REST与RPC”一节）把消息推送给消费者。这就是webhook背后的理念，在这种模式中，一个服务的回调URL被注册到另一个服务中，每当发生事件时，它都会向该URL发出请求。

尽管这些直接消息传递系统在所设计的情况下运行良好，但它们通常要求应用程序代码注意消息丢失的可能性。他们所能容忍的错误是非常有限的：即使协议检测并重新传输网络中丢失的数据包，它们通常也假定生产者和消费者一直在线。

如果消费者离线，它可能会错过消息无法送达时发出的消息。有些协议允许生产者重发失败的消息，但是如果生产者崩溃，这种方法也就失效了，也失去所有缓冲区内的消息。

#### 消息代理

一种广泛使用的替代方案是通过*消息代理*（也称为消息队列）发送消息，它本质上是一种为处理消息流而优化的数据库。它作为服务器运行，生产者和消费者作为客户端连接到它。生产者将消息写入代理，消费者通过从代理读取消息来接收消息。

通过把数据集中在代理中，这些系统可以更容易地容忍来来去去的客户机（连接、断开和崩溃），而且持久性的问题也被转移到代理上。一些消息代理只把消息保存在内存中，而另一些消息代理（取决于配置）把它们写入磁盘，以便在代理崩溃时不会弄丢它们。面对缓慢的消费者，他们通常允许无限制排队（而不是丢弃消息或是反向压力），尽管这种选择也会取决于配置。

排队的结果也导致消费者通常是*异步的*：当生产者发送消息时，它通常只等待代理确认它已经缓存了消息，而不会等待消息被消费者处理。对消费者的交付将发生在未来的某个时间点——通常在一秒内，但如果存在队列积压，有时会明显更久一些。

#### 消息代理与数据库的比较

一些消息代理甚至可以参与到使用XA或JTA的两阶段提交协议（见“实践中的分布式事务”一节）。这一特性使它们在性质上与数据库非常相似，尽管消息代理和数据库之间仍然存在着重要的实际差异：

* 数据库通常会保存数据，直至它被显式地删除，而大多数消息代理在消息成功传递给消费者后会自动删除它。这样的消息代理不适合长期的数据存储.

* 由于会很快地删除消息，因此大多数消息代理都假定它们的工作集相当小——即队列很短。如果因为消费者速度缓慢（也许是因为内存无法容纳更多地消息，导致消息溢出到磁盘）代理需要缓冲大量消息，那么每个消息需要更长的时间来处理，导致总体吞吐量会下降。

* 数据库通常支持次级索引以及各种数据搜索方式，而消息代理通常支持订阅与某种模式匹配的主题子集的某种方式。这些机制是不同的，但本质上这两种方法都是客户端选择它想知道的数据部分的方法。

* 在查询数据库时，结果通常基于数据某个时间点的快照；如果另一个客户端随后向数据库写入了改变了查询结果的内容，第一个客户端不会发现先前的结果现在已经过时（除非它重复查询，或者轮询变更）。相比之下，消息代理不支持任意查询，但是它们确实在数据更改时通知客户端（即，新消息可用时）。

这是对消息代理的传统视角，它被封装在JMS和AMQP等标准中，并在诸如RabbitMQ、ActiveMQ、HornetQ、Qpid、TIBCO企业消息服务、IBM MQ、Azure服务总线和Google Cloud Pub/Sub等软件中实现。

#### 多个消费者

当多个消费者读取同一主题中的消息时，主要使用两种消息传递模式，如图11-1所示：

*负载均衡*

每条消息都被传递给*一*个消费者，这样消费者就可以在主题中共享处理消息的工作。代理可以把消息指定给任意消费者。当消息处理成本很高时这个模式非常有用，因此你希望能够添加使用者来并行处理。（在AMQP中，你可以通过让多个客户端从同一个队列消费来实现负载平衡，而在JMS中它被称为*共享订阅*。）

*散出*

每条消息都被传递给*所有*的消费者。散出允许多个独立的消费者“收听”到相同的消息广播，而互不影响——这种流相当于有几个不同的批处理作业读取相同的输入文件。（JMS中的主题订阅和AMQP中的交换绑定提供了这个特性。）

Each message is delivered to *all* of the consumers. Fan-out allows several independent consumers to each “tune in” to the same broadcast of messages, without affecting each other — the streaming equivalent of having several different batch jobs that read the same input file. (This feature is provided by topic subscriptions in JMS, and exchange bindings in AMQP.)

*图11-1. (a) 负载平衡: 把消费主题的工作在消费者中共享； (b) 散出: 把每个消息发送给多个消费者。*

这两种模式可以组合在一起：例如，两组不同的使用者可以订阅一个主题，这样每个组可以集体接收所有消息，但是在每个组中只有一个节点接收到每个消息。

#### Acknowledgments and redelivery

消费者可能随时崩溃，因此可能发生这样的情况：代理消息传递给消费者，但消费者没有处理它，或者在崩溃之前只对其进行了部分的处理。为了确保消息不丢失，消息代理使用*应答消息*：客户端在处理消息完成后必须显式地告诉代理，以便代理可以把它从队列中删除。

如果到客户端的连接关闭或超时，而代理没有收到应答，它会假定消息没有被处理，于是它会再次把消息传递给另一个消费者。（请注意，消息实际上*已经*被完全处理但是应答消息在网络中丢失了，这是会发生的。处理这种情况需要原子提交协议，如“实践中的分布式事务”一节中所讨论的那样。）

与负载平衡相结合的时候，这种重发行为对消息排序的影响很有趣。在图11-2中，消费者通常按照生产者发送消息的顺序处理消息。然而，消费者2在处理消息*m3*时崩溃，同时消费者1正在处理消息*m4*。随后把未经确认的消息*m3*重新传递给消费者1，结果消费者1按照*m4*、*m3*、*m5*的顺序处理消息。因此，*m3*和*m4*的交付顺序与生产者1发送的顺序不同。

*图11-2. 消费者2在处理m3的时候崩溃，于是稍后m3被重新发送到消费者1。*

即使消息代理尝试保护消息的顺序（根据JMS和AMQP标准的要求），负载平衡与重发的组合不可避免地导致消息被重新排序。为了避免这个问题，你可以为每个消费者使用独立的队列（即，不使用负载平衡特性）。如果消息完全相互独立，消息重新排序不是问题，但是如果消息之间存在因果依赖关系这就很重要了，这一点我们将在这一章后面看到。

### 分区日志

通过网络发送数据包，或是向网络服务发出请求通常是暂时的操作，不会留下永久的跟踪记录。虽然是可以永久记录它（使用数据包捕获和日志记录），但我们通常不会这样想。即使是那些把消息固化到磁盘的消息代理，在消息传递给消费者之后也会很快再次删除它们，因为这些都是建立在短暂的消息传递思维基础上的。

数据库和文件系统采取相反的方法：写入数据库或文件的所有内容通常都会被永久记录，至少直到有人显式地选择再次删除为止。

这种思维方式的差异对衍生数据的构建方式有很大的影响。正如第10章中所讨论的，批处理过程的一个关键特性是你可以重复运行它们，试验处理步骤，而没有损坏输入的风险（因为输入是只读的）。AMQP/JMS风格的通信不是这样的：如果应答导致消息从代理中删除，那么接收消息就是破坏性的，所以你不能再次运行相同的消费者并期望得到相同的结果。

如果添加新的消费者到消息传递系统，它通常只在注册之后才可以接收消息；任何之前的消息都已经不在了，也无法恢复。与文件和数据库相比，你可以在任何时候添加一个新客户端，并且它可以读取过去任意写入的数据（只要它还没有被应用程序显式覆盖或删除）。

为什么我们不能把数据库的持久存储方法与消息传递的低延迟通知功能结合起来呢？这就是*基于日志的消息代理*背后的理念。

#### 使用日志进行消息存储

日志就是磁盘上只可附加的记录序列。我们先前在第3章中讨论日志结构存储引擎与预写入上下文中的日志和写前日志，在第5章中讨论了复制上下文中的日志。

A log is simply an append-only sequence of records on disk. We previously discussed logs in the context of log-structured storage engines and write-ahead logs in Chapter 3, and in the context of replication in Chapter 5.

The same structure can be used to implement a message broker: a producer sends a message by appending it to the end of the log, and a consumer receives messages by reading the log sequentially. If a consumer reaches the end of the log, it waits for a notification that a new message has been appended. The Unix tool `tail -f`, which watches a file for data being appended, essentially works like this.

In order to scale to higher throughput than a single disk can offer, the log can be *partitioned* (in the sense of Chapter   6). Different partitions can then be hosted on different machines, making each partition a separate log that can be read and written independently from other partitions. A topic can then be defined as a group of partitions that all carry messages of the same type. This approach is illustrated in Figure   11-3.

Within each partition, the broker assigns a monotonically increasing sequence number, or *offset*, to every message (in Figure   11-3, the numbers in boxes are message offsets). Such a sequence number makes sense because a partition is append-only, so the messages within a partition are totally ordered. There is no ordering guarantee across different partitions.

*Figure 11-3. Producers send messages by appending them to a topic-partition file, and consumers read these files sequentially.*

Apache Kafka, Amazon Kinesis Streams, and Twitter’s DistributedLog are log-based message brokers that work like this. Google Cloud Pub/Sub is architecturally similar but exposes a JMS-style API rather than a log abstraction. Even though these message brokers write all messages to disk, they are able to achieve throughput of millions of messages per second by partitioning across multiple machines, and fault tolerance by replicating messages.