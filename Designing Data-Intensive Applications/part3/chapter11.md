# 第十章 流处理

*一个切实可行的复杂系统势必是从一个切实可行的简单系统发展而来的。从头开始设计的复杂系统根本不切实可行，无法修修补补让它切实可行。你必须由一个切实可行的简单系统重新开始。*

约翰·盖尔，*系统学*（1975）

---

在第10章中，我们讨论了批处理——这是读取一组文件作为输入并生成一组输出文件的技术。输出是*衍生数据*的一种形式；也就是说，如果有必要，可以通过再次运行批处理过程重新创建的数据集。我们看到了如何使用这个简单而强大的想法来创建搜索索引、推荐系统、分析等等。

然而一个大前提贯穿整个第10章：即，输入是有界的——即已知且有限的大小——因此批处理过程知道它什么时候完成了对输入的读取。例如，位于MapReduce核心位置的排序操作必须先读取整个输入，然后才能开始产生输出：可能会发生最后一个输入记录按键排序值最小的情况，因此它就是是第一条输出记录，所以不可能提早启动输出。

实际上许多数据是没有限制的，因为它是随着时间的推移逐渐到达的：你的用户昨天和今天产生了数据，他们明天会继续生成更多的数据。除非你退出业务，否则这个过程永远没有尽头，因此数据集永远不会以任何有意义的方式“完成”。因此，批处理程序必须人为地把数据按固定时间间隔划分成块：例如，在每天结束时处理一天的数据值，或在每小时结束时处理这一小时的数据。

日常批处理遇到的问题是，输入的更改只会在一天之后的输出中反映出来，这对于许多不耐烦的用户来说太慢了。为了减少延迟，我们可以更频繁地运行处理——比如说，在每秒结束时处理一秒钟的数据——甚至是连续地处理，完全放弃固定的时间片而只处理发生的每一个事件。这就是*流处理*背后的理念。

一般来说，“流”指的是随着时间的推移逐渐可用的数据。这个概念出现在许多地方：在Unix的`stdin`和`stdout`中，编程语言（延迟加载列表）、文件系统API（例如Java的`FileInputStream`）、TCP连接、通过互联网发送音频视频等等。

在本章中，我们将把*事件流*看作一种数据管理机制：与我们在上一章中看到的批处理数据进行无界、增量处理的对应。我们首先会讨论如何在网络上表示、存储和传输流。在“数据库和流”一节中，我们将研究流和数据库之间的关系。最后，在“流的处理”一节中，我们会探索持续处理这些流的方法和工具，以及它们可用于构建应用程序的方法。

## 事件流的发送

在批处理的世界里，作业的输入和输出是文件（或许是在分布式文件系统上）。与流等价的东西是什么样子的？

当输入是文件（字节序列）的时侯，第一个处理步骤通常是把它解析为一系列的记录。在流处理中，记录更常见的名字是*事件*，但本质上是一个东西：一个小的、独立的、不可变的对象，包含了在某个时间点发生的事情的细节。事件通常包含一个时间戳，指的是事件发生时的现世时钟时间（见“单调时钟与现世时钟”）。

例如，发生的事情可能是用户采取的一个操作，例如查看页面或购买。它也可能来自于设备，比如温度传感器的周期性测量，或者是CPU利用率指标。在“使用Unix工具进行批处理”一节的示例中，Web服务器日志的每一行都是一个事件。

如第4章所述，事件可能被编码为文本字符串，或者JSON，或者以某种二进制形式编码。这种编码使得你可以存储事件，比如说可以把它附加到文件，插入到关系性表格，亦或是写入文档型数据库。它还允许你通过网络把事件发送到另一个节点处理。

在批处理中，文件被写入一次，然后会被多个作业读取。类似地，在流的术语中，事件由*生产者*（也称为*发布者*或*发件人*）生成一次，然后可能被多个*消费者*（*订阅者*或*收件人*）处理。在文件系统中，文件名标识一组相关的记录；在流系统中，相关事件通常被分组成为一个*主题*或是*流*。

原则上，文件或是数据库足以连接生产者和消费者：生产者把它生成的每个事件都写入数据存储，而每个消费者定期轮询数据存储以检查自上次运行以来出现的新事件。这基本上是批处理过程在每天结束时处理一整天产生的数据时所做的事情。

然而，向低延迟连续处理发展的时侯，如果数据存储不是为了这一类使用而设计的，轮询的代价就会变得非常高。轮询次数越多，请求返回新事件的百分比就越低，开销因此也就越高。相反地，在新事件出现的时侯通知消费者就好很多。

数据库向来对这种通知机制支持得不是很好：关系型数据库通常有*触发器*，可以对更改作出反应（比如新的一行插入到表中），但它们所能做的非常有限，是数据库设计中之后才考虑到的。取而代之的是，已经有了专门的工具来传递事件通知。

### 消息系统

通知消费者新事件的一种常见方法是使用*消息传递系统*：生产者发送包含这个事件的消息，之后把这个事件推送给消费者。我们之前曾经在“用于消息传递的数据流”一节中讨论过这些系统，现在我们会更详细地讨论这些系统。

生产者和消费者之间直接通信的通道，比如Unix管道或者是TCP连接，是实现消息系统的一种简单方法。然而，大多数消息系统都是在这个基本模型上扩展的。特别的是，Unix管道与TCP都只连接一个发件人与一个收件人，而消息系统则允许多个生产者节点向同一主题发送消息，也允许多个消费者节点在主题中接收消息。

在这个*发布/订阅模型*中，不同的系统采用了各种各样的方法，也没有一个正确的方法可以满足所有的目的。为了区分这些系统，问下面两个问题特别有帮助：

1. *如果生产者发送消息的速度超过了消费者处理的速度，会发生什么？*广义地说有三种选择：系统可以丢弃消息、在队列中缓冲消息或应用*反向压力*（也称为*流量控制*；即，阻止生产者发送更多消息)。例如，Unix管道和TCP使用反向压力：它们有一小块固定大小的缓冲区，如果它被填满，发送方会被阻塞直到接收方从缓冲区中取出数据（请参阅“网络拥塞和排队”）。

    如果消息缓冲在队列中，那么了解队列增长时会发生什么是很重要的。如果内存放不下队列系统会崩溃么，还是它会把消息写入磁盘？如果会写入磁盘，那么这样做是如何影响消息传递系统的性能的？

2. *如果节点崩溃或是暂时离线，会发生什么？有丢失任何消息吗？*与数据库一样，耐久性会要求要么写入磁盘，要么复制到其它设备，或者二者都有（见“复制与耐久性”的边栏），这都是有代价的。如果你可以接受有时消息会丢失，那么在同样的硬件上你会获得更高的吞吐量和更低的延迟。

消息丢失是否可以接受，很大程度上取决于应用程序。例如，对于周期性传输的传感器读数和指标，偶尔丢失数据可能并无大碍，因为不管怎样更新的值晚些就会发出。然而需要注意的是，如果大量消息被丢弃，有可能没有办法立即发现这些指标是不正确的。如果你正在对事件计数，那么可靠地传递是更重要的，因为每一条丢失的消息都意味着不正确的计数值。

我们在第10章中研究的批处理系统有一个优点，那就是它们提供了很强的可靠性保证：失败的任务自动重试，失败任务的部分输出自动丢弃。这意味着如果没有发生错误，输出都是一样的，这有助于简化编程模型。在这一章稍后，我们将研究如何在流中提供类似的保证。

#### 生产者直接向消费者传递信息

许多消息传递系统使用生产者和消费者之间的直接网络通信，而不通过中间节点：

* UDP组播在金融行业中被广泛应用于诸如股票市场提要这样的流中，在这些流中低延迟是非常重要的。尽管UDP本身是不可靠的，但应用程序级别的协议可以恢复丢失的数据包（生产者必须记住它发送的数据包，以便按需重新传输它们）。

* 诸如ZeroMQ和nanomsg这样的无代理消息库采取了类似的方法，通过TCP或IP多播实现发布/订阅消息传递。

* StatsD与Brubeck使用不可靠的UDP消息来收集网络上所有设备的指标，并监视它们。（在StatsD协议中，只有在接收到所有消息时计数器值才是正确的；使用UDP使得指标只是最好的近似值。也请参阅“TCP与UDP”一节）

* 如果消费者在网络上公开了一个服务，生产者可以直接发出HTTP或RPC请求（见“透过服务的数据流：REST与RPC”一节）把消息推送给消费者。这就是webhook背后的理念，在这种模式中，一个服务的回调URL被注册到另一个服务中，每当发生事件时，它都会向该URL发出请求。

尽管这些直接消息传递系统在所设计的情况下运行良好，但它们通常要求应用程序代码注意消息丢失的可能性。他们所能容忍的错误是非常有限的：即使协议检测并重新传输网络中丢失的数据包，它们通常也假定生产者和消费者一直在线。

如果消费者离线，它可能会错过消息无法送达时发出的消息。有些协议允许生产者重发失败的消息，但是如果生产者崩溃，这种方法也就失效了，也失去所有缓冲区内的消息。

If a consumer is offline, it may miss messages that were sent while it is unreachable. Some protocols allow the producer to retry failed message deliveries, but this approach may break down if the producer crashes, losing the buffer of messages that it was supposed to retry.