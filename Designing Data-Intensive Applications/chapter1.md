# 第一章 可靠的、可扩展的、可维护的应用程序

*Internet是如此得成功以至于绝大多数人们以为它就像太平洋一样是一种自然资源，而不是人们动手建立起来的。上一次出现这种有着如此规模却又近乎完美的技术是什么时候来着？*

摘自Alan Kay在2012年Dr Dobb期刊中的访谈

今天许多的应用程序不是*计算集约*而是*数据集约型的*了。对于这些应用程序，CPU的性能很少是瓶颈了——更大的问题是数据的数量、数据的复杂度以及数据变化的速度。

一个数据集约型的应用程序通常由满足一般性需求功能的标准构建模块构建的。举个例子来说，许多应用程序都需要：
* 存储数据从而它们自己，或者其他应用程序可以稍后使用（数据库）
* 存储代价高的运算结果，从而提升访问速度（缓存）
* 允许用户通过各种方式进行关键词搜索或者过滤（搜索索引）
* 向其它进程发送消息，进行异步处理（流处理）
* 周期性的处理大量的累积数据（批处理）

如果这些都听起来相当的显而易见，这正是因为这些*数据系统*是一种成功的抽象：我们一直使用着它们却没有思考太多。构建应用程序的时候，绝大部分工程师不会想着从头开始写一个新的数据存储引擎，毕竟数据库是可以完美胜任这项工作的。

但是现实可没有这么简单。因为不同的应用程序有着不同的需求，于是也就有了许多特性各不相同的数据库系统。同样也有许多种方式实现缓存，简历搜索索引，等等等等。构建应用程序的时候，我们仍然需要搞清楚哪些工具、哪些解决方式对于手边的任务是最合适的。当单一工具无法解决问题的时候，组合不同的工具本身就是难题。

这本书既讨论数据系统的原则也讨论实用性的问题，以及你可以如何使用它们来构建数据集约型的应用程序。我们将探索不同工具之间的共性、差别、以及它们是如何实现不同特性的。

在这一章的开始，我们将探索我们尝试实现的可靠的、可扩展的、可维护的数据系统
的基础部分。我们将阐明它们的含义，提炼一些思考它们的方式，并对后续章节用到的基础知识一一复习。而在稍后几章我们将逐一解析在设计数据集约型应用时那些需要考虑到的设计决定。

## 想想数据系统

我们通常认为数据库、队列、缓存等等是非常不同类别的工具。虽然表面上数据库与消息队列有一些类似——两者都在一段时间内储存数据——然而它们有着非常不同的访问模式，这意味着非常不同的性能特性，并因此有着非常不同的实现。

那我们为什么要把它们都归结为*数据系统*呢？

最近一些年出现了许多新的数据存储与处理工具。它们针对各种各样不同的用例优化，而不再适合归结为传统的一类。比如说，现在有了也可以用作消息队列的数据存储（Redis），也有了类似数据库一样持久性保证的消息队列（Apache Kafka）。这些类别之间的边界渐渐模糊起来。

其次，越来越多的应用程序现在有着越来越多越来越广的需求，以至于单一工具不再能满足所有的数据处理以及储存需求。取而代之的是这些工作被拆分成了许多小任务，每一个任务都*能*被单一工具有效的处理，而应用程序代码把这些工具连在了一起。

假如说你有一个应用程序管理的缓存层（借助Memcached或者类似工具），或者一个与主数据库分离的全文搜索服务器（比如Elasticsearch或者Solr），一般地保证缓存、索引与主数据库同步是应用程序代码的责任。图1-1大致给出了这也许是什么样的（我们会在稍后章节详细讨论）

*图1-1 一种结合了数个模块的数据系统架构*

为了提供服务而合并数个工具时，服务的接口或者是应用编程接口（API）通常会向客户端隐藏这些实现细节。这时事实上你已经用较小的通用模块创建了一个新的、有着特定用途的数据系统。你合成的数据系统也许可以保证，比如说，缓存在被写入时将被正确的校验、更新从而客户端可以得到持续一致的结果。这时你也不再只是一个应用程序开发者，同时也是一个数据系统设计者了。

如果你现在正在设计一个数据系统或者服务，一大堆复杂的问题会冒出来。你将如何保证数据的正确性与完整性，即使在系统内部出错的情况？你将如何向众多客户端提供持续一致的良好性能，即使部分系统性能降级？你将如何扩展系统以应对负载上升？对于服务来说一个好的API应该是什么样的？

有许多因素会影响一个数据系统的设计，它包括了参与者的技能与经验，对遗留系统的依赖程度，产品交付的时间表，所在组织对于不同种类风险的忍耐度，各种监管约束等等。这些因素都取决于当前的情况。

在这本书里，我们聚焦于三个方面的考虑，它们对大多数软件系统都非常重要：

*可靠性*

即使不幸遇到错误（硬件或者软件错误，甚至认为错误）系统应当可以继续正常工作（以期望的性能水平执行正确的功能）。详见“可靠性”。

*可扩展性*

随着系统（在数据量，通讯量，或者复杂度方面）增长，应当有合理的方法来应对。详见“可扩展性”。

*可维护性*

随着时间的推移，许多不同的人将在系统上工作（工程方面与运营方面，双方都维护当前的功能并尝试使系统适应新的用例），他们应当可以富有成效地一起工作。详见“可维护性”。

这几个词经常在不清楚它们确切含义的情况下被用来用去。从值得思考的工程学角度出发，在这一章余下的部分我们将探索关于可靠性、可扩展性、可维护性的思维方式。接着，在后续的章节中，我们会看到实现这些目标的众多技术手段、架构以及算法。

## 可靠性

每个人对于一个东西可靠与否的含义都有直观的认识。对于软件来说，典型的期望包含：

* 应用程序可以执行用户期望的功能。
* 它容许用户犯错，或者以意想不到的方式使用。
* 对于必要的用例，在期望的负载与数据量场景下它的性能是足够好的。
* 系统可以阻止任何未授权的访问和滥用。

如果所有这些加起来意味着“工作正常”，那么我们可以理解*可靠性*，大概，意味着“可以持续正常工作，哪怕出错的情况下”。

这些出错的情况被叫做*故障（faults）*，那些预知并可以应对故障的系统被叫做*可容错的*或是*弹性的*。前一个术语有点误导人：它暗示着我们可以构建一个容忍各种可能故障的系统，而事实上这不太切实际。假如整个地球（还有上面所有的服务器）都被一个黑洞吞噬了，要容忍这样一个故障就要求在太空中进行网络托管——祝你在申请经费的时候好运。因而只针对特定类型故障进行容错才是合理的。

注意，故障并不是罢工。故障通常被定义为系统的某个组件没有按照规范执行，而罢工是指系统作为一个整体不能再向用户提供必要的服务。把故障的可能性降到零是不可能的；于是通常会设计容错机制从而防止故障引起罢工。我们会在这本书中介绍集中用不可靠的部件构建可靠系统的技巧。

与我们的直觉恰恰相反的是在这些可容错的系统中，通过有意触发故障*增加*故障率是合理的——比如说在毫无警告的情况下随机杀死一些独立进程。许多严重的错误实际上都是因为差劲的错误处理导致的；通过有意诱发故障，确保容错机制持续地应用与测试，从而在故障真正发生的时候确信它们可以被正确的处理。Netflix公司的工具Chaos Monkey就是这种方式的一个例证。

虽然相对于预防故障我们一般更倾向容错，也有一些例证证明预防更好（比如，根本无法解决故障）。安全问题就是这样一个经典场景，例如：如果攻击者攻陷了系统并获取了敏感信息，事件的影响不能完全消除。然而本书主要解决那些可以修正的故障，比如接下来几节介绍的。
